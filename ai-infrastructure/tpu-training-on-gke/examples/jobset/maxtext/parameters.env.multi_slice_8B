TPU_SLICE_TYPE=tpu-v5-lite-podslice
TPU_TOPOLOGY=4x4
LOCAL_QUEUE=tpu-training-jobs
ICI_PARALLELISM=16
JOB_PARALLELISM=4
NUM_SLICES=2
RUN_NAME=maxtext-single-slice-101
BASE_OUTPUT_DIRECTORY=gs://prefix-artifact-repository/runs
DATASET_PATH=gs://prefix-artifact-repository/datasets
TENSORBOARD_NAME=projects/project-id/locations/us-central1/tensorboards/910xxxxx16
WID_KSA=wid-sa
ARGS=steps=150 per_device_batch_size=6 enable_checkpointing=false enable_profiler=false remat_policy=full max_target_length=2048  log_period=50 global_parameter_scale=8
LIBTPU_INIT_ARGS=--xla_tpu_enable_data_parallel_all_reduce_opt=true --xla_tpu_data_parallel_opt_different_sized_ops=true --xla_tpu_enable_async_collective_fusion=true --xla_tpu_enable_async_collective_fusion_fuse_all_gather=true --xla_tpu_enable_async_collective_fusion_multiple_steps=true --xla_tpu_overlap_compute_collective_tc=true --xla_enable_async_all_gather=true
