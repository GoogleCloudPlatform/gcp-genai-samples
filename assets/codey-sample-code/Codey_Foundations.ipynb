{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "Codey models are text-to-code models from Google AI, trained on a massive code related dataset. You can generate code related responses for different scenarios such as writing functions, unit tests, debugging, autocompleting and etc. This notebook is to show you how to call REST APIs and Python SDKs of different codey models including code-bision, code-gecko, and codechat-bison.\n",
        "\n",
        "The notebook is structured as follows:\n",
        "\n",
        "1. We will explain what code-bison can do and how to use REST APIs and Python SDKs of code-bison with examples.\n",
        "\n",
        "2. We will explain what code-gecko can do and how to use REST APIs and Python SDKs of code-gecko with examples.\n",
        "\n",
        "3. We will explain what codechat-bison can do and how to use REST APIs and Python SDKs of codechat-bison with examples.\n",
        "\n",
        "Refer to the doc for the latest codey model overview: https://cloud.google.com/vertex-ai/docs/generative-ai/code/code-models-overview"
      ],
      "metadata": {
        "id": "qhqOkOsjgJ1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit to jarekk@ for his work at 01-foundation-models-walkthrough notebook\n"
      ],
      "metadata": {
        "id": "nn2EvV5Z_aLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Contributor: leip@\n",
        "* Date: 09/22/23"
      ],
      "metadata": {
        "id": "jZFKP1cd_V-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep Work"
      ],
      "metadata": {
        "id": "Zw9NzqCg6Wff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Libraries\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    ! pip install google-cloud-aiplatform\n",
        "    ! pip install google-cloud-discoveryengine\n",
        "    from google.colab import auth as google_auth\n",
        "    google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "LWo-Dxmx6F26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67893422-bc2d-4226-8e18-84df6a08a8bf"
      },
      "source": [
        "## Code Models\n",
        "\n",
        "Vertex AI includes a suite of models that work with code. Together these code models are referred to as the Vertex AI Codey APIs. The Vertex AI Codey APIs include the following:\n",
        "\n",
        "* The **code generation API** - Generates code based on a natural language description of the desired code. For example, it can generate a unit test for a function. The code generation API supports the code-bison model.\n",
        "\n",
        "* The **code chat API** - Can power a chatbot that assists with code-related questions. For example, you can use it for help debugging code. The code chat API supports the codechat-bison model.\n",
        "\n",
        "* The **code completion API** - Provides code autocompletion suggestions as you write code. The API uses the context of the code you're writing to make its suggestions. The code completion API supports the code-gecko model.\n",
        "\n",
        "Refer to the doc for the latest codey model overview: https://cloud.google.com/vertex-ai/docs/generative-ai/code/code-models-overview\n",
        "\n",
        "\n",
        "The Codey APIs support the following programming languages:\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/code/code-models-overview#supported_coding_languages\n",
        "\n",
        "### **code-bison** model\n",
        "\n",
        "The **code-bison** model supports generating code using a natural language description. Refer to code-bison doc for the latest updates:\n",
        "\n",
        "Some common use cases for code generation are:\n",
        "\n",
        "* Unit tests - Design a prompt to request a unit test for a function.\n",
        "* Write a function - Pass a problem to the model to get a function that solves the problem.\n",
        "* Create a class - Use a prompt to describe the purpose of a class and have code that defines the class returned.\n",
        "\n",
        "#### Stable version\n",
        "\n",
        "code-bison@001\n",
        "\n",
        "#### Model properties\n",
        "* Max input tokens: 6144\n",
        "* Max ouptut tokens: 2048\n",
        "\n",
        "#### REST API\n",
        "\n",
        "##### HTTP request\n",
        "`POST https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/code-bison:predict`\n",
        "\n",
        "##### Request body\n",
        "```\n",
        "{\n",
        "  \"instances\": [\n",
        "    { \"prefix\": string }\n",
        "  ],\n",
        "  \"parameters\": {\n",
        "    \"temperature\": number,\n",
        "    \"maxOutputTokens\": integer,\n",
        "    \"candidateCount\": integer,\n",
        "    \"stopSequences\": [ string ]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "##### Request response\n",
        "\n",
        "```\n",
        "{\n",
        "  \"predictions\": [\n",
        "    {\n",
        "      \"content\": string,\n",
        "      \"score\": float,\n",
        "      \"citationMetadata\": {\n",
        "        \"citations\": [\n",
        "          {\n",
        "            \"startIndex\": integer,\n",
        "            \"endIndex\": integer,\n",
        "            \"url\": string,\n",
        "            \"title\": string,\n",
        "            \"license\": string,\n",
        "            \"publicationDate\": string\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      \"safetyAttributes\":{\n",
        "        \"categories\": [],\n",
        "        \"blocked\": false,\n",
        "        \"scores\": []\n",
        "      },\n",
        "      \"score\": float\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "Refer to the [API reference](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/code-generation) for the detailed information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd6f45c5-5d03-4b61-be5a-1e38762959b0"
      },
      "source": [
        "#### Using Python SDK\n",
        "\n",
        "Create the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afe2c9be-91db-45e5-875b-a936e4ef9de8"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.language_models import CodeGenerationModel\n",
        "VERTEX_API_PROJECT = 'certain-haiku-391918'\n",
        "VERTEX_API_LOCATION = 'us-central1'\n",
        "vertexai.init(project=VERTEX_API_PROJECT, location=VERTEX_API_LOCATION)\n",
        "code_generation_model = CodeGenerationModel.from_pretrained(\"code-bison@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b1842b1-0af1-4ef5-b453-638d5d9b6c70"
      },
      "source": [
        "Invoke the model with parameters and prefix\n",
        "\n",
        "- Write a function to check leap year with pseudo code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8676a82-c650-4445-910a-e12a9018fb00",
        "outputId": "9c615a4a-4ca0-463d-e448-6048cd05de45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'vertexai.language_models.TextGenerationResponse'>\n"
          ]
        }
      ],
      "source": [
        "prefix = \"Write a pseudo code for a function that checks if a year is a leap year.\"\n",
        "\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 512\n",
        "}\n",
        "\n",
        "response = code_generation_model.predict(\n",
        "        prefix=prefix, **parameters\n",
        ")\n",
        "\n",
        "print(type(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ded88376-4739-4b5e-9489-e02d86d42a9c"
      },
      "source": [
        "The response is a `TextGenerationResponse object`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05fad7e0-87e7-4447-9156-e5aa72373500",
        "outputId": "5afb3b6f-401b-4514-ba11-705eb062a683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Algorithm**\n",
            "\n",
            "1. **Input** the year to be checked.\n",
            "2. **If** the year is divisible by 4, then:\n",
            "    * **If** the year is divisible by 100, then:\n",
            "        * **If** the year is divisible by 400, then the year is a leap year.\n",
            "        * **Else** the year is not a leap year.\n",
            "    * **Else** the year is a leap year.\n",
            "3. **Else** the year is not a leap year.\n",
            "\n",
            "**Output** the result of the check.\n"
          ]
        }
      ],
      "source": [
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Write a function to check leap year with Python\n"
      ],
      "metadata": {
        "id": "vI19hP8kwm1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b3c2d9b-7590-4020-8e4d-8d6eb7a79b27",
        "outputId": "4cbc511e-1eb9-4154-e12f-d34ec7ab42f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def is_leap_year(year):\n",
            "  \"\"\"\n",
            "  Determines whether a year is a leap year.\n",
            "\n",
            "  Args:\n",
            "    year: The year to check.\n",
            "\n",
            "  Returns:\n",
            "    True if the year is a leap year, False otherwise.\n",
            "  \"\"\"\n",
            "\n",
            "  # A year is a leap year if it is divisible by 4, unless it is divisible by 100\n",
            "  # unless it is also divisible by 400.\n",
            "\n",
            "  if year % 4 == 0:\n",
            "    if year % 100 == 0:\n",
            "      return year % 400 == 0\n",
            "    else:\n",
            "      return True\n",
            "  else:\n",
            "    return False\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "prefix = \"Write a Python function that checks if a year is a leap year.\"\n",
        "\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 512\n",
        "}\n",
        "\n",
        "response = code_generation_model.predict(\n",
        "        prefix=prefix, **parameters\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56eb61b4-1938-4868-bf01-63bce34bded9"
      },
      "source": [
        "### **code-gecko** model\n",
        "\n",
        "The **code-gecko** model supports code completion. It completes code that was typed by a user.\n",
        "\n",
        "Some common use cases for code generation are:\n",
        "\n",
        "* Write code faster: Use the code-geckomodel to write code faster by taking advantage of code suggested for you.\n",
        "\n",
        "* Minimize bugs in code: Use code suggestions that you know are syntactically correct to avoid errors. Code completion helps you minimize the risk of accidentally introducing bugs that can occur when you write code quickly.\n",
        "\n",
        "#### Stable version\n",
        "\n",
        "code-gecko@001\n",
        "\n",
        "#### Model properties\n",
        "* Max input tokens: 2048\n",
        "* Max ouptut tokens: 64\n",
        "\n",
        "#### REST API\n",
        "\n",
        "##### HTTP request\n",
        "`POST https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/code-gecko:predict`\n",
        "\n",
        "##### Request body\n",
        "```\n",
        "{\n",
        "  \"instances\": [\n",
        "    { \"prefix\": string,\n",
        "      \"suffix\": string }\n",
        "  ],\n",
        "  \"parameters\": {\n",
        "    \"temperature\": number,\n",
        "    \"maxOutputTokens\": integer,\n",
        "    \"candidateCount\": integer,\n",
        "    \"stopSequences\": [ string ]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "##### Request response\n",
        "\n",
        "```\n",
        "{\n",
        "  \"predictions\": [\n",
        "    {\n",
        "      \"content\": string,\n",
        "      \"citationMetadata\": {\n",
        "        \"citations\": [\n",
        "          {\n",
        "            \"startIndex\": integer,\n",
        "            \"endIndex\": integer,\n",
        "            \"url\": string,\n",
        "            \"title\": string,\n",
        "            \"license\": string,\n",
        "            \"publicationDate\": string\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      \"safetyAttributes\": {\n",
        "        \"categories\": [ string ],\n",
        "        \"blocked\": boolean,\n",
        "        \"scores\": [ float ]\n",
        "      },\n",
        "      \"score\": float\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "Refer to the [API reference](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/code-completion) for the detailed information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b11cb98-fc3e-47b0-8827-89edba75fb54"
      },
      "source": [
        "#### Using Python SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fae6b9d-2f85-4636-aca0-f63f658fc3e4"
      },
      "source": [
        "Create the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43fb022d-265a-4dec-a899-ca803ee7d0bb"
      },
      "outputs": [],
      "source": [
        "from vertexai.language_models import CodeGenerationModel\n",
        "\n",
        "code_completion_model = CodeGenerationModel.from_pretrained(\"code-gecko@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "746dab05-39a1-404e-95b9-9c1a48a9ce0a"
      },
      "source": [
        "Invoke the model with parameters and prefix\n",
        "\n",
        "- Complete code of reverse string function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "283d5851-2d0b-45d9-b43e-65215ff9532d",
        "outputId": "fb134c4c-3d14-4a81-c40a-1b3aac7a4be9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'vertexai.language_models.TextGenerationResponse'>\n"
          ]
        }
      ],
      "source": [
        "prefix = \"def reverse_string(s):\"\n",
        "\n",
        "parameters = {\n",
        "        \"temperature\": 0.2,\n",
        "        \"max_output_tokens\": 64,\n",
        "}\n",
        "\n",
        "response = code_completion_model.predict(prefix=prefix, **parameters)\n",
        "\n",
        "print(type(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "905a2b0b-c734-4bbf-a107-e6dd2f1e12d4"
      },
      "source": [
        "The response is a TextGenerationResponse object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58efc0ab-0bba-4332-97db-5fb9fdefdbe8",
        "outputId": "9da101e8-83ef-4daa-c5d0-d6a19c8a3714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    return s[::-1]\n",
            "\n",
            "\n",
            "def reverse_string_2(s):\n",
            "score:  -2.4987316131591797\n"
          ]
        }
      ],
      "source": [
        "print(response.text)\n",
        "print('score: ', response._prediction_response.predictions[0]['score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f41fff4e-718b-4c89-b975-c9740efcb054"
      },
      "source": [
        "### **codechat-bison** model\n",
        "\n",
        "The **codechat-bison** model supports multi-turn conversations that are specialized for code. The model allows developers to chat with a chatbot for help with code-related questions.\n",
        "\n",
        "Some common use cases for code generation are:\n",
        "\n",
        "* Get help about code: Get help with questions you have about code, such as questions about an API, syntax in a supported programming language, or which version of a library is required for code you're writing.\n",
        "\n",
        "* Debugging: Get help with debugging code that doesn't compile or that contains a bug.\n",
        "\n",
        "* Documentation: Get help understanding code so you can document it accurately.\n",
        "\n",
        "* Learn about code: Get help learning about code you're not familiar with.\n",
        "\n",
        "#### Stable version\n",
        "\n",
        "codechat-bison@001\n",
        "\n",
        "#### Model properties\n",
        "* Max input tokens: 6144\n",
        "* Max ouptut tokens: 2048\n",
        "\n",
        "#### REST API\n",
        "\n",
        "##### HTTP request\n",
        "`POST https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/codechat-bison:predict`\n",
        "\n",
        "##### Request body\n",
        "```\n",
        "{\n",
        "  \"instances\": [\n",
        "    {\n",
        "      \"context\": string,\n",
        "      \"messages\": [\n",
        "        {\n",
        "          \"content\": string,\n",
        "          \"author\": string\n",
        "        }\n",
        "  ],\n",
        "  \"parameters\": {\n",
        "    \"temperature\": number,\n",
        "    \"maxOutputTokens\": integer,\n",
        "    \"candidateCount\": integer\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "##### Request response\n",
        "\n",
        "```\n",
        "{\n",
        "  \"predictions\": [\n",
        "    {\n",
        "      \"candidates\": [\n",
        "        {\n",
        "          \"author\": string,\n",
        "          \"content\": string\n",
        "        }\n",
        "      ],\n",
        "      \"citationMetadata\": {\n",
        "        \"citations\": [\n",
        "          {\n",
        "            \"startIndex\": integer,\n",
        "            \"endIndex\": integer,\n",
        "            \"url\": string,\n",
        "            \"title\": string,\n",
        "            \"license\": string,\n",
        "            \"publicationDate\": string\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      \"safetyAttributes\": {\n",
        "        \"categories\": [],\n",
        "        \"blocked\": false,\n",
        "        \"scores\": []\n",
        "      },\n",
        "      \"score\": float\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "Refer to the [API reference](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/code-chat) for the detailed information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c7caeed-a102-4763-8fc6-44ca623e3aba"
      },
      "source": [
        "#### Using Python SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a53d400d-bfd9-400f-b02c-d585066aa463"
      },
      "source": [
        "Create the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fed9838d-ec00-4648-86de-77b40b31940a"
      },
      "outputs": [],
      "source": [
        "from vertexai.language_models import CodeChatModel\n",
        "\n",
        "code_chat_model = CodeChatModel.from_pretrained(\"codechat-bison@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc52b81d-4ad6-4321-867a-31b92f65284b"
      },
      "source": [
        "Create a chat session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f899012-83fb-43b5-b525-183edc11cb7d"
      },
      "outputs": [],
      "source": [
        "chat = code_chat_model.start_chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01e18f5b-2347-49ef-af78-dc1c196eafcf"
      },
      "source": [
        "Invoke the model with parameters and prefix\n",
        "\n",
        "- Modify functions with codechat-bison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "975f352c-d403-4f84-be32-c43f6330d14f",
        "outputId": "7e7fe453-643e-4d88-de4a-841b29eed34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following Python function calculates the minimum of two numbers:\n",
            "\n",
            "```\n",
            "def min(a, b):\n",
            "  \"\"\"\n",
            "  Calculates the minimum of two numbers.\n",
            "\n",
            "  Args:\n",
            "    a: The first number.\n",
            "    b: The second number.\n",
            "\n",
            "  Returns:\n",
            "    The smaller of the two numbers.\n",
            "  \"\"\"\n",
            "\n",
            "  if a < b:\n",
            "    return a\n",
            "  else:\n",
            "    return b\n",
            "```\n",
            "\n",
            "This function takes two numbers as input and returns the smaller of the two numbers. The function first compares the two numbers and returns the smaller number. If the two numbers are equal, the function returns either of the two numbers.\n"
          ]
        }
      ],
      "source": [
        "message = \"Please help write a Python function to calculate the min of two numbers\"\n",
        "\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 1024\n",
        "}\n",
        "\n",
        "response = chat.send_message(message,**parameters)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d03fe746-ab6a-4352-b7e9-a6eedd28c585"
      },
      "source": [
        "Continue a conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd361fa7-d0fc-4d9d-bec9-e47f8a2c8101",
        "outputId": "9532e8cb-80d6-4630-9788-a1b60c91dda4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, here is the modified function:\n",
            "\n",
            "```\n",
            "def min(a, b):\n",
            "  \"\"\"\n",
            "  Calculates the minimum of two numbers and multiplies the result by 2.\n",
            "\n",
            "  Args:\n",
            "    a: The first number.\n",
            "    b: The second number.\n",
            "\n",
            "  Returns:\n",
            "    The smaller of the two numbers multiplied by 2.\n",
            "  \"\"\"\n",
            "\n",
            "  if a < b:\n",
            "    return a * 2\n",
            "  else:\n",
            "    return b * 2\n",
            "```\n",
            "\n",
            "This function takes two numbers as input and returns the smaller of the two numbers multiplied by 2. The function first compares the two numbers and returns the smaller number. If the two numbers are equal, the function returns either of the two numbers multiplied by 2.\n"
          ]
        }
      ],
      "source": [
        "message = \"Modify the function to multiple a result by 2.\"\n",
        "\n",
        "response = chat.send_message(message)\n",
        "\n",
        "print(response)"
      ]
    }
  ]
}