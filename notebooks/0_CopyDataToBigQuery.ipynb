{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"display: flex; align-items: left;\">\n",
        "    <a href=\"https://sites.google.com/corp/google.com/genai-solutions/home?authuser=0\">\n",
        "        <img src=\"https://storage.googleapis.com/miscfilespublic/Linkedin%20Banner%20%E2%80%93%202.png\" style=\"margin-right\">\n",
        "    </a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "copyright"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRyGcAepAPJ5"
      },
      "source": [
        "\n",
        "# **Open Data QnA: Set up BigQuery Source**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook shows how to copy a BigQuery public dataset to your GCP project \n",
        "\n",
        "\n",
        "This is accomplished through the three following steps:  \n",
        "> i. Create a BigQuery dataset in your GCP project\n",
        "\n",
        "> ii. Create a table in the above dataset\n",
        "\n",
        "> iii. Copy data from the public dataset to the dataset on your project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó **1. Connect Your Google Cloud Project**\n",
        "Time to connect your Google Cloud Project to this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "Project has been set to eight-p-o\n"
          ]
        }
      ],
      "source": [
        "#@markdown Please fill in the value below with your GCP project ID and then run the cell.\n",
        "PROJECT_ID = input(\"Enter the project id (same as your SetUpVectorStore) to copy source data in bigquery for this solution\")\n",
        "\n",
        "# Quick input validation\n",
        "assert PROJECT_ID, \"‚ö†Ô∏è Please provide your Google Cloud Project ID\"\n",
        "\n",
        "# Configure gcloud.\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "print(f'Project has been set to {PROJECT_ID}')\n",
        "# !gcloud auth application-default set-quota-project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yygMe6rPWxHS"
      },
      "source": [
        "## üîê **2. Authenticate to Google Cloud**\n",
        "Authenticate to Google Cloud as the IAM user logged into this notebook in order to access your Google Cloud Project.\n",
        "\n",
        "You can do this within Google Colab or using the Application Default Credentials in the Google Cloud CLI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PTXN1_DSXj2b"
      },
      "outputs": [],
      "source": [
        "# Authentication step\n",
        "\n",
        "\"\"\"Colab Auth\"\"\" \n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "\n",
        "\n",
        "\"\"\"Google CLI Auth\"\"\"\n",
        "# !gcloud auth application-default login\n",
        "\n",
        "\"\"\"Jupiter Notebook Auth\"\"\"\n",
        "import google.auth\n",
        "credentials, project_id = google.auth.default()\n",
        "# credentials = google.auth.credentials.with_scopes_if_required(credentials)\n",
        "# authed_http = google.auth.transport.requests.AuthorizedSession(credentials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚òÅÔ∏è **Copy a Public Dataset to your GCP Project**\n",
        "\n",
        "Conside the table from the public dataset to ask questions against. Copy that the needed table to local dataset so that.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Details of source Dataset\n",
        "BQ_SRC_PROJECT = \"bigquery-public-data\"\n",
        "BQ_SRC_DATASET = \"fda_food\"\n",
        "BQ_SRC_TABLE = \"food_enforcement\"\n",
        "BQ_SRC_REGION= \"us\"\n",
        "\n",
        "# Details of destination Dataset\n",
        "BQ_DST_PROJECT = PROJECT_ID\n",
        "BQ_DST_DATASET = \"fda_food\"\n",
        "BQ_DST_TABLE = \"food_enforcement\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def createBQDataset(bq_project_id, dataset_name,dataset_region):\n",
        "    from google.cloud import bigquery\n",
        "    import google.api_core \n",
        "\n",
        "    client=bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "    dataset_ref = f\"{bq_project_id}.{dataset_name}\"\n",
        "\n",
        "    try:\n",
        "        client.get_dataset(dataset_ref)\n",
        "        print(\"Destination Dataset exists\")\n",
        "    except google.api_core.exceptions.NotFound:\n",
        "        print(\"Cannot find the dataset hence creating.......\")\n",
        "        dataset=bigquery.Dataset(dataset_ref)\n",
        "        dataset.location=dataset_region\n",
        "        client.create_dataset(dataset)\n",
        "        \n",
        "    return dataset_ref\n",
        "\n",
        "def createBQTable(bq_project_id,dataset_name, table_name):\n",
        "        from google.cloud import bigquery\n",
        "        import google.api_core \n",
        "\n",
        "        client=bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "        table_ref = client.dataset(dataset_name, project=bq_project_id).table(table_name)\n",
        "\n",
        "        try:\n",
        "            client.get_table(table_ref)\n",
        "            print(\"Destination Table exists\")\n",
        "            \n",
        "        except google.api_core.exceptions.NotFound:\n",
        "            print(\"Cannot find the table hence creating.......\")\n",
        "            table = bigquery.Table(table_ref)\n",
        "            client.create_table(table)\n",
        "\n",
        "        return table_ref\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cannot find the dataset hence creating.......\n",
            "Cannot find the table hence creating.......\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CopyJob<project=eight-p-o, location=US, id=acc09426-c15f-4747-aaf5-f423f69fef54>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create destination table and copy table data\n",
        "from google.cloud import bigquery\n",
        "\n",
        "client=bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "dst_dataset_ref=createBQDataset(BQ_DST_PROJECT,BQ_DST_DATASET,BQ_SRC_REGION)\n",
        "\n",
        "dst_table_ref=createBQTable(BQ_DST_PROJECT,BQ_DST_DATASET,BQ_DST_TABLE)\n",
        "\n",
        "src_table_ref = client.dataset(BQ_SRC_DATASET, project=BQ_SRC_PROJECT).table(BQ_SRC_TABLE)\n",
        "\n",
        "job_config = bigquery.CopyJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
        "\n",
        "copy_job = client.copy_table(src_table_ref, dst_table_ref, job_config=job_config)\n",
        "\n",
        "\n",
        "\n",
        "# Wait for the job to complete and check for errors\n",
        "copy_job.result()  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### If all the above steps are executed suucessfully, the Bigquery Public dataset should be copied to your GCP project"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
