{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0q6qjyLbCG5"
      },
      "source": [
        "# Game Review Analysis Workflow with Vertex Extensions\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/applied-ai-engineering-samples/blob/main/genai-on-vertex-ai/vertex_extensions/business_analyst_workflow_vertex_extensions.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fapplied-ai-engineering-samples%2Fmain%2Fgenai-on-vertex-ai%2Fvertex_extensions%2Fbusiness_analyst_workflow_vertex_extensions.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/applied-ai-engineering-samples/main/genai-on-vertex-ai/vertex_extensions/business_analyst_workflow_vertex_extensions.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/applied-ai-engineering-samples/tree/main/genai-on-vertex-ai/vertex_extensions/business_analyst_workflow_vertex_extensions.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGwjcyJkb78K"
      },
      "source": [
        "| | |\n",
        "|----------|-------------|\n",
        "| Author(s)   | [Meltem Subasioglu](https://github.com/5Y5TEM)|\n",
        "| Reviewers(s) | Yan Sun |\n",
        "| Last updated | 2024-04-08: Initial Publication |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Overview\n",
        "\n",
        "[Vertex AI Extensions](https://cloud.google.com/vertex-ai/docs/generative-ai/extensions/private/overview) is a platform for creating and managing extensions that connect large language models to external systems via APIs. These external systems can provide LLMs with real-time data and perform data processing actions on their behalf.\n",
        "\n",
        "In this tutorial, you'll use vertex extensions to complete a review analysis of a steam game:\n",
        "\n",
        "- Retrieve 50 reviews from steam on the game\n",
        "- Create a pre-built code interpreter extension in your project\n",
        "- Use code interpreter to analyze the reviews and generate plots\n",
        "- Retrieve 10 websites with more detailed reviews on the game\n",
        "- Create and use the vertex AI search extension to research and summarize  the website reviews\n",
        "- Use code interpreter to build a report with all the generated assets\n",
        "- Convert the report to PDF and upload to your Google Drive  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S23-EwCumCU"
      },
      "source": [
        "‚ñ∂ If you're already familiar with Google Cloud and the Vertex Extensions Code Interpreter Extension, you can skip reading between here and the \"**Getting Started**\" section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUXzlvfpn513"
      },
      "source": [
        "## Vertex AI Extensions\n",
        "\n",
        "[Vertex AI Extensions](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/overview) is a platform for creating and managing extensions that connect large language models to external systems via APIs. These external systems can provide LLMs with real-time data and perform data processing actions on their behalf. You can use pre-built or third-party extensions in Vertex AI Extensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r29fUEFn8JH"
      },
      "source": [
        "## Vertex AI Extensions Code Interpreter Extension\n",
        "\n",
        "The [Code Interpreter](https://console.cloud.google.com/vertex-ai/generative-ai/docs/extensions/google-extensions.md#google_code_interpreter_extension) extension provides access to a Python interpreter with a sandboxed, secure execution environment that can be used with any model in the Vertex AI Model Garden. This extension can generate and execute code in response to a user query or workflow. It allows the user or LLM agent to perform various tasks such as data analysis and visualization on new or existing data files.\n",
        "\n",
        "You can use the Code Interpreter extension to:\n",
        "\n",
        "* Generate and execute code.\n",
        "* Perform a wide variety of mathematical calculations.\n",
        "* Sort, filter, select the top results, and otherwise analyze data (including data acquired from other tools and APIs).\n",
        "* Create visualizations, plot charts, draw graphs, shapes, print results, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNriTZl70OdV"
      },
      "source": [
        "## Using this Notebook\n",
        "\n",
        "Colab is recommended for running this notebook, but it can run in any iPython environment where you can connect to Google Cloud, install pip packages, etc.\n",
        "\n",
        "If you're running outside of Colab, depending on your environment you may need to install pip packages (like pandas) that are included in the Colab environment by default but are not part of the Python Standard Library. You'll also notice some comments in code cells that look like #@something -- these may contain informative text\n",
        "\n",
        "This tutorial uses the following Google Cloud services and resources:\n",
        "\n",
        "* Vertex AI Extensions\n",
        "* Google Cloud Storage Client\n",
        "* Google Drive Client\n",
        "\n",
        "This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.10.12\n",
        "* [google-cloud-aiplatform](https://pypi.org/project/google-cloud-aiplatform/) version = 1.46.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar0aDcql1dxl"
      },
      "source": [
        "## Useful Tips\n",
        "\n",
        "1. This notebook is using Generative AI cababilities. Re-running a cell that uses Generative AI capabilities may produce similar but not identical results.\n",
        "2. Because of #1, it is possible that an output from Code Interpreter producess errors. If that happens re-run the cell that produced the coding error. The different generated code will likely be bug free.\n",
        "3. If you see a session error when using the extension, try re-running the cell.\n",
        "4. The use of Extensions and other Generative AI capabilities is subject to service quotas. Running the notebook using \"Run All\" may exceed  your Queries per minute (QPM) limitations. Run the notebook manually and if you get a quota error pause for up to 1 minute before retrying that cell. Code Interpreter uses Gemini on the backend and is subject to the Gemini quotas, [view your Gemini quotas here](https://console.cloud.google.com/iam-admin/quotas?pageState=(%22allQuotasTable%22:(%22f%22:%22%255B%257B_22k_22_3A_22_22_2C_22t_22_3A10_2C_22v_22_3A_22_5C_22base_model_5C_22_22%257D_2C%257B_22k_22_3A_22_22_2C_22t_22_3A10_2C_22v_22_3A_22_5C_22gemini_5C_22_22%257D%255D%22%29%29&e=13802955&mods=logs_tg_staging).\n",
        "\n",
        "\n",
        "üíÅ Extra tips:\n",
        "- The Code Interpreter runs in a sandbox environment. So try to avoid prompts that need additional python packages to run or tell the Code Interpreter to ignore anything that needs packages beyond the built-in ones\n",
        "- Tell the Code Interpreter to catch and print any exceptions for you\n",
        "- For debugging the output of the Vertex Code Interpreter extension, it usually helps copying the error message into the prompt and telling the extension to properly handle that error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO_tnShTGUik"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "The following steps are necessary to run this notebook, no matter what notebook environment you're using.\n",
        "\n",
        "If you're entirely new to Google Cloud, [get started here](https://cloud.google.com/docs/get-started)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLf5oGqHn_DH"
      },
      "source": [
        "## Google Cloud Project Setup\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "1. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTuXDJ2qn-8W"
      },
      "source": [
        "## Google Cloud Permissions\n",
        "Make sure you have been [granted the following roles](https://cloud.google.com/iam/docs/granting-changing-revoking-access) for the GCP project you'll access from this notebook:\n",
        "* [`roles/aiplatform.user`](https://cloud.google.com/vertex-ai/docs/general/access-control#aiplatform.user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## Install Vertex AI SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-discoveryengine --upgrade\n",
        "!pip install google-cloud-aiplatform --upgrade\n",
        "!pip install weasyprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "You may see the restart reported as a crash, but it is working as-intended -- you are merely restarting the runtime.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>‚ö†Ô∏è The kernel is going to restart. Please wait until it is finished before continuing to the next step. ‚ö†Ô∏è</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vk8FYRBekhR"
      },
      "source": [
        "## Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAihqmEKetF9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from google.auth import default\n",
        "from google.colab import auth as google_auth\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    google_auth.authenticate_user()\n",
        "\n",
        "creds, _ = default()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE5wS2uzoDsk"
      },
      "source": [
        "## Outside of Colab: Install the Google Cloud CLI\n",
        "\n",
        "If you are running this notebook in your own environment, you need to install the [Cloud SDK](https://cloud.google.com/sdk) (aka `gcloud`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNcfOA7Ne0kP"
      },
      "source": [
        "## Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n",
        "\n",
        "You will further need a GCS bucket. Learn more about [creating a Google Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n",
        "\n",
        "**Note:** For the scope of this Notebook, set the access permissions for your newly created bucket to public. This is needed to embed generated images into the pdf report further below. Alternatively, you can prompt the Code Interpreter to input the image links into the report instead of embedding them directly. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"MY_PROJECT_ID\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
        "API_ENV = \"aiplatform.googleapis.com\"  # @param {type:\"string\"}\n",
        "GCS_BUCKET = \"MY_GCS_BUCKET_NAME\"  # @param {type:\"string\"}\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "\n",
        "\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    api_endpoint=f\"{REGION}-{API_ENV}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MFqpF8pfWPJ"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWMRFC3rfa2U"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview import extensions\n",
        "from vertexai.generative_models import GenerativeModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ossHfQf-4Swv"
      },
      "source": [
        "# Using Extensions to Analyze Game Reviews - Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgTdZdjBzrEN"
      },
      "source": [
        "## Step 1: Create a Code Interpreter Extension\n",
        "\n",
        "Now you can create the extension. The following cell uses the Python SDK to import the extension (thereby creating it) in Vertex AI Extensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-A82yCzDry5"
      },
      "outputs": [],
      "source": [
        "extension_code_interpreter = extensions.Extension.from_hub(\"code_interpreter\")\n",
        "extension_code_interpreter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1usXSbifON0"
      },
      "source": [
        "### Helper Functions\n",
        "These functions are optional when using Code Interpreter but make it easier to inspect Code Interpreter's output, assemble Code Interprer requests, and run generated code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9voRN5xMU6qO"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import io\n",
        "import json\n",
        "from PIL import Image\n",
        "import pprint\n",
        "from google.protobuf import json_format\n",
        "from google.protobuf.struct_pb2 import Struct\n",
        "import pandas\n",
        "import sys\n",
        "import os\n",
        "import IPython\n",
        "if sys.version_info[0] < 3:\n",
        "    from StringIO import StringIO\n",
        "else:\n",
        "    from io import StringIO\n",
        "\n",
        "css_styles = \"\"\"\n",
        "<style>\n",
        ".main_summary { font-weight: bold; font-size: 14px; color: #4285F4;  background-color:rgba(221, 221, 221, 0.5); padding:8px;}\n",
        ".main_summary:hover {background-color: rgba(221, 221, 221, 1);}\n",
        "details { background-color:#fff; border: 1px solid #E8EAED; padding:0px; margin-bottom:2px; }\n",
        "details img {width:50%}\n",
        "details > div {padding:10px; }\n",
        "div#left > details:first-of-type > div {overflow:auto; max-height:400px; }\n",
        "div#right > pre {overflow:auto; max-height:600px; background-color: ghostwhite; padding: 10px; }\n",
        "details details > div { overflow: scroll; max-height:400px}\n",
        "details details { background-color:rgba(246, 231, 217, 0.2);  border: 1px solid #FBBC04;}\n",
        "details details > summary { padding: 8px; background-color:rgba(255, 228, 196, 0.6); }\n",
        "details details > summary:hover { background-color:rgba(255, 228, 196, 0.9); }\n",
        "div#left {width: 64%; padding:0 1%;  }\n",
        "div#right {border-left: 1px solid silver; width: 30%; float: right; padding:0 1%; }\n",
        "body {color: #000; background-color: white; padding:10px 10px 40px 10px; }\n",
        "#main { border: 1px solid #FBBC04; padding:10px 0; display: flow-root; }\n",
        "h3 {color: #000; }\n",
        "code  { font-family: monospace; color: #900; padding: 0 2px; font-size: 105%; }\n",
        "</style>\n",
        "        \"\"\"\n",
        "# Parser that helps visualise the content of the returned files as HTML\n",
        "def parse_files_to_html(outputFiles, save_files_locally = True):\n",
        "    IMAGE_FILE_EXTENSIONS = set([\"jpg\", \"jpeg\", \"png\"])\n",
        "    file_list = []\n",
        "\n",
        "    if not outputFiles:\n",
        "      return \"No Files generated from the code\"\n",
        "    # Sort the output_files so images are displayed before other files such as JSON\n",
        "    for output_file in sorted(\n",
        "        outputFiles,\n",
        "        key=lambda x: x[\"name\"].split(\".\")[-1] not in IMAGE_FILE_EXTENSIONS,\n",
        "    ):\n",
        "        file_name = output_file.get(\"name\")\n",
        "        file_contents = base64.b64decode(output_file.get(\"contents\"))\n",
        "        if save_files_locally:\n",
        "          open(file_name,\"wb\").write(file_contents)\n",
        "\n",
        "        if file_name.split(\".\")[-1] in IMAGE_FILE_EXTENSIONS:\n",
        "            # Render Image\n",
        "            file_html_content = f'<img src=\"data:image/png;base64, {output_file.get(\"contents\")}\" />'\n",
        "        elif file_name.endswith(\".json\"):\n",
        "            # Pretty print JSON\n",
        "            file_html_content =  f'<span>{pprint.pformat(json.loads(file_contents.decode()), compact=False, width=160)}</span>'\n",
        "        elif file_name.endswith(\".csv\"):\n",
        "            # CSV\n",
        "            file_html_content = f'<span>{pandas.read_csv(StringIO(file_contents.decode())).to_markdown(index=False)}</span>'\n",
        "        elif file_name.endswith(\".pkl\"):\n",
        "            # PKL\n",
        "            file_html_content = f'<span>Preview N/A</span>'\n",
        "        else:\n",
        "            file_html_content = f\"<span>{file_contents.decode()}</span>\"\n",
        "\n",
        "\n",
        "        file_list.append({'name': file_name, \"html_content\": file_html_content})\n",
        "\n",
        "    buffer_html = [ f\"<details><summary>{_file.get('name')}</summary><div>{_file.get('html_content')}</div></details>\" for _file in file_list ]\n",
        "\n",
        "\n",
        "    return \"\".join(buffer_html)\n",
        "\n",
        "\n",
        "# Comments\n",
        "# @title #### Helper function process_response(response) { form-width: \"35%\", display-mode: \"both\" }\n",
        "# @markdown Here we are defining functions that help processing and visualising the response from our extension within colab environment. \\\n",
        "# @markdown This is an optional process but it helps you: \\\n",
        "# @markdown - Visualise the code generated by Code Interpreter\n",
        "# @markdown - Visualise the executed code output or Exceptions\n",
        "# @markdown - Visualise any files generated from Code Interpreter \\\n",
        "# @markdown - Save all generated files locally \\\n",
        "\n",
        "# @markdown To use this functionality simply call **process_response(response)** \\\n",
        "# @markdown where **response** is the code interpreter response object\n",
        "# @markdown\n",
        "def process_response(response: dict, save_files_locally = True) -> None:\n",
        "\n",
        "  result_template = \"<details open><summary class='main_summary'>{summary}:</summary><div><pre>{content}</pre></div></details>\"\n",
        "  result = \"\"\n",
        "  code = response.get('generated_code')\n",
        "  if response.get('execution_error', None):\n",
        "    result = result_template.format(summary=\"An error occured when executing code\", content=response.get('execution_error', None))\n",
        "  else:\n",
        "    if 'execution_result' in response and response['execution_result']!=\"\":\n",
        "      result = result_template.format(summary=\"Executed Code Output\", content=response.get('execution_result'))\n",
        "    else:\n",
        "      result = result_template.format(summary=\"Executed Code Output\", content=\"Code did not produce printable output\")\n",
        "\n",
        "    result += result_template.format(summary=\"Files Created <u>(Click on filename to view content)</u>\", content=parse_files_to_html(response.get('output_files', []),  save_files_locally = True))\n",
        "\n",
        "  display(\n",
        "      IPython.display.HTML(\n",
        "        ( f\"{css_styles}\"\n",
        "f\"\"\"\n",
        "<div id='main'>\n",
        "    <div id=\"right\"><h3>Generated Code by Code Interpreter</h3><pre><code>{code}</code></pre></div>\n",
        "    <div id=\"left\"><h3>Code Execution Results</h3>{result}</div>\n",
        "</div>\n",
        "\"\"\"\n",
        "        )\n",
        "      )\n",
        "  )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O30vvMCqmnUx"
      },
      "outputs": [],
      "source": [
        "# Comments\n",
        "# @title #### Helper function to call code interpreter { form-width: \"35%\", display-mode: \"both\" }\n",
        "# @markdown ### **run_code_interpreter(instructions: str, filenames: list[dict])**\n",
        "# @markdown run_code_interpreter helps you call the code interpreter by submitting local files and instructions on what to do. \\\n",
        "# @markdown The function will deal with encoding the file content to base 64 and add it to the request payload. \\\n",
        "# @markdown Additionally if there is an error the function retries to up to `retry_num` (default is 2). \\\n",
        "\n",
        "def run_code_interpreter(instructions: str, filenames: list[dict] = [], retry_num = 2):\n",
        "  file_arr = [{\"name\": filename, \"contents\":  base64.b64encode(open(filename, \"rb\").read()).decode()} for filename in filenames]\n",
        "\n",
        "  attempts = 0\n",
        "  while attempts <= retry_num:\n",
        "    attempts += 1\n",
        "    res = extension_code_interpreter.execute(\n",
        "        operation_id = \"generate_and_execute\",\n",
        "        operation_params = {\n",
        "            \"query\": instructions,\n",
        "            \"files\": file_arr\n",
        "        },\n",
        "    )\n",
        "    if not res['execution_error']:\n",
        "      return res\n",
        "\n",
        "  return res\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown ### **run_locally(instructions: str, filenames: list[dict])**\n",
        "# @markdown run_locally executes the code generated by code interpreter locally (helps better understand the code behaviour and debugging)\n",
        "def run_locally(instructions: str, filenames: list[dict]):\n",
        "  response = run_code_interpreter(instructions= instructions, filenames= filenames)\n",
        "  my_code = \"\\n\".join(response['generated_code'].split('\\n')[1:-1])\n",
        "  exec(my_code)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCjnPm_lyWz"
      },
      "source": [
        "## Step 2: Use Code Interpreter to Analyze Steam Reviews\n",
        "\n",
        "In this section, you will specify a game title and parse some steam reviews for the title from store.steampowered.com.\n",
        "Using the Code Interpreter Extension, you will then perform some automated analysis on the reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O9PZdlhGNLm"
      },
      "outputs": [],
      "source": [
        "#@markdown Specify the name of the game\n",
        "game = \"Palworld\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcr6drreG_jE"
      },
      "source": [
        "### Prepare the Reviews Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uusyDyPfC5L"
      },
      "source": [
        "Now, grab the steam App ID for the game, if the game is supported on the platform. For this, we will do a Google Search to retrieve the Steam Game URL, and parse the ID out of the URL.\n",
        "\n",
        "**Note:** if you are facing errors with importing googlesearch, make sure that you don't have any conflicting packages installed. This is the googlesearch module that's installed when running pip install google. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDZ5EcodfCjn"
      },
      "outputs": [],
      "source": [
        "# Fetch steam review URL and the games App ID\n",
        "from googlesearch import search\n",
        "\n",
        "query = f\"{game} steampowered.com \"\n",
        "steam_url = list()\n",
        "\n",
        "for j in search(query, tld=\"com\", num=1, stop=1, pause=1):\n",
        "    print(\"URL: \",j)\n",
        "    steam_url.append(j)\n",
        "\n",
        "try:\n",
        "  steam_url = steam_url[0].split('app/')[1]\n",
        "  steam_appId = steam_url.split('/')[0]\n",
        "\n",
        "  print(\"App ID: \", steam_appId)\n",
        "\n",
        "except:\n",
        "  print(\"Could not parse the steam ID out of the URL. The game is likely not supported on Steam.\")\n",
        "  steam_appId = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAVahl-_NlO7"
      },
      "source": [
        "Now, grab some reviews from steam.\n",
        "The steam website loads infinitely and does not allow to search through the pages by the url. So we are limited to retrieving 10 hits for now.\n",
        "To circumvent, we will set five different filters to get the reviews:\n",
        "1. Top rated reviews of all time\n",
        "2. Trending reviews today\n",
        "3. Trending reviews this week\n",
        "4. Trending reviews this month  \n",
        "5. Most recent reviews\n",
        "\n",
        "This will give us a total of 50 reviews to work with.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frMOHXzG9vV7"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "def get_steam_reviews(filter, num_reviews):\n",
        "\n",
        "    url = f'https://steamcommunity.com/app/{steam_appId}/reviews/?p=1&browsefilter={filter}'\n",
        "\n",
        "    print(\"URL: \", url)\n",
        "\n",
        "    reviews = []\n",
        "    page = 0\n",
        "    reviews_per_page = 20\n",
        "\n",
        "    while len(reviews) < num_reviews:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        review_blocks = soup.find_all('div', class_='apphub_Card')\n",
        "\n",
        "        for block in review_blocks:\n",
        "            #print(\"\\nReview Block: \\n\", block)\n",
        "\n",
        "            # Author\n",
        "            author_block = block.find('div', class_='apphub_CardContentAuthorName')\n",
        "            if author_block:\n",
        "                author = author_block.text.strip()\n",
        "\n",
        "            # Rating\n",
        "            rating_block = block.find('div', class_='title')\n",
        "            if rating_block:\n",
        "                rating = rating_block.text.strip()\n",
        "\n",
        "            # Review Content\n",
        "            content_block = block.find('div', class_='apphub_CardTextContent')\n",
        "            if content_block:\n",
        "                content = content_block.text.strip()\n",
        "\n",
        "            # Review Date\n",
        "            date_block = content_block.find('div', class_='date_posted')\n",
        "            if date_block:\n",
        "                date = date_block.text.replace('Posted:', '').strip()\n",
        "\n",
        "            # Total Hours Played\n",
        "            hours_block = block.find('div', class_='hours')\n",
        "            if hours_block:\n",
        "                hours_played = hours_block.text.strip()\n",
        "\n",
        "\n",
        "            reviews.append({'author': author, 'content': content, 'rating': rating, 'date': date, 'hours_played' : hours_played})\n",
        "\n",
        "\n",
        "            if len(reviews) >= num_reviews:\n",
        "                break\n",
        "\n",
        "        page += 1\n",
        "\n",
        "    return reviews\n",
        "\n",
        "topRated_reviews = get_steam_reviews('toprated', 10)\n",
        "trendWeek_reviews = get_steam_reviews('trendweek', 10)\n",
        "trendMonth_reviews = get_steam_reviews('trendmonth', 10)\n",
        "trendDay_reviews = get_steam_reviews('trendday', 10)\n",
        "mostRecent_reviews = get_steam_reviews('mostrecent', 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUOEgt73GWVJ"
      },
      "source": [
        "Concatenate all the reviews in one single list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9g6hW5-OvDe"
      },
      "outputs": [],
      "source": [
        "all_reviews = topRated_reviews + trendWeek_reviews + trendMonth_reviews+ trendDay_reviews+ mostRecent_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPFrofM0nGub"
      },
      "source": [
        "Write the reviews into a .csv file so you can parse it with the Code Interpreter Extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOy00HlTR12H"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "filename = 'reviews.csv'\n",
        "\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "    # Determine field names (header row)\n",
        "    fieldnames = all_reviews[0].keys()\n",
        "\n",
        "    # Create a DictWriter\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    # Write the header\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write the data rows\n",
        "    writer.writerows(all_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqhj_DBMGpUR"
      },
      "source": [
        "Get the reviews in a pandas dataframe, so you can take a look into its content and inspect the reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSrIOYG0FRkV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('reviews.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4guwwt37G2_F"
      },
      "source": [
        "### Let Code Interpreter do its Magic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNWQ7DttHHEe"
      },
      "source": [
        "Write a helper function to collect all of the assets created by a Vertex Extension. This will help later when generating the PDF Report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq7gEArxoqn9"
      },
      "outputs": [],
      "source": [
        "output_list = []\n",
        "\n",
        "def is_string(value):\n",
        "    return isinstance(value, str)\n",
        "\n",
        "def grab_outs(response):\n",
        "  if is_string(response):\n",
        "    output_list.append(response)\n",
        "  else:\n",
        "    for dict in response['output_files']:\n",
        "      if \"code_execution\" in dict[\"name\"]: continue\n",
        "      output_list.append(dict[\"name\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3edqBaVHUaq"
      },
      "source": [
        "You can call the Vertex Code Interpreter Extension to generate plots and graphs on your dataset. However, you can also ask the Extension to take a look at the dataset for you and generate a few ideas for insightful visualizations. The following cell prompts the Code Interpreter Extension to save some plot ideas in the ideas.txt file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6yjvRipGlX3"
      },
      "outputs": [],
      "source": [
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "You are given a dataset of reviews. I want you to come up with some ideas for relevant visualization for this dataset.\n",
        "Create natural language **instructions** and save them into the file ideas.txt\n",
        "Please put your ideas as natural language **instructions** into the file ideas.txt\n",
        "Do not generate any plots yourself.\n",
        "\"\"\", filenames= ['reviews.csv'])\n",
        "process_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFNhqz4Bb5cV"
      },
      "source": [
        "That looks interesting! You could go ahead and parse these ideas automatically by another Code Interpreter call. We will see an optional cell below on how to do that. But for now, we want to reformulate things a bit, so let's go ahead and plot some of the ideas above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyvNv5APRYn_"
      },
      "outputs": [],
      "source": [
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "    You are given a dataset of reviews. Create a pie chart showing the following:\n",
        "    - how many ratings have 'recommended' vs 'not recommended'?\n",
        "    Save the plot with a descriptive name.\n",
        "\"\"\", filenames= ['reviews.csv'])\n",
        "process_response(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ5PFHQWmSNr"
      },
      "outputs": [],
      "source": [
        "# Grab the output if it looks good.\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxPsjO7mJwzd"
      },
      "source": [
        "Easy peasy. But what if we want to generate a more complex plot with the Extension? You can try that with the next cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFsFZN4mU1uN"
      },
      "outputs": [],
      "source": [
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "    You are given a dataset of reviews. The hours_played column contains information on the total hours played, in the format '3,650.6 hrs on record' or '219.6 hrs on record'.\n",
        "    Avoid and handle conversion errors, e.g. 'could not convert string to float: '3,650.6''.\n",
        "    Make a plot that shows the relationship between hours played and the count of the ratings 'Not Recommended'.\n",
        "    Put the hours_played into the different buckets 0-50, 50-100, 100-1000, >1000.\n",
        "    Save the plot with a descriptive name.\n",
        "\n",
        "    Make sure Plots have visible numbers or percentages when applicable, and labels.\n",
        "    Make sure to avoid and handle the error 'Expected value of kwarg 'errors' to be one of ['raise', 'ignore']. Supplied value is 'coerce' '.\n",
        "    Use >>> import warnings\n",
        "    warnings.simplefilter(action='ignore', category=FutureWarning) <<< to avoid any FutureWarnings from pandas.\n",
        "\n",
        "    \"\"\", filenames= ['reviews.csv'])\n",
        "process_response(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDn1ZHbol5Bl"
      },
      "outputs": [],
      "source": [
        "# Grab the output if it looks good.\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrcJUnyETErU"
      },
      "source": [
        "####Optional: Plotting ideas.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFgEjmyyKETT"
      },
      "source": [
        "**OPTIONAL**: You can also parse the plot ideas that Code Interpreter created back and prompt it to generate the plots described in ideas.txt .\n",
        "Code Interpreter may generate some weird plots at this step - this is usually because the instructions are not clearly defined.\n",
        "\n",
        "üí°**Tip**: it works better if you grab the instructions form the ideas.txt file and put them along in the prompt, instead of passing the file over in the filenames.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Q0ntCZvlY0sH"
      },
      "outputs": [],
      "source": [
        "with open('ideas.txt', 'r', encoding='utf-8') as file:\n",
        "    ideas = file.read()\n",
        "\n",
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "    Create and save the following plots.\n",
        "    Make sure each plot is in  its own file and do not overlay multiple plots so for every plot reset the process.\n",
        "    Save the plot with a descriptive name.\n",
        "    Make sure Plots have visible numebers or percentages, when applicable, and labels.\n",
        "    Do not use the library 'wordcloud', it's not available. Skip an idea if it uses wordcloud.\n",
        "    Make sure to avoid 'Rectangle.set() got an unexpected keyword argument 'kind''\n",
        "    Make sure to surpress any user warnings.\n",
        "    **If any of the following produces an exception make sure you catch and print it, and continue to the next item in the list**:\n",
        "    {str(ideas)}\n",
        "\"\"\", filenames= ['reviews.csv'])\n",
        "process_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFUC9V4NKR5V"
      },
      "source": [
        "## Step 3: Use Vertex Search Extension to do a Qualitative Analysis of the Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TaNXRnqL1Lu"
      },
      "source": [
        "### Set Up Qualitative Review Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWO5fNxGe9JX"
      },
      "source": [
        "Grab some more detailed reviews of the game for qualitative analysis. For this, you can use google search to get urls of the top 10 results for the game's reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFMCT89eG7qY"
      },
      "outputs": [],
      "source": [
        "from googlesearch import search\n",
        "\n",
        "# Search\n",
        "query = f\"{game} Reviews\"\n",
        "urls = list()\n",
        "\n",
        "for j in search(query, tld=\"com\", num=10, stop=10, pause=2):\n",
        "    print(j)\n",
        "    urls.append(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNHMCmZJfjdJ"
      },
      "source": [
        "We want vertex search to summarize the contents for us and to answer our questions. To do this, we could manually grab the above URLs and set up a data store for websites in the Google Cloud Console.\n",
        "\n",
        "But, we want to ensure cleaner results. For this reason, first fetch the text contents from the websites, then store the .txt files in your Google Cloud Storage Bucket."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTAhUI7DT8Ek"
      },
      "source": [
        "The following cell lets you grab the contents from the websites and write them into .txt files. Then, these files will be uploaded to your GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqsfwqQdGVq5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "from google.cloud import storage\n",
        "\n",
        "def url_txt_to_gcs(id, url, filename, bucket_name):\n",
        "\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract all text content\n",
        "    all_text = soup.get_text(separator='\\n', strip=True)\n",
        "\n",
        "    # Save to .txt file\n",
        "    with open(filename, \"w\", encoding='utf-8') as file:\n",
        "        file.write(id +\"\\n\"+ all_text)\n",
        "\n",
        "    # Upload\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(filename)\n",
        "\n",
        "    # Assuming the file is in the root of your Colab temp directory\n",
        "    local_temp_path = os.path.join(filename)\n",
        "    blob.upload_from_filename(local_temp_path)\n",
        "\n",
        "    print(f\"File uploaded to gs://{bucket_name}/{filename}\")\n",
        "\n",
        "\n",
        "# Upload the website content .txt files into GCS\n",
        "txt_files = []\n",
        "\n",
        "for idx, url in enumerate(urls):\n",
        "  id = \"doc-\"+str(idx)\n",
        "  filename = f\"website_text_{idx}.txt\"\n",
        "  txt_files.append(f\"website_text_{idx}.txt\")\n",
        "  url_txt_to_gcs(id, url, filename, GCS_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsZUGcCSgMFw"
      },
      "source": [
        "### Create a Search Data Store and Ingest your Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTpr3AoY10Hp"
      },
      "source": [
        "The Vertex Search Extension needs a Data Store to run. The following cells will help you in the setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmKy60yIivpb"
      },
      "outputs": [],
      "source": [
        "# @markdown Specify an id for your datastore. It should only use lowercase letters.\n",
        "data_store_id = \"gamereview-extensions\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwLU9sb6UWvK"
      },
      "source": [
        "Use the following bash command to **create** your Data Store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOLi7KS5gR0P"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$PROJECT_ID\" \"$data_store_id\"\n",
        "\n",
        "curl -X POST \\\n",
        "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-H \"X-Goog-User-Project: $1\" \\\n",
        "\"https://discoveryengine.googleapis.com/v1alpha/projects/$1/locations/global/collections/default_collection/dataStores?dataStoreId=$2\" \\\n",
        "-d '{\n",
        "  \"displayName\": \"GameReview-Extensions-Store\",\n",
        "  \"industryVertical\": \"GENERIC\",\n",
        "  \"solutionTypes\": [\"SOLUTION_TYPE_SEARCH\"],\n",
        "  \"contentConfig\": \"CONTENT_REQUIRED\",\n",
        "}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEMZ-vPVWO9O"
      },
      "source": [
        "üéâ Your Data Store is all set! You can inspect it under: https://console.cloud.google.com/gen-app-builder/data-stores\n",
        "\n",
        "Now you just need to **ingest** your .txt files with the website contents into it by running the cell below.\n",
        "\n",
        "**This process can take somewhere between 5-10 mins**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MT6vj3nr6T8e"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from google.api_core.client_options import ClientOptions\n",
        "from google.cloud import discoveryengine\n",
        "\n",
        "def import_documents_sample(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    data_store_id: str,\n",
        "    gcs_uri: Optional[str] = None,\n",
        "    bigquery_dataset: Optional[str] = None,\n",
        "    bigquery_table: Optional[str] = None,\n",
        ") -> str:\n",
        "    #  For more information, refer to:\n",
        "    # https://cloud.google.com/generative-ai-app-builder/docs/locations#specify_a_multi-region_for_your_data_store\n",
        "    client_options = (\n",
        "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
        "        if location != \"global\"\n",
        "        else None\n",
        "    )\n",
        "\n",
        "    # Create a client\n",
        "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
        "\n",
        "    # The full resource name of the search engine branch.\n",
        "    # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
        "    parent = client.branch_path(\n",
        "        project=project_id,\n",
        "        location=location,\n",
        "        data_store=data_store_id,\n",
        "        branch=\"default_branch\",\n",
        "    )\n",
        "\n",
        "    request = discoveryengine.ImportDocumentsRequest(\n",
        "        parent=parent,\n",
        "        gcs_source=discoveryengine.GcsSource(\n",
        "            input_uris=[gcs_uri], data_schema=\"content\"\n",
        "        ),\n",
        "        # Options: `FULL`, `INCREMENTAL`\n",
        "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,\n",
        "    )\n",
        "\n",
        "\n",
        "    # Make the request\n",
        "    operation = client.import_documents(request=request)\n",
        "\n",
        "    print(f\"Waiting for operation to complete: {operation.operation.name}\")\n",
        "    response = operation.result()\n",
        "\n",
        "    # Once the operation is complete,\n",
        "    # get information from operation metadata\n",
        "    metadata = discoveryengine.ImportDocumentsMetadata(operation.metadata)\n",
        "\n",
        "    # Handle the response\n",
        "    print(response)\n",
        "    print(metadata)\n",
        "\n",
        "    return operation.operation.name\n",
        "\n",
        "\n",
        "gcs_uri = \"gs://extensions-demo-bucket/*.txt\"\n",
        "import_documents_sample(PROJECT_ID, 'global', data_store_id, gcs_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwcBGeljauNR"
      },
      "source": [
        "### Connect Data Store to a Vertex Search Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h87Jzly6ax7d"
      },
      "source": [
        "The following cell let's you create a Vertex Search Engine on top of your newly created Data Store. For the Vertex Search Extension to work, you will need to enable Enterprise features by setting `\"searchTier\": \"SEARCH_TIER_ENTERPRISE\" `and Advanced LLM Features by setting `\"searchAddOns\": [\"SEARCH_ADD_ON_LLM\"]`.\n",
        "\n",
        "‚è∞ **Once you run this cell, you will need to wait an additional 5-10 minutes so the Vertex Search Engine is set up properly. Else your Vertex Search Extension will not be able to identify that the Enterprise features are correctly enabled.**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu8919bNaybd"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$PROJECT_ID\" \"$data_store_id\"\n",
        "\n",
        "curl -X POST \\\n",
        "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-H \"X-Goog-User-Project: $1\" \\\n",
        "\"https://discoveryengine.googleapis.com/v1/projects/$1/locations/global/collections/default_collection/engines?engineId=$2\" \\\n",
        "-d '{\n",
        "  \"displayName\": \"game-review-engine\",\n",
        "  \"dataStoreIds\": [\"'$2'\"],\n",
        "  \"solutionType\": \"SOLUTION_TYPE_SEARCH\",\n",
        "  \"searchEngineConfig\": {\n",
        "     \"searchTier\": \"SEARCH_TIER_ENTERPRISE\",\n",
        "     \"searchAddOns\": [\"SEARCH_ADD_ON_LLM\"]\n",
        "   }\n",
        "}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8n2cU8eXyKD"
      },
      "source": [
        "### Set up the Vertex Search Extension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvcXnnFxX6f-"
      },
      "source": [
        "Your Data Store is all set. Now you just need to create an instance of the Vertex Search Extension by running the cell below.\n",
        "\n",
        "But before, please grant the [Vertex AI Extension Service agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) the [permission needed](https://cloud.google.com/vertex-ai/docs/general/access-control#home-project). In this case, you need permissions to run discovery engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXggbziVKPC2"
      },
      "outputs": [],
      "source": [
        "# Construct an object that points to the relevant data store\n",
        "DATASTORE = f\"projects/{PROJECT_ID}/locations/global/collections/default_collection/dataStores/{data_store_id}/servingConfigs/default_search\"\n",
        "\n",
        "# Instantiate extension\n",
        "extension_vertex_ai_search = extensions.Extension.from_hub(\n",
        "    \"vertex_ai_search\",\n",
        "    runtime_config={\n",
        "        \"vertex_ai_search_runtime_config\": {\n",
        "            \"serving_config_name\": DATASTORE,\n",
        "        }\n",
        "    })\n",
        "\n",
        "extension_vertex_ai_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WcNCzR5NgEG"
      },
      "source": [
        "The following is a helper function. We can let the Vertex Search Engine generate an answer for our prompt directly. However, for a more descriptive response, we get retrieve the segment matches provided by the Vertex Search Engine and let Gemini generate an answer over it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zCrkC_OgJjY"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.generative_models import GenerativeModel, Part\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
        "\n",
        "# Helper function\n",
        "def get_vertexSearch_response(QUERY, mode):\n",
        "  vertex_ai_search_response = extension_vertex_ai_search.execute(\n",
        "    operation_id = \"search\",\n",
        "    operation_params = {\"query\": QUERY},\n",
        "  )\n",
        "\n",
        "  # Let Vertex Search Extension generate a response\n",
        "  if mode == 'vertex':\n",
        "    list_extractive_answers = []\n",
        "    for i in vertex_ai_search_response:\n",
        "      list_extractive_answers.append(i[\"extractive_answers\"][0])\n",
        "      return list_extractive_answers\n",
        "\n",
        "\n",
        "  # Let Gemini generate a response over the Vertex Search Extension segments\n",
        "  else:\n",
        "    list_extractive_segments = []\n",
        "\n",
        "    for i in vertex_ai_search_response:\n",
        "      list_extractive_segments.append(i[\"extractive_segments\"][0])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Prompt: {QUERY};\n",
        "    Contents: {str(list_extractive_segments)}\n",
        "    \"\"\"\n",
        "\n",
        "    res = model.generate_content(\n",
        "        prompt,\n",
        "        generation_config={\n",
        "            \"max_output_tokens\": 2048,\n",
        "            \"temperature\": 0.1,\n",
        "            \"top_p\": 1\n",
        "        },\n",
        "        safety_settings={\n",
        "              generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "              generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "              generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "              generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "        },\n",
        "        stream=False,\n",
        "      )\n",
        "\n",
        "    return res.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G-jUjCjOsSk"
      },
      "source": [
        "### Use Vertex Search Extension to answer Questions and retrieve Summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrT-HTS3POFg"
      },
      "source": [
        "Now you can run Vertex Search Extension. The cell below demonstrates an output of Vertex Search Engine without Gemini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgX31Eug83YV"
      },
      "outputs": [],
      "source": [
        "QUERY = f\"What are some negative review points for {game}?\" # @param {type:\"string\"}\n",
        "\n",
        "search_res = get_vertexSearch_response(QUERY, mode='vertex')\n",
        "\n",
        "search_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-U047_vPZYe"
      },
      "source": [
        "The output below highlights the differences between the pure Vertex Search Extension output, and the hybrid response generated with Gemini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSPriyrGjXdo"
      },
      "outputs": [],
      "source": [
        "QUERY = f\"List 10 positive review points for {game}\" # @param {type:\"string\"}\n",
        "\n",
        "response = get_vertexSearch_response(QUERY, mode='gemini')\n",
        "\n",
        "print(response)\n",
        "\n",
        "# Grab the output for report generation\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQvZPXx7PlsS"
      },
      "source": [
        "Looks good. Collect more information from the website contents by giving the extension some more prompts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TNJ2BddhiWw"
      },
      "outputs": [],
      "source": [
        "QUERY = f\"List 10 negative review points for {game}\" # @param {type:\"string\"}\n",
        "\n",
        "response = get_vertexSearch_response(QUERY, mode='gemini')\n",
        "\n",
        "response\n",
        "\n",
        "# Grab the output for report generation\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26YnYGWtPsIn"
      },
      "outputs": [],
      "source": [
        "QUERY = f\"Provide a summary description of the game {game}\" # @param {type:\"string\"}\n",
        "\n",
        "response = get_vertexSearch_response(QUERY, mode='gemini')\n",
        "\n",
        "response\n",
        "\n",
        "# Grab the output for report generation\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAkfc7-i3hdg"
      },
      "source": [
        "## Step 4: Populate your Results in a PDF Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8EKZ_SRky90"
      },
      "source": [
        "Now it's time to put everything together. We have collected the generated responses (both images and texts) from Vertex Code Interpreter and Search Extensions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8KCzXfMuZx6"
      },
      "outputs": [],
      "source": [
        "output_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxXQX2Lu0fm7"
      },
      "source": [
        "Upload the images to GCS to get a public URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9sQ7kKx0qjE"
      },
      "outputs": [],
      "source": [
        "imgs_files = []\n",
        "txt_outs = []\n",
        "\n",
        "for element in output_list:\n",
        "  if \".png\" in element or \".jpg\" in element or \".jpeg\" in element:\n",
        "    # Get image filenames\n",
        "    imgs_files.append(element)\n",
        "  else:\n",
        "    # Get text outputs\n",
        "    txt_outs.append(element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCFYcWiH0qhK"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "def upload_to_gcs(local_file, bucket_name, blob_name):\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_filename(local_file)\n",
        "\n",
        "def get_public_url(bucket_name, blob_name):\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    return blob.public_url\n",
        "\n",
        "# Upload to GCS\n",
        "bucket_name = GCS_BUCKET\n",
        "\n",
        "gcs_img_files = []\n",
        "\n",
        "for image in imgs_files:\n",
        "  # Upload Image\n",
        "  upload_to_gcs(image, bucket_name, image)\n",
        "\n",
        "  # Get Image public URL\n",
        "  public_image_url = get_public_url(bucket_name, image)\n",
        "  gcs_img_files.append(public_image_url)\n",
        "  print(public_image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d6S-S2CRQfD"
      },
      "source": [
        "### Generate the Report with Vertex Code Interpreter Extension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpbQpB8wQlXv"
      },
      "source": [
        "With the collected text outputs and the public URLs of the images, you can ask Code Interpreter Extension to generate a compelling PDF Report. For this, let it generate a .html file first - you can convert it to PDF in the next cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DerzVD39k2oM"
      },
      "outputs": [],
      "source": [
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "    You are a report generator. Given a list of filenames and strings, create an interesting report in html language and save it to report.html.\n",
        "    The report revolves around reviews for the game {game}.\n",
        "\n",
        "    Structure the report with proper headings. Don't use 'String' as a heading.\n",
        "    Write the whole report in natural language. You are allowed to use bullet points.\n",
        "    Start the report with a summary of the game {game}\n",
        "    Embed the images directly in the html and include image descriptions.\n",
        "\n",
        "    The contents you can use are these, including images (the filenames indicate the image content):\n",
        "    {gcs_img_files}\n",
        "\n",
        "    And string contents:\n",
        "    {txt_outs}\n",
        "    \"\"\")\n",
        "process_response(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu7Oc0QX2dt-"
      },
      "source": [
        "Convert the html to a .pdf file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDq5ooVd_iSk"
      },
      "outputs": [],
      "source": [
        "from weasyprint import HTML, CSS\n",
        "\n",
        "with open('report.html', 'r') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "pdf = HTML(string=html_content).write_pdf()\n",
        "\n",
        "# Optional: Save the PDF file\n",
        "with open('report.pdf', 'wb') as file:\n",
        "    file.write(pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAERYURKx6Me"
      },
      "source": [
        "Now, push your new PDF Report to your Google Drive Storage. The following cells will set up a new folder for your asset, and push the report in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWsSrRt1RteH"
      },
      "outputs": [],
      "source": [
        "# @markdown Provide the folder name on Google Drive where the PDF should be saved into:\n",
        "\n",
        "folder_name = 'extensions-demo-assets' # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdlpIvw6vb5d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "def create_folder(folder_name):\n",
        "    drive_service = build('drive', 'v3', credentials=creds)  # Assuming credentials are set up\n",
        "\n",
        "    file_metadata = {\n",
        "        'name': folder_name,\n",
        "        'mimeType': 'application/vnd.google-apps.folder'\n",
        "    }\n",
        "    folder = drive_service.files().create(body=file_metadata, fields='id').execute()\n",
        "    return folder.get('id')\n",
        "\n",
        "def upload_file(file_path, folder_id):\n",
        "    drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "    file_metadata = {\n",
        "        'name': os.path.basename(file_path),\n",
        "        'parents': [folder_id]\n",
        "    }\n",
        "\n",
        "    # Determine MIME type based on file extension\n",
        "    extension = os.path.splitext(file_path)[1].lower()\n",
        "    if extension in ['.jpg', '.jpeg', '.png']:\n",
        "        mime_type = 'image/jpeg'  # Adjust for other image types if needed\n",
        "    elif extension == '.pdf':\n",
        "        mime_type = 'application/pdf'\n",
        "    else:\n",
        "        mime_type = 'application/octet-stream'  # Generic fallback\n",
        "\n",
        "    media = MediaFileUpload(file_path, mimetype=mime_type, resumable=True)\n",
        "    file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "    print(f'File uploaded to Drive: {file.get(\"id\")}')\n",
        "\n",
        "    return file.get(\"id\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzJv8YrlAqj5"
      },
      "outputs": [],
      "source": [
        "# Create your folder\n",
        "folder_id = create_folder(folder_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT8PpUlISFQw"
      },
      "source": [
        "Lastly, upload your report.pdf to your new Google Drive Folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uVEcbkdAq4q"
      },
      "outputs": [],
      "source": [
        "file_id = upload_file('report.pdf', folder_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8gZtlqZnvH4"
      },
      "source": [
        "## [OPTIONAL]¬†Step 5: Send Report via Email\n",
        "\n",
        "This section shows how you can grab your generated pdf report and send it via GMail to a specified recipient.\n",
        "\n",
        "For this to work, you need to configure the GMail API and credentials first.\n",
        "Follow the \"Quickstart Guide\" for Python: https://developers.google.com/gmail/api/quickstart/python\n",
        "\n",
        "Steps:\n",
        "- Enable the Gmail API in your Google Cloud Project\n",
        "- Set up the OAuth as described in the document; set the scope for your app to allow gmail.send\n",
        "- In the OAuth settings, set ¬¥https://localhost:8080/¬¥ in **Authorized redirect URI**\n",
        "- Download the client secret json and rename it to credentials.json\n",
        "- Upload the json to colab through the file system on the left panel\n",
        "\n",
        "\n",
        "After that, you can run the following cells below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDxWXDdIyt9m"
      },
      "source": [
        "Grab the contents of the pdf report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZcwa89bkl5o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_pdf_file(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        pdf_data = f.read()\n",
        "    return pdf_data\n",
        "\n",
        "pdf_filename = \"report.pdf\"  # Path to your PDF in Colab\n",
        "pdf_data = read_pdf_file(pdf_filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rXqEyxfyxs_"
      },
      "source": [
        "Parse the pdf contents into a raw message for the e-mail attachment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1c4Az0Lkl2_"
      },
      "outputs": [],
      "source": [
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "import base64\n",
        "\n",
        "def create_message_with_attachment(sender, to, subject, body, filename, attachment):\n",
        "    message = MIMEMultipart()\n",
        "    message['to'] = to\n",
        "    message['from'] = sender\n",
        "    message['subject'] = subject\n",
        "\n",
        "    msg_body = MIMEText(body, 'plain')\n",
        "    message.attach(msg_body)\n",
        "\n",
        "    part = MIMEBase('application', 'octet-stream')  # For PDFs\n",
        "    part.set_payload(attachment)\n",
        "    encoders.encode_base64(part)\n",
        "    part.add_header('Content-Disposition', f'attachment; filename={filename}')\n",
        "    message.attach(part)\n",
        "\n",
        "    raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
        "    return {'raw': raw_message}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GuNuRmXy6ud"
      },
      "source": [
        "### Setting up e-mail configuration\n",
        "Provide the recipient and run the next cell to get a API token for accessing GMail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWgbAgUYopXq"
      },
      "outputs": [],
      "source": [
        "# Provide the details for constructing your e-mail\n",
        "\n",
        "recipient = 'msubasioglu@google.com' #@param {type: 'string'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ic38FaEis1k-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2 import credentials\n",
        "\n",
        "SCOPES = ['https://mail.google.com/', 'https://www.googleapis.com/auth/gmail.send']\n",
        "\n",
        "creds = None\n",
        "# Token file typically stores credentials for reuse\n",
        "token_file = 'token.json'\n",
        "\n",
        "# Check if authorized credentials exist\n",
        "if os.path.exists(token_file):\n",
        "    creds = credentials.from_authorized_user_file(token_file, SCOPES)\n",
        "# If not, or credentials are invalid, trigger the authorization flow\n",
        "if not creds or not creds.valid:\n",
        "  if creds and creds.expired and creds.refresh_token:\n",
        "      creds.refresh(Request())\n",
        "  else:\n",
        "      flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES, redirect_uri='https://localhost:8080/')\n",
        "      auth_url = flow.authorization_url()[0]  # Get the authorization URL\n",
        "      print(f\"Open this URL to authorize: {auth_url}\")\n",
        "      print(\"Enter the authorization code:\")\n",
        "      code = input()\n",
        "      creds = flow.fetch_token(code=code)\n",
        "\n",
        "\n",
        "# Build the Gmail API service object\n",
        "service = build('gmail', 'v1', credentials=creds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lp54MYkzGgM"
      },
      "source": [
        "### Send the e-mail\n",
        "Now that you have your API token, you can send the e-mail with the attached pdf report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnViq7pXkl1D"
      },
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Provide the details for constructing your e-mail\n",
        "subject = f\"{game} Review Analysis Report\"\n",
        "body = f\"Attached is the Report on the Review Analysis for {game}\"\n",
        "\n",
        "# Construct e-mail\n",
        "message = create_message_with_attachment('me', recipient,\n",
        "                                          subject, body,\n",
        "                                          pdf_filename, pdf_data)\n",
        "\n",
        "# Send e-mail\n",
        "service.users().messages().send(userId='me', body=message).execute()\n",
        "print(\"Email sent!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co10z50ugMF3"
      },
      "source": [
        "# Cleaning up\n",
        "\n",
        "Clean up extension resources created in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1pyDrUuSOg8"
      },
      "source": [
        "You can run the next cell to get a list of all Vertex Extension Instances in your environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTEgYGhFQfTW"
      },
      "outputs": [],
      "source": [
        "extensions.Extension.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove the extensions instances created in this notebook: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extension_code_interpreter.delete()\n",
        "extension_vertex_ai_search.delete() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihJEWJvNSfc9"
      },
      "source": [
        "Alternatively, you can uncomment the following code block to delete all active extensions in your project, by using the IDs above to clean up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsPKKv-USmi-"
      },
      "outputs": [],
      "source": [
        "# clean_ids = []\n",
        "\n",
        "# for element in extensions.Extension.list():\n",
        "#   clean_ids.append(str(element).split(\"extensions/\")[1])\n",
        "\n",
        "# for id in clean_ids:\n",
        "#   extension = extensions.Extension(id)\n",
        "#   extension.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuJs4q0oThE3"
      },
      "source": [
        "Don't forget to delete any created assets if you don't need them, e.g.\n",
        "\n",
        "\n",
        "*   Files in your Colab Environment\n",
        "*   PDF Report in your Google Drive folder\n",
        "*   Your Vertex Search Engine: https://console.cloud.google.com/gen-app-builder/apps\n",
        "*   Your Data Store: https://console.cloud.google.com/gen-app-builder/data-stores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaXXzExFTlje"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
