{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title LICENSE\n",
        "\n",
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration & Model Training with Vertex AI Extensions Code Interpreter\n"
      ],
      "metadata": {
        "id": "ZJ5caKL2Ff2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/applied-ai-engineering-samples/blob/main/genai-on-vertex-ai/vertex_ai_extensions/notebooks/data_science_code_interpreter.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fapplied-ai-engineering-samples%2Fblob%2Fmain%2Fgenai-on-vertex-ai%2Fvertex_ai_extensions%2Fnotebooks%2Fdata_science_code_interpreter.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/applied-ai-engineering-samples/blob/main/genai-on-vertex-ai/vertex_ai_extensions/notebooks/data_science_code_interpreter.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/applied-ai-engineering-samples/blob/main/genai-on-vertex-ai/vertex_ai_extensions/notebooks/data_science_code_interpreter.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "5Qj-TzSNGUii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| | |\n",
        "|----------|-------------|\n",
        "| Authors   | Christos Aniftos |\n",
        "| | Michael W. Sherman |\n",
        "| Reviewer | Meltem Subasioglu |\n",
        "| Last updated | 2024 04 09: Initial release |\n",
        "| | 2024 04 04: Complete draft |"
      ],
      "metadata": {
        "id": "ocycMnwJGUii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "This notebook shows how to use the [Vertex AI Extensions](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/overview) Google-provided [Code Interpreter Extension](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/google-extensions.md#code_interpreter_extension) to do standard data science tasks like analyzing a dataset and training an ML model. As a data scientist, Code Interpreter can save you time getting up and running with a new dataset.\n",
        "\n",
        "In this notebook you will use Code Interpreter to:\n",
        "- Explore data\n",
        "- Clean data\n",
        "- Visualise data\n",
        "- Train a linear regression model\n",
        "- Generate predictions using that model.\n",
        "- Evaluate the predictions against the ground truth"
      ],
      "metadata": {
        "id": "FlkJDD0nGUij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If you're already familiar with Google Cloud and the Vertex AI Extensions Code Interpreter Extension**, you can skip reading between here and the \"Create the Data\" section, but make sure to run the code cells."
      ],
      "metadata": {
        "id": "ZIBXCGNGfPKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vertex AI Extensions\n",
        "\n",
        "[Vertex AI Extensions](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/overview) is a platform for creating and managing extensions that connect large language models to external systems via APIs. These external systems can provide LLMs with real-time data and perform data processing actions on their behalf. You can use pre-built or third-party extensions in Vertex AI Extensions."
      ],
      "metadata": {
        "id": "KUXzlvfpn513"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vertex AI Extensions Code Interpreter Extension\n",
        "\n",
        "The [Code Interpreter](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/google-extensions.md#code_interpreter_extension) extension provides access to a Python interpreter with a sandboxed, secure execution environment that can be used with any model in the Vertex AI Model Garden. This extension can generate and execute code in response to a user query or workflow. It allows the user or LLM agent to perform various tasks such as data analysis and visualization on new or existing data files.\n",
        "\n",
        "You can use the Code Interpreter extension to:\n",
        "\n",
        "* Generate and execute code.\n",
        "* Perform a wide variety of mathematical calculations.\n",
        "* Sort, filter, select the top results, and otherwise analyze data (including data acquired from other tools and APIs).\n",
        "* Create visualizations, plot charts, draw graphs, shapes, print results, etc."
      ],
      "metadata": {
        "id": "3r29fUEFn8JH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using this Notebook\n",
        "\n",
        "Colab is recommended for running this notebook, but it can run in any iPython environment where you can connect to Google Cloud, install pip packages, etc.\n",
        "\n",
        "If you're running outside of Colab, depending on your environment you may need to install pip packages that are included in the Colab environment by default but are not part of the Python Standard Library. You'll also notice some comments in code cells that look like #@something -- these may contain informative text\n",
        "\n",
        "This tutorial uses the following Google Cloud services and resources:\n",
        "\n",
        "* Vertex AI Extensions\n",
        "\n",
        "This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.10.12\n",
        "* [google-cloud-aiplatform](https://pypi.org/project/google-cloud-aiplatform/) version = 1.47.0"
      ],
      "metadata": {
        "id": "uNriTZl70OdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Useful Tips\n",
        "\n",
        "1. This notebook uses Generative AI cababilities. Re-running a cell that uses Generative AI capabilities may produce similar but not identical results.\n",
        "2. Because of #1, it is possible that an output from Code Interpreter producess errors. If that happens re-run the cell that produced the coding error. The different generated code will likely be bug free. The `run_code_interpreter` method below helps automate this.\n",
        "3. The use of Extensions and other Generative AI capabilities is subject to service quotas. Running the notebook using \"Run All\" may exceed  your Queries per minute (QPM) limitations. Run the notebook manually and if you get a quota error pause for up to 1 minute before retrying that cell. Code Interpreter uses Gemini on the backend and is subject to the Gemini quotas, [view your Gemini quotas here](https://console.cloud.google.com/iam-admin/quotas?pageState=(%22allQuotasTable%22:(%22f%22:%22%255B%257B_22k_22_3A_22_22_2C_22t_22_3A10_2C_22v_22_3A_22_5C_22base_model_5C_22_22%257D_2C%257B_22k_22_3A_22_22_2C_22t_22_3A10_2C_22v_22_3A_22_5C_22gemini_5C_22_22%257D%255D%22%29%29&e=13802955&mods=logs_tg_staging).\n",
        "4. The Code Interpreter Extension is stateless and therefore every request to Code Interpreter does not have knowledge of previous operations nor files injested or produced in previous steps. Therefore, with any request to Code Interpreter you need to submit all files and instructions for that request to complete successfully.\n",
        "5. When doing data science tasks with Code Interpreter, often the pandas library will be used, and common ways of using pandas generate a lot of warnings. Related to number 2 above, you'll want to make sure you don't necessarily automatically rerun code that generates warnings. One way to handle this is to instruct Code Interpreter to use the Python `warnings` library to supress warnings."
      ],
      "metadata": {
        "id": "Ar0aDcql1dxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "\n",
        "The following steps are necessary to run this notebook, no matter what notebook environment you're using.\n",
        "\n",
        "If you're entirely new to Google Cloud, [get started here](https://cloud.google.com/docs/get-started)."
      ],
      "metadata": {
        "id": "PO_tnShTGUik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Cloud Project Setup\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "1. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)."
      ],
      "metadata": {
        "id": "XLf5oGqHn_DH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Cloud Permissions\n",
        "Make sure you have been [granted the following roles](https://cloud.google.com/iam/docs/granting-changing-revoking-access) for the GCP project you'll access from this notebook:\n",
        "* [`roles/aiplatform.user`](https://cloud.google.com/vertex-ai/docs/general/access-control#aiplatform.user)"
      ],
      "metadata": {
        "id": "PTuXDJ2qn-8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Google Cloud Vertex AI Python SDK\n",
        "\n",
        "If you already have the Google Cloud Vertex AI Python SDK installed, upgrade to the latest version."
      ],
      "metadata": {
        "id": "JdU-qMmbpR8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform --upgrade"
      ],
      "metadata": {
        "id": "lHEI7wZMhZPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "You may need to restart your notebook runtime to use the Vertex AI SDK. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "You may see the restart reported as a crash, but it is working as-intended -- you are merely restarting the runtime.\n",
        "\n",
        "The restart might take a minute or longer. After its restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're using Colab, as long the notebook runtime isn't deleted (even if it restarts) you don't need to re-run the previous cell.\n",
        "\n",
        "If you're running this notebook in your own environment you shouldn't need to run the previous cell again unless you delete your IPython kernel."
      ],
      "metadata": {
        "id": "mCG23ih_sJr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate\n",
        "\n",
        "If you're using Colab, run the code in the next cell. Follow the popups and authenticate with an account that has access to your Google Cloud [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects).\n",
        "\n",
        "If you're running this notebook somewhere besides Colab, make sure your environment has the right Google Cloud access. If that's a new concept to you, consider looking into [Application Default Credentials for your local environment](https://cloud.google.com/docs/authentication/provide-credentials-adc#local-dev) and [initializing the Google Cloud CLI](https://cloud.google.com/docs/authentication/gcloud). More authentication options are discussed [here](https://cloud.google.com/docs/authentication)."
      ],
      "metadata": {
        "id": "7plalcaLGUik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab authentication.\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    print('Authenticated')"
      ],
      "metadata": {
        "id": "THYfMKWMGUil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "# Initialize the Google Cloud Vertex AI Python SDK\n",
        "\n",
        "Start here if your Notebook kernel restarts (but isn't deleted), though if it's been a few hours you may need to run the Authentication steps above again.\n",
        "\n",
        "To initialize the SDK, you need to set your Google Cloud project ID and region.\n",
        "\n",
        "If you don't know your project  ID, try the [Google Cloud CLI](https://cloud.google.com/sdk) commands [`gcloud config list`](https://cloud.google.com/sdk/gcloud/reference/config/list) or [`gcloud projects list`](https://cloud.google.com/sdk/gcloud/reference/projects/list). See the support page [Locate the project ID](https://support.google.com/googleapi/answer/7014113) for more information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "### Set Your Project ID\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"YOUR_PROJECT_ID_ HERE\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "### Set the Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg9uNa6rlyWx"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the Vertex AI Python SDK"
      ],
      "metadata": {
        "id": "3fadEmDvz04h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.preview import extensions\n",
        "\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION\n",
        ")"
      ],
      "metadata": {
        "id": "KhnzTqS8iOJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXzY2nqRlyWy"
      },
      "source": [
        "Now that you've imported the Code Interpreter Extension, let's confirm that it's registered:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Test the Code Interpreter Extension\n",
        "\n",
        "Code Interpreter is provided by Google, so you can load it directly."
      ],
      "metadata": {
        "id": "NIZnIItkxeb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extension_code_interpreter = extensions.Extension.from_hub(\"code_interpreter\")\n",
        "extension_code_interpreter"
      ],
      "metadata": {
        "id": "6zAMy-Ndinbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqlgusC10Es3"
      },
      "source": [
        "Confirm your Code Interpreter extension is registered:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAxsJvBh0Es3"
      },
      "outputs": [],
      "source": [
        "print(\"Name:\", extension_code_interpreter.gca_resource.name)\n",
        "print(\"Display Name:\", extension_code_interpreter.gca_resource.display_name)\n",
        "print(\"Description:\", extension_code_interpreter.gca_resource.description)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Code Interpreter\n",
        "\n",
        "To test Code Interpreter, ask it to generate a basic plot from a small dataset."
      ],
      "metadata": {
        "id": "MejOedOYxc1O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkgY1Ji-lyWz"
      },
      "outputs": [],
      "source": [
        "QUERY = \"\"\"\n",
        "Using the data below, construct a bar chart that includes only the height values with different colors for the bars:\n",
        "\n",
        "tree_heights_prices = {\n",
        "  \\\"Pine\\\": {\\\"height\\\": 100, \\\"price\\\": 100},\n",
        "  \\\"Oak\\\": {\\\"height\\\": 65, \\\"price\\\": 135},\n",
        "  \\\"Birch\\\": {\\\"height\\\": 45, \\\"price\\\": 80},\n",
        "  \\\"Redwood\\\": {\\\"height\\\": 200, \\\"price\\\": 200},\n",
        "  \\\"Fir\\\": {\\\"height\\\": 180, \\\"price\\\": 162},\n",
        "}\n",
        "\n",
        "Please include the data in the generated code.\n",
        "\"\"\"\n",
        "\n",
        "response = extension_code_interpreter.execute(\n",
        "    operation_id = \"generate_and_execute\",\n",
        "    operation_params = {\"query\": QUERY},\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, dig deeper into the returned `response` object. `pprint` more clearly shows the generated code:"
      ],
      "metadata": {
        "id": "9zfhZvJrzh8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(response)"
      ],
      "metadata": {
        "id": "eEwauD0Xyzru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll notice the `response` object has an `output_files` object that contains files you'll want to extract.\n",
        "\n",
        "In the next section you'll create some helper functions that make it easier to work with Code Interpreter's `response` object."
      ],
      "metadata": {
        "id": "aZB4ZDEmyzLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Interpreter Helper Functions\n",
        "\n",
        "These functions are optional when using Code Interpreter but make it easier to inspect Code Interpreter's output, assemble Code Interprer requests, and run generated code."
      ],
      "metadata": {
        "id": "NLE3wb5VfhJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `process_response`\n",
        "\n",
        "`process_response` displays the generated code and any output files, shows the output from code execution, surfaces code execution errors, and saves output files.\n",
        "\n",
        "**To use this functionality** call `process_response(response)` \\\n",
        "where `response` is the Code Interpreter `response` object.\n"
      ],
      "metadata": {
        "id": "9NnhQmFLAHXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import json\n",
        "import pprint\n",
        "import pandas\n",
        "import sys\n",
        "import IPython\n",
        "if sys.version_info[0] < 3:\n",
        "    from StringIO import StringIO\n",
        "else:\n",
        "    from io import StringIO\n",
        "\n",
        "css_styles = \"\"\"\n",
        "<style>\n",
        ".main_summary {\n",
        "  font-weight: bold;\n",
        "  font-size: 14px; color: #4285F4;\n",
        "  background-color:rgba(221, 221, 221, 0.5); padding:8px;}\n",
        ".main_summary:hover {background-color: rgba(221, 221, 221, 1);}\n",
        "details {\n",
        "  background-color:#fff;\n",
        "  border: 1px solid #E8EAED;\n",
        "  padding:0px;\n",
        "  margin-bottom:2px; }\n",
        "details img {width:50%}\n",
        "details > div {padding:10px; }\n",
        "div#left > * > div {\n",
        "    overflow:auto;\n",
        "    max-height:400px; }\n",
        "\n",
        "div#right > pre {\n",
        "    overflow:auto;\n",
        "    max-height:600px;\n",
        "    background-color: ghostwhite;\n",
        "    padding: 10px; }\n",
        "details details > div { overflow: scroll; max-height:400px}\n",
        "details details {\n",
        "  background-color:rgba(246, 231, 217, 0.2);\n",
        "  border: 1px solid #FBBC04;}\n",
        "details details > summary {\n",
        "  padding: 8px;\n",
        "  background-color:rgba(255, 228, 196, 0.6); }\n",
        "details details > summary:hover { background-color:rgba(255, 228, 196, 0.9); }\n",
        "div#left {width: 64%; padding:0 1%;  }\n",
        "div#right {\n",
        "  border-left: 1px solid silver;\n",
        "  width: 30%;\n",
        "  float: right;\n",
        "  padding:0 1%; }\n",
        "body {color: #000; background-color: white; padding:10px 10px 40px 10px; }\n",
        "#main { border: 1px solid #FBBC04; padding:10px 0; display: flow-root; }\n",
        "h3 {color: #000; }\n",
        "code  { font-family: monospace; color: #900; padding: 0 2px; font-size: 105%; }\n",
        "</style>\n",
        "        \"\"\"\n",
        "\n",
        "# Parser to visualise the content of returned files as HTML.\n",
        "def parse_files_to_html(outputFiles, save_files_locally = True):\n",
        "    IMAGE_FILE_EXTENSIONS = set([\"jpg\", \"jpeg\", \"png\"])\n",
        "    file_list = []\n",
        "    details_tml = \"\"\"<details><summary>{name}</summary><div>{html_content}</div></details>\"\"\"\n",
        "\n",
        "    if not outputFiles:\n",
        "      return \"No Files generated from the code\"\n",
        "    # Sort output_files so images are displayed before other files such as JSON.\n",
        "    for output_file in sorted(\n",
        "        outputFiles,\n",
        "        key=lambda x: x[\"name\"].split(\".\")[-1] not in IMAGE_FILE_EXTENSIONS,\n",
        "    ):\n",
        "        file_name = output_file.get(\"name\")\n",
        "        file_contents = base64.b64decode(output_file.get(\"contents\"))\n",
        "        if save_files_locally:\n",
        "          open(file_name,\"wb\").write(file_contents)\n",
        "\n",
        "        if file_name.split(\".\")[-1] in IMAGE_FILE_EXTENSIONS:\n",
        "            # Render Image\n",
        "            file_html_content = ('<img src=\"data:image/png;base64, '\n",
        "                                f'{output_file.get(\"contents\")}\" />')\n",
        "        elif file_name.endswith(\".json\"):\n",
        "            # Pretty print JSON\n",
        "            json_pp = pprint.pformat(\n",
        "                        json.loads(file_contents.decode()),\n",
        "                        compact=False,\n",
        "                        width=160)\n",
        "            file_html_content =  (f'<span>{json_pp}</span>')\n",
        "        elif file_name.endswith(\".csv\"):\n",
        "            # CSV\n",
        "            csv_md = pandas.read_csv(\n",
        "                  StringIO(file_contents.decode())).to_markdown(index=False)\n",
        "            file_html_content = f'<span>{csv_md}</span>'\n",
        "        elif file_name.endswith(\".pkl\"):\n",
        "            # PKL\n",
        "            file_html_content = f'<span>Preview N/A</span>'\n",
        "        else:\n",
        "            file_html_content = f\"<span>{file_contents.decode()}</span>\"\n",
        "\n",
        "        file_list.append({'name': file_name, \"html_content\": file_html_content})\n",
        "\n",
        "    buffer_html = [ details_tml.format(**_file) for _file in file_list ]\n",
        "    return \"\".join(buffer_html)\n",
        "\n",
        "# Processing code interpreter response to html visualization.\n",
        "def process_response(response: dict, save_files_locally = True) -> None:\n",
        "\n",
        "  result_template = \"\"\"\n",
        "  <details open>\n",
        "    <summary class='main_summary'>{summary}:</summary>\n",
        "    <div><pre>{content}</pre></div>\n",
        "  </details>\n",
        "  \"\"\"\n",
        "\n",
        "  result = \"\"\n",
        "  code = response.get('generated_code')\n",
        "  if 'execution_result' in response and response['execution_result']!=\"\":\n",
        "    result = result_template.format(\n",
        "        summary=\"Executed Code Output\",\n",
        "        content=response.get('execution_result'))\n",
        "  else:\n",
        "    result = result_template.format(\n",
        "      summary=\"Executed Code Output\",\n",
        "      content=\"Code does not produce printable output.\")\n",
        "\n",
        "  if response.get('execution_error', None):\n",
        "    result += result_template.format(\n",
        "        summary=\"Generated Code Raised a (Possibly Non-Fatal) Exception\",\n",
        "        content=response.get('execution_error', None))\n",
        "\n",
        "  result += result_template.format(\n",
        "    summary=\"Files Created <u>(Click on filename to view content)</u>\",\n",
        "    content=parse_files_to_html(\n",
        "        response.get('output_files', []),\n",
        "        save_files_locally = True))\n",
        "\n",
        "  display(\n",
        "      IPython.display.HTML(\n",
        "        ( f\"{css_styles}\"\n",
        "f\"\"\"\n",
        "<div id='main'>\n",
        "    <div id=\"right\">\n",
        "      <h3>Generated Code by Code Interpreter</h3>\n",
        "      <pre><code>{code}</code></pre>\n",
        "    </div>\n",
        "    <div id=\"left\">\n",
        "      <h3>Code Execution Results</h3>\n",
        "      {result}\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "        )\n",
        "      )\n",
        "  )"
      ],
      "metadata": {
        "id": "ATDcBTSRIVen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `run_code_interpreter`\n",
        "`run_code_interpreter` eases calling Code Interpreter by encoding files to base 64 (a Code Interpreter requirement) and submitting the files alongside the instructions. It also automates retries (5 by default) if the generated code doesn't execute or if Code Interpreter fails due to exceeding Gemini (time-based) quotas. Additionally, a global `CODE_INTERPRETER_WRITTEN_FILES` variable is populated by `run_code_interpreter` to aid with cleaning up files created by code intprereter.\n",
        "\n",
        "**To use this functionality**  call `run_code_interpreter(instructions, filenames, retry_num)`\n",
        "where `instructions` is the prompt for Code Interpreter, `filenames` is a list of local files in the working directory to submit to Code Interpreter, and optionally `retry_num` if you want to change the default number of retries from 5 and `retry_wait_time` if you want to change the default 15 second wait between retries."
      ],
      "metadata": {
        "id": "9UYWV1OYEYz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "\n",
        "global CODE_INTERPRETER_WRITTEN_FILES\n",
        "CODE_INTERPRETER_WRITTEN_FILES = []\n",
        "\n",
        "def run_code_interpreter(instructions: str,\n",
        "                         filenames: list[dict] = [],\n",
        "                         retry_num: int = 5,\n",
        "                         retry_wait_time: int = 15) -> dict['str', 'str']:\n",
        "\n",
        "  global CODE_INTERPRETER_WRITTEN_FILES\n",
        "\n",
        "  file_arr = [\n",
        "      {\n",
        "          \"name\": filename,\n",
        "          \"contents\":  base64.b64encode(open(filename, \"rb\").read()).decode()\n",
        "      }\n",
        "      for filename in filenames\n",
        "  ]\n",
        "\n",
        "  attempts = 0\n",
        "  res = {}\n",
        "\n",
        "  while attempts <= retry_num:\n",
        "    attempts += 1\n",
        "\n",
        "    res = extension_code_interpreter.execute(\n",
        "        operation_id = \"generate_and_execute\",\n",
        "        operation_params = {\n",
        "            \"query\": instructions,\n",
        "            \"files\": file_arr\n",
        "        },\n",
        "    )\n",
        "\n",
        "    CODE_INTERPRETER_WRITTEN_FILES.extend(\n",
        "        [item['name'] for item in res['output_files']])\n",
        "\n",
        "    if not res.get('execution_error', None):\n",
        "      return res\n",
        "    elif attempts <= retry_num:\n",
        "      print(f\"The generated code produced an error {res.get('execution_error')}\"\n",
        "            f\" -Automatic retry attempt # {attempts}/{retry_num}\")"
      ],
      "metadata": {
        "id": "6q7jqPCBPBYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Helper Functions\n",
        "\n",
        "To demonstrate the helper functions, write a CSV of data, send the CSV with a prompt to Code Interpreter, examine the response, and run the code locally."
      ],
      "metadata": {
        "id": "Wq71jPJ7dMOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "tree_heights_prices = {\n",
        "  \"Pine\": {\"height\": 100, \"price\": 100},\n",
        "  \"Oak\": {\"height\": 65, \"price\": 135},\n",
        "  \"Birch\": {\"height\": 45, \"price\": 80},\n",
        "  \"Redwood\": {\"height\": 200, \"price\": 200},\n",
        "  \"Fir\": {\"height\": 180, \"price\": 162},\n",
        "}\n",
        "\n",
        "with open('tree_data.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['Tree', 'Height', 'Price']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for tree, data in tree_heights_prices.items():\n",
        "        writer.writerow({'Tree': tree, 'Height': data['height'], 'Price': data['price']})"
      ],
      "metadata": {
        "id": "4FQ1s3YxfL4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = run_code_interpreter(\"Make a bar chart of the heights of the trees.\",\n",
        "                                ['tree_data.csv'])"
      ],
      "metadata": {
        "id": "ZEIADEAXjMuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_response(response)"
      ],
      "metadata": {
        "id": "MaLwhE6kjrQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Data\n",
        "\n",
        "The following code writes a local CSV file of synthetic data. This is a simple dataset of students containing attributes about sleeping and eating habits along with academic performance. This dataset is fictional and does not represent reality, it is only used to  demontstrate Code Interpreter cabapilities."
      ],
      "metadata": {
        "id": "8gZVnoGDbrbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile students.csv\n",
        "StudentID,Gender,ExtraActivitiesGroup,EatingHabits,SleepingHabits,Reading,Writing,Maths\n",
        "1,Male,nan,Healthy,Satisfactory,75,80,78\n",
        "2,Female,Group B,Mixed,Non-Satisfactory,nan,70,67\n",
        "3,nan,Group A,Unhealthy,Satisfactory,55,60,58\n",
        "4,Female,Group C,Healthy,Non-Satisfactory,70,75,73\n",
        "5,Male,Group B,Mixed,Satisfactory,60,65,63\n",
        "6,Female,Group A,Unhealthy,Non-Satisfactory,50,55,53\n",
        "7,Male,Group C,Healthy,Satisfactory,80,85,83\n",
        "8,Female,Group B,Mixed,Non-Satisfactory,65,70,67\n",
        "9,Male,Group A,Unhealthy,Satisfactory,55,60,58\n",
        "10,Male,nan,Mixed,Non-Satisfactory,80,78,85\n",
        "11,Female,Group B,Unhealthy,Satisfactory,65,68,70\n",
        "12,Female,Group A,Healthy,Non-Satisfactory,52,57,55\n",
        "13,nan,Group C,Unhealthy,Satisfactory,78,75,79\n",
        "14,Female,Group B,Mixed,Non-Satisfactory,63,70,65\n",
        "15,Male,Group A,Healthy,Satisfactory,82,87,80\n",
        "16,Male,Group C,Unhealthy,Non-Satisfactory,57,60,54\n",
        "17,Female,Group A,Mixed,Satisfactory,67,65,63\n",
        "18,Male,Group B,Unhealthy,Non-Satisfactory,55,62,58\n",
        "19,nan,Group C,Healthy,Satisfactory,88,85,87\n",
        "20,Female,Group B,Mixed,Non-Satisfactory,67,75,68\n",
        "21,Male,Group A,Unhealthy,Satisfactory,53,58,55\n",
        "22,Female,Group C,Healthy,Non-Satisfactory,80,77,82\n",
        "23,Male,Group A,Mixed,Satisfactory,60,63,60\n",
        "24,Female,Group B,Unhealthy,Non-Satisfactory,65,62,60\n",
        "25,Male,Group C,Healthy,Satisfactory,90,92,88\n",
        "26,Female,Group B,Mixed,Non-Satisfactory,58,65,60\n",
        "27,Male,Group A,Unhealthy,Satisfactory,67,60,65\n",
        "28,Male,Group C,Healthy,Non-Satisfactory,72,78,73\n",
        "29,Female,Group A,Mixed,Satisfactory,55,62,58\n",
        "30,Male,Group B,Unhealthy,Non-Satisfactory,78,75,72\n",
        "31,Female,Group C,Healthy,Satisfactory,85,87,83\n",
        "32,Female,Group A,Mixed,Non-Satisfactory,70,65,67\n",
        "33,Male,Group B,Unhealthy,Satisfactory,62,67,65\n",
        "34,Male,Group C,Healthy,Non-Satisfactory,77,83,75\n",
        "35,nan,Group A,Mixed,Satisfactory,65,63,60\n",
        "36,Female,Group B,Unhealthy,Non-Satisfactory,72,78,70\n",
        "37,Male,Group C,Healthy,Satisfactory,80,87,83\n",
        "38,Female,Group A,Mixed,Non-Satisfactory,75,70,72\n",
        "39,Male,Group B,Unhealthy,Satisfactory,65,67,60\n",
        "40,nan,Group C,Healthy,Non-Satisfactory,82,88,80\n",
        "41,Female,Group A,Mixed,Satisfactory,77,72,70\n",
        "42,Male,Group B,Unhealthy,Non-Satisfactory,67,62,63\n",
        "43,Male,Group C,Healthy,Satisfactory,92,90,88\n",
        "44,Female,Group A,Mixed,Non-Satisfactory,80,75,77\n",
        "45,nan,Group B,Unhealthy,Satisfactory,72,75,73\n",
        "46,Female,Group C,Healthy,Non-Satisfactory,83,80,85\n",
        "47,Male,Group A,Mixed,Satisfactory,75,72,73\n",
        "48,Male,Group B,Unhealthy,Non-Satisfactory,60,63,58\n",
        "49,nan,Group C,Healthy,Satisfactory,90,92,88\n",
        "50,Female,Group A,Mixed,Non-Satisfactory,85,80,82\n",
        "51,Male,Group B,Unhealthy,Satisfactory,70,67,65\n",
        "52,Female,Group C,Healthy,Non-Satisfactory,78,83,77\n",
        "53,Male,Group B,Mixed,Satisfactory,65,63,62\n",
        "54,Male,Group A,Unhealthy,Non-Satisfactory,52,57,55\n",
        "55,nan,Group C,Healthy,Satisfactory,75,78,73\n",
        "56,Female,Group B,Mixed,Non-Satisfactory,70,77,72\n",
        "57,Male,Group A,Unhealthy,Satisfactory,62,65,63\n",
        "58,Female,Group C,Healthy,Non-Satisfactory,88,85,83\n",
        "59,Male,Group B,Mixed,Satisfactory,78,80,77\n",
        "60,nan,Group A,Unhealthy,Non-Satisfactory,67,60,65\n",
        "61,Female,Group C,Healthy,Satisfactory,83,80,82\n",
        "62,Male,Group B,Mixed,Non-Satisfactory,72,68,70\n",
        "63,Male,Group A,Unhealthy,Satisfactory,62,57,60\n",
        "64,Female,Group C,Healthy,Non-Satisfactory,90,87,88\n",
        "65,Male,Group B,Mixed,Satisfactory,85,82,80\n",
        "66,nan,Group A,Unhealthy,Non-Satisfactory,55,62,58\n",
        "67,Female,Group C,Healthy,Satisfactory,77,85,80\n",
        "68,Male,Group B,Mixed,Non-Satisfactory,65,72,67\n",
        "69,Male,Group A,Unhealthy,Satisfactory,67,60,68\n",
        "70,Female,Group C,Healthy,Non-Satisfactory,92,90,85\n",
        "71,Male,Group B,Mixed,Satisfactory,77,85,82\n",
        "72,nan,Group A,Unhealthy,Non-Satisfactory,62,55,60\n",
        "73,Female,Group C,Healthy,Satisfactory,83,87,85\n",
        "74,Male,Group B,Mixed,Non-Satisfactory,68,72,65\n",
        "75,Male,Group A,Unhealthy,Satisfactory,53,58,55\n",
        "76,nan,Group C,Healthy,Non-Satisfactory,88,83,87\n",
        "77,Female,Group B,Mixed,Satisfactory,72,70,73\n",
        "78,Male,Group A,Unhealthy,Non-Satisfactory,70,65,67\n",
        "79,Male,Group C,Healthy,Satisfactory,80,85,80\n",
        "80,Female,Group B,Mixed,Non-Satisfactory,75,72,75\n",
        "81,nan,Group A,Unhealthy,Satisfactory,55,60,58\n",
        "82,Female,Group C,Healthy,Non-Satisfactory,80,77,82\n",
        "83,Male,Group B,Mixed,Satisfactory,68,70,68\n",
        "84,Male,Group A,Unhealthy,Non-Satisfactory,62,57,63\n",
        "85,Female,Group C,Healthy,Satisfactory,90,92,88\n",
        "86,nan,Group B,Mixed,Non-Satisfactory,67,72,67\n",
        "87,Female,Group A,Unhealthy,Satisfactory,53,60,58\n",
        "88,Male,Group C,Healthy,Non-Satisfactory,75,78,73\n",
        "89,Male,Group B,Mixed,Satisfactory,82,80,83\n",
        "90,nan,Group A,Unhealthy,Non-Satisfactory,65,62,63\n",
        "91,Female,Group C,Healthy,Satisfactory,80,83,80\n",
        "92,Male,Group B,Mixed,Non-Satisfactory,85,80,82\n",
        "93,Male,Group A,Unhealthy,Satisfactory,62,67,65\n",
        "94,nan,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "95,Female,Group B,Mixed,Satisfactory,77,75,78\n",
        "96,Female,Group A,Unhealthy,Non-Satisfactory,67,60,68\n",
        "97,nan,Group C,Healthy,Satisfactory,77,83,78\n",
        "98,Male,Group B,Mixed,Non-Satisfactory,62,68,65\n",
        "99,Male,Group A,Unhealthy,Satisfactory,52,57,58\n",
        "100,Female,Group C,Healthy,Non-Satisfactory,72,75,77\n",
        "101,Male,Group B,Mixed,Satisfactory,70,67,72\n",
        "102,nan,Group A,Unhealthy,Non-Satisfactory,67,62,65\n",
        "103,Female,Group C,Healthy,Satisfactory,83,87,85\n",
        "104,Male,Group B,Mixed,Non-Satisfactory,80,77,82\n",
        "105,Male,Group A,Unhealthy,Satisfactory,55,62,53\n",
        "106,Female,Group C,Healthy,Non-Satisfactory,92,90,88\n",
        "107,nan,Group B,Mixed,Satisfactory,78,83,78\n",
        "108,Female,Group A,Unhealthy,Non-Satisfactory,72,65,70\n",
        "109,Male,Group C,Healthy,Satisfactory,83,80,85\n",
        "110,Female,Group B,Mixed,Non-Satisfactory,68,72,63\n",
        "111,Male,Group A,Unhealthy,Satisfactory,60,63,63\n",
        "112,nan,Group C,Healthy,Non-Satisfactory,72,78,73\n",
        "113,Female,Group B,Mixed,Satisfactory,80,83,83\n",
        "114,Male,Group A,Unhealthy,Non-Satisfactory,70,65,67\n",
        "115,Female,Group C,Healthy,Satisfactory,90,87,92\n",
        "116,Male,Group B,Mixed,Non-Satisfactory,85,82,80\n",
        "117,Male,Group A,Unhealthy,Satisfactory,52,57,55\n",
        "118,Female,Group C,Healthy,Non-Satisfactory,77,85,80\n",
        "119,nan,Group B,Mixed,Satisfactory,68,70,68\n",
        "120,Female,Group A,Unhealthy,Non-Satisfactory,53,60,58\n",
        "121,Male,Group C,Healthy,Satisfactory,75,80,77\n",
        "122,Female,Group B,Mixed,Non-Satisfactory,67,72,67\n",
        "123,Male,Group B,Unhealthy,Satisfactory,70,67,72\n",
        "124,Female,Group A,Mixed,Non-Satisfactory,62,57,60\n",
        "125,nan,Group C,Healthy,Satisfactory,80,83,80\n",
        "126,Male,Group B,Mixed,Non-Satisfactory,62,68,60\n",
        "127,Male,Group A,Unhealthy,Satisfactory,55,60,58\n",
        "128,Female,Group C,Healthy,Non-Satisfactory,92,90,85\n",
        "129,Male,Group B,Mixed,Satisfactory,85,82,80\n",
        "130,Female,Group A,Unhealthy,Non-Satisfactory,75,70,72\n",
        "131,nan,Group C,Healthy,Satisfactory,77,83,78\n",
        "132,Male,Group B,Mixed,Non-Satisfactory,80,77,82\n",
        "133,Male,Group A,Unhealthy,Satisfactory,62,67,60\n",
        "134,Female,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "135,Male,Group B,Mixed,Satisfactory,78,83,78\n",
        "136,Female,Group A,Unhealthy,Non-Satisfactory,55,62,58\n",
        "137,Male,Group C,Healthy,Satisfactory,80,83,80\n",
        "138,Male,Group B,Mixed,Non-Satisfactory,67,70,63\n",
        "139,nan,Group A,Unhealthy,Satisfactory,65,62,65\n",
        "140,Female,Group C,Healthy,Non-Satisfactory,88,83,87\n",
        "141,Female,Group B,Mixed,Satisfactory,70,77,70\n",
        "142,Male,Group A,Unhealthy,Non-Satisfactory,52,57,55\n",
        "143,Male,Group C,Healthy,Satisfactory,85,80,82\n",
        "144,Male,Group B,Mixed,Non-Satisfactory,82,80,83\n",
        "145,nan,Group A,Unhealthy,Satisfactory,60,63,63\n",
        "146,Female,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "147,Female,Group B,Mixed,Satisfactory,75,72,77\n",
        "148,Male,Group A,Unhealthy,Non-Satisfactory,57,60,54\n",
        "149,nan,Group C,Healthy,Satisfactory,80,85,82\n",
        "150,Female,Group B,Mixed,Non-Satisfactory,80,75,83\n",
        "151,Male,Group A,Unhealthy,Satisfactory,78,75,79\n",
        "152,Male,Group C,Healthy,Non-Satisfactory,92,90,88\n",
        "153,nan,Group B,Mixed,Satisfactory,65,63,62\n",
        "154,Female,Group A,Unhealthy,Non-Satisfactory,53,58,55\n",
        "155,Male,Group C,Healthy,Satisfactory,83,87,82\n",
        "156,Female,Group B,Mixed,Non-Satisfactory,85,80,83\n",
        "157,Male,Group A,Unhealthy,Satisfactory,70,67,72\n",
        "158,Male,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "159,Female,Group B,Mixed,Satisfactory,68,70,68\n",
        "160,Female,Group A,Unhealthy,Non-Satisfactory,67,60,70\n",
        "161,nan,Group C,Healthy,Satisfactory,90,92,88\n",
        "162,Male,Group B,Mixed,Non-Satisfactory,85,82,80\n",
        "163,Male,Group A,Unhealthy,Satisfactory,65,62,65\n",
        "164,Female,Group C,Healthy,Non-Satisfactory,83,87,85\n",
        "165,nan,Group B,Mixed,Satisfactory,78,83,78\n",
        "166,Female,Group A,Unhealthy,Non-Satisfactory,55,62,58\n",
        "167,Male,Group C,Healthy,Satisfactory,80,83,80\n",
        "168,Female,Group B,Mixed,Non-Satisfactory,67,70,63\n",
        "169,Male,Group A,Unhealthy,Satisfactory,52,57,55\n",
        "170,nan,Group C,Healthy,Non-Satisfactory,82,88,80\n",
        "171,Male,Group B,Mixed,Satisfactory,80,83,83\n",
        "172,Female,Group A,Unhealthy,Non-Satisfactory,75,70,72\n",
        "173,Male,Group B,Healthy,Satisfactory,90,87,88\n",
        "174,Male,Group B,Mixed,Non-Satisfactory,62,68,65\n",
        "175,nan,Group A,Unhealthy,Satisfactory,62,57,63\n",
        "176,Female,Group C,Healthy,Non-Satisfactory,77,85,80\n",
        "177,Male,Group B,Mixed,Satisfactory,68,70,68\n",
        "178,Male,Group A,Unhealthy,Non-Satisfactory,53,60,58\n",
        "179,Female,Group C,Healthy,Satisfactory,90,87,92\n",
        "180,Male,Group B,Mixed,Non-Satisfactory,70,67,75\n",
        "181,nan,Group A,Unhealthy,Satisfactory,65,62,65\n",
        "182,Female,Group C,Healthy,Non-Satisfactory,83,87,85\n",
        "183,nan,Group A,Mixed,Satisfactory,75,78,77\n",
        "184,Female,Group A,Unhealthy,Non-Satisfactory,55,62,58\n",
        "185,Male,Group C,Healthy,Satisfactory,80,83,80\n",
        "186,Male,Group A,Mixed,Non-Satisfactory,85,82,80\n",
        "187,Male,Group A,Unhealthy,Satisfactory,78,75,79\n",
        "188,nan,Group C,Healthy,Non-Satisfactory,80,85,83\n",
        "189,Female,Group B,Mixed,Satisfactory,70,77,70\n",
        "190,Male,Group A,Unhealthy,Non-Satisfactory,57,60,54\n",
        "191,nan,Group C,Healthy,Satisfactory,92,90,85\n",
        "192,Female,Group B,Mixed,Non-Satisfactory,80,75,83\n",
        "193,Male,Group A,Unhealthy,Satisfactory,53,58,55\n",
        "194,nan,Group C,Healthy,Non-Satisfactory,75,78,77\n",
        "195,Female,Group B,Mixed,Satisfactory,65,63,62\n",
        "196,Female,Group A,Unhealthy,Non-Satisfactory,67,60,70\n",
        "197,Male,Group A,Healthy,Satisfactory,85,80,87\n",
        "198,Male,Group B,Mixed,Non-Satisfactory,85,82,80\n",
        "199,Male,Group A,Unhealthy,Satisfactory,72,65,70\n",
        "200,nan,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "201,Female,Group B,Mixed,Satisfactory,68,70,68\n",
        "202,Female,Group A,Unhealthy,Non-Satisfactory,62,57,63\n",
        "203,nan,Group A,Healthy,Satisfactory,82,88,80\n",
        "204,Female,Group B,Mixed,Non-Satisfactory,80,77,82\n",
        "205,Male,Group A,Unhealthy,Satisfactory,67,60,68\n",
        "206,Male,Group A,Healthy,Non-Satisfactory,90,87,92\n",
        "207,Female,Group B,Mixed,Satisfactory,78,83,78\n",
        "208,Female,Group A,Unhealthy,Non-Satisfactory,72,65,70\n",
        "209,nan,Group C,Healthy,Satisfactory,77,83,78\n",
        "210,Male,Group B,Mixed,Non-Satisfactory,62,68,65\n",
        "211,Male,Group A,Unhealthy,Satisfactory,53,58,55\n",
        "212,Male,Group A,Healthy,Non-Satisfactory,92,90,85\n",
        "213,Female,Group B,Mixed,Satisfactory,68,70,68\n",
        "214,Female,Group A,Unhealthy,Non-Satisfactory,75,70,72\n",
        "215,nan,Group B,Healthy,Satisfactory,77,83,78\n",
        "216,Female,Group B,Mixed,Non-Satisfactory,67,70,63\n",
        "217,Male,Group A,Unhealthy,Satisfactory,52,57,55\n",
        "218,nan,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "219,Female,Group B,Mixed,Satisfactory,85,82,80\n",
        "220,Female,Group A,Unhealthy,Non-Satisfactory,55,62,58\n",
        "221,Male,Group A,Healthy,Satisfactory,80,83,80\n",
        "222,Male,Group B,Mixed,Non-Satisfactory,60,63,63\n",
        "223,Male,Group A,Unhealthy,Satisfactory,78,75,79\n",
        "224,Female,Group C,Healthy,Non-Satisfactory,75,78,77\n",
        "225,nan,Group B,Mixed,Satisfactory,70,67,72\n",
        "226,Male,Group A,Unhealthy,Non-Satisfactory,70,65,67\n",
        "227,nan,Group C,Healthy,Satisfactory,90,92,88\n",
        "228,Female,Group B,Mixed,Non-Satisfactory,85,82,80\n",
        "229,Male,Group A,Unhealthy,Satisfactory,65,62,65\n",
        "230,Female,Group C,Healthy,Non-Satisfactory,83,87,85\n",
        "231,nan,Group B,Mixed,Satisfactory,75,78,77\n",
        "232,Female,Group A,Unhealthy,Non-Satisfactory,55,62,58\n",
        "233,Male,Group C,Healthy,Satisfactory,80,83,80\n",
        "234,Male,Group B,Mixed,Non-Satisfactory,85,82,80\n",
        "235,Male,Group A,Unhealthy,Satisfactory,78,75,79\n",
        "236,Female,Group C,Healthy,Non-Satisfactory,83,87,85\n",
        "237,nan,Group A,Mixed,Satisfactory,80,83,83\n",
        "238,Female,Group B,Mixed,Non-Satisfactory,75,70,77\n",
        "239,Male,Group A,Unhealthy,Non-Satisfactory,62,57,63\n",
        "240,nan,Group C,Healthy,Non-Satisfactory,82,88,80\n",
        "241,Female,Group B,Mixed,Satisfactory,80,77,82\n",
        "242,Male,Group A,Unhealthy,Satisfactory,60,63,63\n",
        "243,Female,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "244,Male,Group B,Mixed,Non-Satisfactory,82,80,83\n",
        "245,nan,Group C,Healthy,Satisfactory,77,83,78\n",
        "246,Male,Group B,Mixed,Non-Satisfactory,72,68,70\n",
        "247,Female,Group A,Unhealthy,Satisfactory,65,62,65\n",
        "248,Male,Group C,Healthy,Non-Satisfactory,80,85,83\n",
        "249,Female,Group A,Mixed,Non-Satisfactory,70,65,67\n",
        "250,nan,Group C,Healthy,Non-Satisfactory,83,80,85\n",
        "251,Female,Group B,Mixed,Satisfactory,68,70,68\n",
        "252,Female,Group A,Unhealthy,Non-Satisfactory,62,57,63\n",
        "253,Male,Group C,Healthy,Satisfactory,92,90,88\n",
        "254,Female,Group B,Mixed,Non-Satisfactory,80,75,83\n",
        "255,nan,Group C,Healthy,Satisfactory,90,92,88\n",
        "256,Female,Group B,Mixed,Satisfactory,70,77,70\n",
        "257,Male,Group A,Unhealthy,Non-Satisfactory,52,57,55\n",
        "258,nan,Group C,Healthy,Non-Satisfactory,75,78,77\n",
        "259,Female,Group B,Mixed,Non-Satisfactory,80,77,82\n",
        "260,Male,Group A,Unhealthy,Satisfactory,55,62,58\n",
        "261,nan,Group C,Healthy,Satisfactory,82,88,80\n",
        "262,Female,Group B,Mixed,Non-Satisfactory,72,65,70\n",
        "263,Male,Group A,Unhealthy,Non-Satisfactory,65,62,65\n",
        "264,Female,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "265,Male,Group B,Mixed,Satisfactory,77,85,82\n",
        "266,Female,Group A,Unhealthy,Non-Satisfactory,55,62,58\n",
        "267,nan,Group C,Healthy,Satisfactory,83,80,85\n",
        "268,Female,Group B,Mixed,Non-Satisfactory,85,82,80\n",
        "269,Male,Group A,Unhealthy,Satisfactory,62,57,63\n",
        "270,Female,Group C,Healthy,Non-Satisfactory,77,85,80\n",
        "271,nan,Group B,Mixed,Satisfactory,70,67,72\n",
        "272,Male,Group A,Unhealthy,Non-Satisfactory,53,60,58\n",
        "273,Male,Group C,Healthy,Satisfactory,75,80,77\n",
        "274,Female,Group B,Mixed,Non-Satisfactory,80,75,83\n",
        "275,Male,Group A,Unhealthy,Satisfactory,52,57,55\n",
        "276,nan,Group C,Healthy,Non-Satisfactory,92,90,85\n",
        "277,Female,Group B,Mixed,Satisfactory,68,72,65\n",
        "278,Male,Group A,Unhealthy,Non-Satisfactory,70,65,67\n",
        "279,nan,Group C,Healthy,Satisfactory,80,83,80\n",
        "280,Female,Group B,Mixed,Non-Satisfactory,75,72,75\n",
        "281,Male,Group A,Unhealthy,Satisfactory,57,60,54\n",
        "282,Female,Group C,Healthy,Non-Satisfactory,78,83,77\n",
        "283,nan,Group B,Mixed,Satisfactory,70,67,72\n",
        "284,Female,Group A,Unhealthy,Non-Satisfactory,62,57,63\n",
        "285,Male,Group C,Healthy,Satisfactory,90,87,88\n",
        "286,Male,Group B,Mixed,Non-Satisfactory,82,80,83\n",
        "287,nan,Group C,Healthy,Satisfactory,77,83,78\n",
        "288,Female,Group B,Mixed,Non-Satisfactory,72,70,73\n",
        "289,Male,Group A,Unhealthy,Satisfactory,65,62,65\n",
        "290,Female,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "291,nan,Group B,Mixed,Satisfactory,70,63,60\n",
        "292,Female,Group A,Unhealthy,Non-Satisfactory,55,62,58\n",
        "293,Male,Group C,Healthy,Satisfactory,75,80,77\n",
        "294,Male,Group B,Mixed,Non-Satisfactory,85,82,80\n",
        "295,nan,Group A,Mixed,Satisfactory,80,75,77\n",
        "296,Female,Group C,Healthy,Non-Satisfactory,77,83,78\n",
        "297,Female,Group B,Mixed,Non-Satisfactory,67,72,67\n",
        "298,Male,Group A,Unhealthy,Satisfactory,67,60,68\n",
        "299,Male,Group B,Healthy,Satisfactory,88,85,87\n",
        "300,Female,Group A,Mixed,Non-Satisfactory,78,75,79\n",
        "301,Male,Group C,Unhealthy,Satisfactory,75,78,72\n",
        "302,Female,Group B,Mixed,Non-Satisfactory,72,65,70\n",
        "303,Male,Group A,Healthy,Non-Satisfactory,85,82,80\n",
        "304,Female,Group C,Healthy,Non-Satisfactory,77,83,78\n",
        "305,Male,Group A,Mixed,Non-Satisfactory,72,65,70\n",
        "306,Female,Group B,Unhealthy,Satisfactory,72,78,70\n",
        "307,nan,Group A,Healthy,Satisfactory,82,88,80\n",
        "308,Female,Group C,Mixed,Non-Satisfactory,72,75,77\n",
        "309,Male,Group B,Mixed,Non-Satisfactory,62,68,65\n",
        "310,Female,Group A,Unhealthy,Satisfactory,53,60,58\n",
        "311,nan,Group C,Healthy,Satisfactory,90,92,88\n",
        "312,Female,Group B,Mixed,Non-Satisfactory,80,77,82\n",
        "313,Male,Group A,Unhealthy,Non-Satisfactory,67,60,68\n",
        "314,nan,Group C,Healthy,Satisfactory,77,83,78\n",
        "315,Female,Group B,Mixed,Satisfactory,75,72,75\n",
        "316,Male,Group A,Unhealthy,Non-Satisfactory,52,57,55\n",
        "317,Female,Group C,Healthy,Non-Satisfactory,90,87,92\n",
        "318,Male,Group B,Mixed,Non-Satisfactory,85,82,80"
      ],
      "metadata": {
        "id": "u8nB4DCaVsUa",
        "tags": []
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Analyze the Dataset\n",
        "\n",
        "Send a prompt with instructions that uses data from a CSV file attached to the Code Interpreter call."
      ],
      "metadata": {
        "id": "5Wi3ZigPrnp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Dataset Using Plots\n",
        "In this step you are going to use Gemini to generate plot ideas. Provide the first 30 rows of the CSV and prompt Gemini in natural language to propose plots. Then you will use Code Interpreter to execute those plot ideas."
      ],
      "metadata": {
        "id": "oH92Wa0rOSlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.generative_models import (\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold )\n",
        "from pathlib import Path\n",
        "\n",
        "model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
        "csv_content = Path(\"students.csv\").read_text().split('\\n')\n",
        "sample = '\\n'.join(csv_content[:30])\n",
        "prompt = f\"\"\"\n",
        "Data sample:\n",
        "{sample}\n",
        "\n",
        "You are a data scientist and you are using Code Interpreter to run data\n",
        "operations and generate plots/charts. Code interpreter generates code from\n",
        "natural language instructions.\n",
        "\n",
        "Based on the data, create about 8 prompt instructions in natural language for\n",
        "Code Interpreter to use to create code that generates plots that help you\n",
        "understand the data.\n",
        "\n",
        "Do not use StudentID as it is unique identifier.\n",
        "\n",
        "There is no time attribute in the dataset so do not suggest ploting something over time.\n",
        "\n",
        "You can use boxplots, pie charts, scatter charts, and bar charts.\"\"\"\n",
        "\n",
        "ideas = model.generate_content(\n",
        "    prompt,\n",
        "    generation_config={\n",
        "        \"max_output_tokens\": 2048,\n",
        "        \"temperature\": 0.1,\n",
        "        \"top_p\": 1\n",
        "    },\n",
        "    safety_settings={\n",
        "          HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "          HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "          HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "          HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    },\n",
        "    stream=False,\n",
        "  )\n",
        "\n",
        "print(f\"Gemini responded with the following suggestions: \\n\\n{ideas.text}\")"
      ],
      "metadata": {
        "id": "b8k3k5dTlp7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thank you Gemini! Next, ask Code Interpreter to plot these ideas.\n",
        "\n",
        "**Note:** Code Interpreter might fail to plot some of the suggestions because they might be poorly defined. In the instructions below you are asking Code Interpreter to interate over those ideas, and if there is a failure to simply continue with the next plot idea and not fail. Basically, you are asking Code Interpreter to plot as many of the ideas as possible."
      ],
      "metadata": {
        "id": "og-VlMNEcG2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "Create the following plots.\n",
        "Make sure each plot is in its own file and do not overlay multiple plots, so for every plot reset the process.\n",
        "Make sure plots have visible numebers or percentages when aplicable and labels.\n",
        "If any of the following produces an exception make sure you catch it and continue to the next item in the list:\n",
        "{ideas.text}\n",
        "\"\"\", filenames= ['students.csv'])\n",
        "process_response(response)"
      ],
      "metadata": {
        "id": "QWlAxqL4ERWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may noticed some generated errors, and/or some plots that look strange or are entirely blank. Check if you have any missing values in your data."
      ],
      "metadata": {
        "id": "_82keNfoO7KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = run_code_interpreter(instructions=\"Are there any missing values in my data? show results in a nice table\",\n",
        "                                filenames= ['students.csv'])\n",
        "process_response(response)"
      ],
      "metadata": {
        "id": "EroIInUSwfWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use Code Interpreter to generate a statistics report."
      ],
      "metadata": {
        "id": "b9yuNYUQglVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = run_code_interpreter(\"Generate a detailed statistics report from the data.\",\n",
        "                                filenames= ['students.csv'])\n",
        "process_response(response)"
      ],
      "metadata": {
        "id": "UX9tQiO5vBbl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a correlation matrix."
      ],
      "metadata": {
        "id": "NZUNUGFvgwGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = run_code_interpreter(\"\"\"\n",
        "Plot a correlation matrix of the Maths, Reading, and Writing fields.\n",
        "First set the seaborn font scale to 0.5.\n",
        "Make width and height to 4 using figsize.\n",
        "Use Blue base gradient for coloring where dark blue means high correlation.\"\"\",\n",
        "                                filenames= ['students.csv'])\n",
        "process_response(response)"
      ],
      "metadata": {
        "id": "u4aYEH49ySw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Clean the Dataset\n",
        "In this step you will fix some issues identified in the analysis above."
      ],
      "metadata": {
        "id": "6T6ifC2zhSrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fix Missing Values\n",
        "\n",
        "Fix the missing values issue in the dataset and produce a new file *students_clean.csv*.\n",
        "\n",
        "You'll see in the example below that Code Interpreter is instructed to ignore FutureWarnings. This is because Code Interpreter favors pandas for data transformations, and pandas throws many non-fatal warnings. The `run_code_interpreter` method will retry code that throws errors, but since the pandas warnings are non-fatal we don't want to retry code that only has warnings in this particular case."
      ],
      "metadata": {
        "id": "rF0WbqDyf7q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instr = \"\"\"\n",
        "Use the warnings library to supress all category=FutureWarning.\n",
        "Replace Gender missing values with Unknown.\n",
        "Replace missing ExtraActivitiesGroup values with Group X.\n",
        "Replace missing Reading, Writing, or Maths values with the mean value of that column.\n",
        "Write the results in students_clean.csv.\n",
        "\"\"\"\n",
        "\n",
        "response = run_code_interpreter(instructions=instr, filenames= ['students.csv'])\n",
        "process_response(response)"
      ],
      "metadata": {
        "id": "h_xhsJ1Kkt9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Outliers\n",
        "\n",
        "Remove outliers using quantiles between 0.05 and 0.95."
      ],
      "metadata": {
        "id": "kx1MtZeRg1Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instr = \"\"\"\n",
        "Print the initial number of rows.\n",
        "Remove any outliers in numeric columns based on quantiles between 0.05 and 0.95.\n",
        "Write the new dataset in students_clean_v2.csv.\n",
        "Print the total number of rows after removing outliers.\n",
        "\"\"\"\n",
        "\n",
        "response = run_code_interpreter(instructions=instr, filenames= ['students_clean.csv'])\n",
        "process_response(response)"
      ],
      "metadata": {
        "id": "ktn_60IFAAlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Training a Model\n",
        "Now that you have cleaned the dataset, in this step you will train a regression model to predict the Maths score based on student attributes."
      ],
      "metadata": {
        "id": "0I5L_Y-chCGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Data\n",
        "Create a training set and an evaluation set with an 80%/20% split."
      ],
      "metadata": {
        "id": "zyOh7t48th-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instr = \"\"\"\n",
        "Split the data in 2 files. 80% in train.csv and 20% in evaluate.csv.\n",
        "Print the number of rows in each file excluding the header\"\"\"\n",
        "\n",
        "response = run_code_interpreter(instructions=instr, filenames= ['students_clean_v2.csv'])\n",
        "process_response(response)"
      ],
      "metadata": {
        "id": "sgGfGxET1R9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model\n",
        "\n",
        "Now we train a model to predict the Maths score based on other attributes, excluding Reading and Writing."
      ],
      "metadata": {
        "id": "rOLCpa1ch9gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_training_instruction = \"\"\"\n",
        "Train a regression model to predict Maths score based on other fields.\n",
        "Exclude Reading and Writing and StudentID columns, and separate the Maths column as a label.\n",
        "Use the rest of the columns to train a model to predict the Maths score.\n",
        "All the columns apart from the label are categorical so treat them as such.\n",
        "Use a sklearn pipeline to do data transformations and modeling together.\n",
        "At the end export the pipeline as pipeline.pkl.\n",
        "Do not split the data, the file is only the training data.\n",
        "Report back MAE and R2 using the training data.\n",
        "Do not use sklearn.externals.\n",
        "\"\"\"\n",
        "\n",
        "response = run_code_interpreter(model_training_instruction, ['train.csv'])\n",
        "process_response(response)"
      ],
      "metadata": {
        "id": "mt6CTQ7ZzNMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Using the Model to Predict\n",
        "In this step you will use the `pipeline.pkl` to run predicitons on the test split."
      ],
      "metadata": {
        "id": "CHgnegDUiY0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_predict_instruction = \"\"\"\n",
        "Load the .pkl file and run predictions on evaluate.csv.\n",
        "Export predictions in a new predictions.csv.\n",
        "The prediction should be in new column called 'pred'.\n",
        "Calculate and print MAE and R2 using columns Maths and pred.\n",
        "Do not use sklearn.externals.\n",
        "\"\"\"\n",
        "\n",
        "response = run_code_interpreter(model_predict_instruction, ['pipeline.pkl','evaluate.csv'])\n",
        "process_response(response)"
      ],
      "metadata": {
        "id": "n0mBXOzG1f0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleanup\n",
        "In this tutorial you used Code Interpreter from Vertex AI Extensions to process data, train a linear regression model, and run predictions."
      ],
      "metadata": {
        "id": "figw2zZ7MmO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Up Extensions\n",
        "\n",
        "Run the next code block to remove the extension you registered in this notebook."
      ],
      "metadata": {
        "id": "SSwaXG-zq-Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extension_code_interpreter.delete()"
      ],
      "metadata": {
        "id": "G6y9BgeyQuXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you restarted the notebook runtime, you may have some stray registered Extensions. This next line of code shows you all the Extensions registered in your project:"
      ],
      "metadata": {
        "id": "-DjFqPctqxg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extensions.Extension.list()"
      ],
      "metadata": {
        "id": "GTEgYGhFQfTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the [Google Cloud Console](https://console.cloud.google.com/vertex-ai/extensions) to view and delete any stray registered Extensions.\n",
        "\n",
        "If you cant to delete all the extensions in your project, uncomment and run this code block. **WARNING**: This cannot be undone!"
      ],
      "metadata": {
        "id": "ihJEWJvNSfc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "clean_ids = []\n",
        "\n",
        "for element in extensions.Extension.list():\n",
        "  clean_ids.append(str(element).split(\"extensions/\")[1])\n",
        "\n",
        "for id in clean_ids:\n",
        "  extension = extensions.Extension(id)\n",
        "  extension.delete()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CsPKKv-USmi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Up Local Files"
      ],
      "metadata": {
        "id": "jUkl6FE-tXGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you used the `run_code_interpreter` helper function, you can quickly cleanup the files created by Code Interpreter. First, take a look at the file names created:"
      ],
      "metadata": {
        "id": "dyM_NM-cPciW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(CODE_INTERPRETER_WRITTEN_FILES))"
      ],
      "metadata": {
        "id": "KKIcuYjMQYmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you don't want to keep any of these files, uncomment and run the next code block. **WARNING**: These files will all be deleted, and this cannot be undone."
      ],
      "metadata": {
        "id": "nbcEVKPAQcX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# _ = [os.remove(filename) for filename in set(CODE_INTERPRETER_WRITTEN_FILES)]"
      ],
      "metadata": {
        "id": "SrK4sJCiPtkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncomment to remove two more files created by this notebook:"
      ],
      "metadata": {
        "id": "PMKk4CScm_4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os.remove('students.csv')\n",
        "# os.remove('tree_data.csv')"
      ],
      "metadata": {
        "id": "1BfKIV2Jm_eU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9NnhQmFLAHXs",
        "8gZVnoGDbrbT"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
