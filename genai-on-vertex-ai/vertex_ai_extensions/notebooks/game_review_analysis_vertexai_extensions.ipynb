{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0q6qjyLbCG5"
      },
      "source": [
        "# Game Review Analysis Workflow with Vertex AI Extensions\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/applied-ai-engineering-samples/blob/main/genai-on-vertex-ai/vertex_ai_extensions/notebooks/game_review_analysis_vertexai_extensions.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fapplied-ai-engineering-samples%2Fmain%2Fgenai-on-vertex-ai%2Fvertex_ai_extensions%2Fnotebooks%2Fgame_review_analysis_vertexai_extensions.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/applied-ai-engineering-samples/main/genai-on-vertex-ai/vertex_ai_extensions/game_review_analysis_vertexai_extensions.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/applied-ai-engineering-samples/blob/main/genai-on-vertex-ai/vertex_ai_extensions/notebooks/game_review_analysis_vertexai_extensions.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGwjcyJkb78K"
      },
      "source": [
        "| | |\n",
        "|----------|-------------|\n",
        "| Author(s)   | [Meltem Subasioglu](https://github.com/5Y5TEM)|\n",
        "| Reviewers(s) | Yan Sun, Michael Sherman |\n",
        "| Last updated | 2024-04-15: Documentation Changes |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Overview\n",
        "\n",
        "[Vertex AI Extensions](https://cloud.google.com/vertex-ai/docs/generative-ai/extensions/private/overview) is a platform for creating and managing extensions that connect large language models to external systems via APIs. These external systems can provide LLMs with real-time data and perform data processing actions on their behalf.\n",
        "\n",
        "In this tutorial, you'll use Vertex AI Extensions to complete a review analysis of a Steam game:\n",
        "\n",
        "- Retrieve 50 reviews about the game from Steam\n",
        "- Create a pre-built Code Interpreter extension in your project\n",
        "- Use Code Interpreter to analyze the reviews and generate plots\n",
        "- Retrieve 10 websites with more detailed reviews on the game\n",
        "- Create and use the Vertex AI Search extension to research and summarize the website reviews\n",
        "- Use Code Interpreter to build a report with all the generated assets\n",
        "- Convert the report to PDF and upload to your Google Drive  \n",
        "- **[Optional]:** Send the PDF Report as an attachment via Gmail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S23-EwCumCU"
      },
      "source": [
        "▶ If you're already familiar with Google Cloud and the Vertex AI Extensions Code Interpreter Extension, you can skip reading between here and the \"**Getting Started**\" section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUXzlvfpn513"
      },
      "source": [
        "## Vertex AI Extensions\n",
        "\n",
        "[Vertex AI Extensions](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/overview) is a platform for creating and managing extensions that connect large language models to external systems via APIs. These external systems can provide LLMs with real-time data and perform data processing actions on their behalf. You can use pre-built or third-party extensions in Vertex AI Extensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r29fUEFn8JH"
      },
      "source": [
        "## Vertex AI Extensions Code Interpreter Extension\n",
        "\n",
        "The [Code Interpreter](https://console.cloud.google.com/vertex-ai/generative-ai/docs/extensions/google-extensions.md#google_code_interpreter_extension) extension provides access to a Python interpreter with a sandboxed, secure execution environment that can be used with any model in the Vertex AI Model Garden. This extension can generate and execute code in response to a user query or workflow. It allows the user or LLM agent to perform various tasks such as data analysis and visualization on new or existing data files.\n",
        "\n",
        "You can use the Code Interpreter extension to:\n",
        "\n",
        "* Generate and execute code.\n",
        "* Perform a wide variety of mathematical calculations.\n",
        "* Sort, filter, select the top results, and otherwise analyze data (including data acquired from other tools and APIs).\n",
        "* Create visualizations, plot charts, draw graphs, shapes, print results, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vertex AI Extensions Search Extension\n",
        "\n",
        "The Vertex AI [Search](https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/google-extensions#vertex_ai_search_extension) extension lets you access and search website corpuses and unstructured data to provide relevant responses to natural language questions, such as:\n",
        "\n",
        "* \"How did the competitive threats for the company change from Q1 of last year to Q1 of this year?\"\n",
        "* \"What parts of the company are growing the fastest? How fast?\""
      ],
      "metadata": {
        "id": "-CDQMnan1a7o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNriTZl70OdV"
      },
      "source": [
        "## Using this Notebook\n",
        "\n",
        "Colab is recommended for running this notebook, but it can run in any iPython environment where you can connect to Google Cloud, install pip packages, etc.\n",
        "\n",
        "If you're running outside of Colab, depending on your environment you may need to install pip packages (like pandas) that are included in the Colab environment by default but are not part of the Python Standard Library. You'll also notice some comments in code cells that look like #@something -- these may contain informative text\n",
        "\n",
        "This tutorial uses the following Google Cloud services and resources:\n",
        "\n",
        "* Vertex AI Extensions\n",
        "* Google Cloud Storage Client\n",
        "* Google Drive Client\n",
        "* Gmail API Client\n",
        "\n",
        "This notebook has been tested in the following environment:\n",
        "\n",
        "* Python version = 3.10.12 & 3.12.0\n",
        "* [google-cloud-aiplatform](https://pypi.org/project/google-cloud-aiplatform/) version = 1.47.0\n",
        "\n",
        "**Note:** Vertex AI Extensions requires google-cloud-aiplatform version >= 1.47.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar0aDcql1dxl"
      },
      "source": [
        "## Useful Tips\n",
        "\n",
        "1. This notebook uses Generative AI cababilities. Re-running a cell that uses Generative AI capabilities may produce similar but not identical results.\n",
        "2. Because of #1, it is possible that an output from Code Interpreter producess errors. If that happens re-run the cell that produced the coding error. The different generated code will likely be bug free. The `run_code_interpreter` method below helps automate this, but you still may need to rerun cells that generate working code that doesn't perfectly follow the instructions in the prompt.\n",
        "3. The use of Extensions and other Generative AI capabilities is subject to service quotas. Running the notebook using \"Run All\" may exceed  your queries per minute (QPM) limitations. Run the notebook manually and if you get a quota error pause for up to 1 minute before retrying that cell. Code Interpreter defaults to Gemini on the backend and is subject to the Gemini quotas, [view your Gemini quotas here](https://console.cloud.google.com/iam-admin/quotas?pageState=(%22allQuotasTable%22:(%22f%22:%22%255B%257B_22k_22_3A_22_22_2C_22t_22_3A10_2C_22v_22_3A_22_5C_22base_model_5C_22_22%257D_2C%257B_22k_22_3A_22_22_2C_22t_22_3A10_2C_22v_22_3A_22_5C_22gemini_5C_22_22%257D%255D%22%29%29&e=13802955&mods=logs_tg_staging).\n",
        "4. The Code Interpreter Extension is stateless and therefore every request to Code Interpreter does not have knowledge of previous operations nor files injested or produced in previous steps. Therefore, with any request to Code Interpreter you need to submit all files and instructions for that request to complete successfully.\n",
        "5. The Code Interpreter runs in a sandbox environment. So try to avoid prompts that need additional python packages to run or tell the Code Interpreter to ignore anything that needs packages beyond the built-in ones\n",
        "6. Tell the Code Interpreter to catch and print any exceptions for you, and to suppress UserWarnings and FutureWarnings\n",
        "7. For debugging the output of the Vertex Code Interpreter extension, it usually helps copying the error message into the prompt and telling the extension to properly handle that error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO_tnShTGUik"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "The following steps are necessary to run this notebook, no matter what notebook environment you're using.\n",
        "\n",
        "If you're entirely new to Google Cloud, [get started here](https://cloud.google.com/docs/get-started)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLf5oGqHn_DH"
      },
      "source": [
        "## Google Cloud Project Setup\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "1. [Enable the Service Usage API](https://console.cloud.google.com/apis/library/serviceusage.googleapis.com)\n",
        "1. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "1. [Enable the Cloud Storage API](https://console.cloud.google.com/flows/enableapi?apiid=storage.googleapis.com).\n",
        "1. [Enable the Google Drive API](https://console.cloud.google.com/flows/enableapi?apiid=drive.googleapis.com).\n",
        "1. [Enable the Gmail API](https://console.cloud.google.com/flows/enableapi?apiid=gmail.googleapis.com).\n",
        "1. [Enable the Discovery Engine API for your project](https://console.cloud.google.com/marketplace/product/google/discoveryengine.googleapis.com)\n",
        "1. [Enable the Agent Builder API](https://console.cloud.google.com/gen-app-builder/start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTuXDJ2qn-8W"
      },
      "source": [
        "## Google Cloud Permissions\n",
        "\n",
        "**To run the complete Notebook, including the optional section, you will need to have Owner permisions to the project.**\n",
        "\n",
        "If you want to skip the optional section, you need at least the following [roles](https://cloud.google.com/iam/docs/granting-changing-revoking-access):\n",
        "* **`roles/serviceusage.serviceUsageAdmin`** to enable APIs\n",
        "* **`roles/iam.serviceAccountAdmin`** to modify service agent permissions\n",
        "* **`roles/discoveryengine.admin`** to modify discoveryengine assets\n",
        "* **`roles/aiplatform.user`** to use AI Platform components\n",
        "* **`roles/storage.objectAdmin`** to modify and delete GCS buckets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## Install Vertex AI SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2b4ef9b72d43"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-discoveryengine --upgrade\n",
        "!pip install google-cloud-aiplatform --upgrade\n",
        "!pip install xhtml2pdf\n",
        "\n",
        "## If you're running outside of colab, make sure to install the following modules as well:\n",
        "# !pip install pandas\n",
        "# !pip install google\n",
        "# !pip install google-api-python-client\n",
        "# !pip install google-oauth\n",
        "# !pip install google-auth-oauthlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you may need to restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "You may see the restart reported as a crash, but it is working as-intended -- you are merely restarting the runtime.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate (Colab)\n",
        "\n",
        "If you're using Colab, run the code in the next cell. Follow the popups and authenticate with an account that has access to your Google Cloud [project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects).\n"
      ],
      "metadata": {
        "id": "7plalcaLGUik"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAihqmEKetF9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from google.auth import default\n",
        "from google.colab import auth as google_auth\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    google_auth.authenticate_user()\n",
        "\n",
        "creds, _ = default()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate (Outside Colab)\n",
        "\n",
        "If you're running this notebook somewhere besides Colab, make sure your environment has the right Google Cloud access. If that's a new concept to you, consider looking into [Application Default Credentials for your local environment](https://cloud.google.com/docs/authentication/provide-credentials-adc#local-dev) and [initializing the Google Cloud CLI](https://cloud.google.com/docs/authentication/gcloud). More authentication options are discussed [here](https://cloud.google.com/docs/authentication).\n",
        "\n",
        "Once the Google Cloud CLI is properly installed on your system, follow the instructions in the next cells to set up your ADC."
      ],
      "metadata": {
        "id": "HkGvv9mcjjEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting up Application Default Credentials\n",
        "\n",
        "Outside of Colab, you can authenticate through Google Cloud via Application Default Credentials.\n",
        "It is recommended that you set up a new configuration to run this notebook.\n",
        "\n",
        "To do so, open a terminal and run:\n",
        "\n",
        "`$ gcloud config configurations create CONFIG_NAME`\n",
        "\n",
        "This creates a new config with the specified name.\n",
        "\n",
        "\n",
        "💡 **NOTE:** You can list all available configurations by running\n",
        "`$ gcloud config configurations list` 💡\n",
        "\n",
        "\n",
        "\n",
        "The configuration should be activated automatically.\n",
        "Next, login with your account by running\n",
        "\n",
        "`$ gcloud auth login EMAIL_ADDRESS`\n",
        "\n",
        "Set your project:\n",
        "\n",
        "`$ gcloud config set project PROJECT_ID`\n",
        "\n",
        "You will likely get a warning that the active project doesn't match the quota project.\n",
        "To change this, run:\n",
        "\n",
        "`$ gcloud auth application-default set-quota-project PROJECT_ID`\n",
        "\n",
        "Confirm that the API cloudresourcemanager.googleapis.com will be enabled with Y.\n",
        "\n",
        "\n",
        "**You're ADC is all set now. Fetch your credentials by running the next cell:**"
      ],
      "metadata": {
        "id": "JiFvVCrfjfNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.auth import default\n",
        "creds, _ = default()"
      ],
      "metadata": {
        "id": "7VcW3ea9k90W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNcfOA7Ne0kP"
      },
      "source": [
        "## Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and enable all the APIs mentioned in the 'Getting Started' section of this notebook.\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"YOUR_PROJECT_ID\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
        "API_ENV = \"aiplatform.googleapis.com\"  # @param {type:\"string\"}\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "\n",
        "\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    api_endpoint=f\"{REGION}-{API_ENV}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a public Google Cloud Storage bucket"
      ],
      "metadata": {
        "id": "NUU5MAVF-agr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will further need a GCS bucket. For the scope of this notebook, we will create a public bucket by running the cells below.\n",
        "\n",
        "**Note:** This is needed to embed generated images into the pdf report further below. Alternatively, you can prompt the Code Interpreter to input the image links into the report instead of embedding them directly, and use your own non-public bucket instead."
      ],
      "metadata": {
        "id": "9oDrzqRm8_HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Select a **unique** name for your bucket\n",
        "GCS_BUCKET = \"my_testbucket\"  # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "6N2AoE0o8yMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "# Create a client object\n",
        "client = storage.Client(project=PROJECT_ID)\n",
        "\n",
        "# Create the bucket with public access\n",
        "bucket = client.create_bucket(GCS_BUCKET)\n",
        "bucket.make_public(future=True)  # Make the bucket publicly accessible\n",
        "\n",
        "print(f\"Public bucket {GCS_BUCKET} created successfully.\")"
      ],
      "metadata": {
        "id": "yeOhiKVX8P8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MFqpF8pfWPJ"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWMRFC3rfa2U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ossHfQf-4Swv"
      },
      "source": [
        "# Using Vertex AI Extensions to Analyze Game Reviews - Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgTdZdjBzrEN"
      },
      "source": [
        "## Step 1: Create a Code Interpreter Extension\n",
        "\n",
        "Now you can create the extension. The following cell uses the Python SDK to import the extension (thereby creating it) in Vertex AI Extensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-A82yCzDry5"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview import extensions\n",
        "\n",
        "extension_code_interpreter = extensions.Extension.from_hub(\"code_interpreter\")\n",
        "extension_code_interpreter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Interpreter Helper Functions\n",
        "\n",
        "These functions make it easier to inspect Code Interpreter's output, assemble Code Interprer requests, and run generated code."
      ],
      "metadata": {
        "id": "NLE3wb5VfhJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `process_response`\n",
        "\n",
        "`process_response` displays the generated code and any output files, shows the output from code execution, surfaces code execution errors, and saves output files.\n",
        "\n",
        "If the output of `process_response` looks strange, try making your noteboook window wider--this will help keep the HTML layout organized.\n",
        "\n",
        "**To use this functionality** call `process_response(response)`, where `response` is the Code Interpreter `response` object.\n"
      ],
      "metadata": {
        "id": "9NnhQmFLAHXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import json\n",
        "import pprint\n",
        "import pandas\n",
        "import sys\n",
        "import IPython\n",
        "if sys.version_info[0] < 3:\n",
        "    from StringIO import StringIO\n",
        "else:\n",
        "    from io import StringIO\n",
        "\n",
        "css_styles = \"\"\"\n",
        "<style>\n",
        ".main_summary {\n",
        "  font-weight: bold;\n",
        "  font-size: 14px; color: #4285F4;\n",
        "  background-color:rgba(221, 221, 221, 0.5); padding:8px;}\n",
        ".main_summary:hover {background-color: rgba(221, 221, 221, 1);}\n",
        "details {\n",
        "  background-color:#fff;\n",
        "  border: 1px solid #E8EAED;\n",
        "  padding:0px;\n",
        "  margin-bottom:2px; }\n",
        "details img {width:50%}\n",
        "details > div {padding:10px; }\n",
        "div#left > * > div {\n",
        "    overflow:auto;\n",
        "    max-height:400px; }\n",
        "\n",
        "div#right > pre {\n",
        "    overflow:auto;\n",
        "    max-height:600px;\n",
        "    background-color: ghostwhite;\n",
        "    padding: 10px; }\n",
        "details details > div { overflow: scroll; max-height:400px}\n",
        "details details {\n",
        "  background-color:rgba(246, 231, 217, 0.2);\n",
        "  border: 1px solid #FBBC04;}\n",
        "details details > summary {\n",
        "  padding: 8px;\n",
        "  background-color:rgba(255, 228, 196, 0.6); }\n",
        "details details > summary:hover { background-color:rgba(255, 228, 196, 0.9); }\n",
        "div#left {width: 64%; padding:0 1%;  }\n",
        "div#right {\n",
        "  border-left: 1px solid silver;\n",
        "  width: 30%;\n",
        "  float: right;\n",
        "  padding:0 1%; }\n",
        "body {color: #000; background-color: white; padding:10px 10px 40px 10px; }\n",
        "#main { border: 1px solid #FBBC04; padding:10px 0; display: flow-root; }\n",
        "h3 {color: #000; }\n",
        "code  { font-family: monospace; color: #900; padding: 0 2px; font-size: 105%; }\n",
        "</style>\n",
        "        \"\"\"\n",
        "\n",
        "# Parser to visualise the content of returned files as HTML.\n",
        "def parse_files_to_html(outputFiles, save_files_locally = True):\n",
        "    IMAGE_FILE_EXTENSIONS = set([\"jpg\", \"jpeg\", \"png\"])\n",
        "    file_list = []\n",
        "    details_tml = \"\"\"<details><summary>{name}</summary><div>{html_content}</div></details>\"\"\"\n",
        "\n",
        "    if not outputFiles:\n",
        "      return \"No Files generated from the code\"\n",
        "    # Sort output_files so images are displayed before other files such as JSON.\n",
        "    for output_file in sorted(\n",
        "        outputFiles,\n",
        "        key=lambda x: x[\"name\"].split(\".\")[-1] not in IMAGE_FILE_EXTENSIONS,\n",
        "    ):\n",
        "        file_name = output_file.get(\"name\")\n",
        "        file_contents = base64.b64decode(output_file.get(\"contents\"))\n",
        "        if save_files_locally:\n",
        "          open(file_name,\"wb\").write(file_contents)\n",
        "\n",
        "        if file_name.split(\".\")[-1] in IMAGE_FILE_EXTENSIONS:\n",
        "            # Render Image\n",
        "            file_html_content = ('<img src=\"data:image/png;base64, '\n",
        "                                f'{output_file.get(\"contents\")}\" />')\n",
        "        elif file_name.endswith(\".json\"):\n",
        "            # Pretty print JSON\n",
        "            json_pp = pprint.pformat(\n",
        "                        json.loads(file_contents.decode()),\n",
        "                        compact=False,\n",
        "                        width=160)\n",
        "            file_html_content =  (f'<span>{json_pp}</span>')\n",
        "        elif file_name.endswith(\".csv\"):\n",
        "            # CSV\n",
        "            csv_md = pandas.read_csv(\n",
        "                  StringIO(file_contents.decode())).to_markdown(index=False)\n",
        "            file_html_content = f'<span>{csv_md}</span>'\n",
        "        elif file_name.endswith(\".pkl\"):\n",
        "            # PKL\n",
        "            file_html_content = f'<span>Preview N/A</span>'\n",
        "        else:\n",
        "            file_html_content = f\"<span>{file_contents.decode()}</span>\"\n",
        "\n",
        "        file_list.append({'name': file_name, \"html_content\": file_html_content})\n",
        "\n",
        "    buffer_html = [ details_tml.format(**_file) for _file in file_list ]\n",
        "    return \"\".join(buffer_html)\n",
        "\n",
        "# Processing code interpreter response to html visualization.\n",
        "def process_response(response: dict, save_files_locally = True) -> None:\n",
        "\n",
        "  result_template = \"\"\"\n",
        "  <details open>\n",
        "    <summary class='main_summary'>{summary}:</summary>\n",
        "    <div><pre>{content}</pre></div>\n",
        "  </details>\n",
        "  \"\"\"\n",
        "\n",
        "  result = \"\"\n",
        "  code = response.get('generated_code')\n",
        "  if 'execution_result' in response and response['execution_result']!=\"\":\n",
        "    result = result_template.format(\n",
        "        summary=\"Executed Code Output\",\n",
        "        content=response.get('execution_result'))\n",
        "  else:\n",
        "    result = result_template.format(\n",
        "      summary=\"Executed Code Output\",\n",
        "      content=\"Code does not produce printable output.\")\n",
        "\n",
        "  if response.get('execution_error', None):\n",
        "    result += result_template.format(\n",
        "        summary=\"Generated Code Raised a (Possibly Non-Fatal) Exception\",\n",
        "        content=response.get('execution_error', None))\n",
        "\n",
        "  result += result_template.format(\n",
        "    summary=\"Files Created <u>(Click on filename to view content)</u>\",\n",
        "    content=parse_files_to_html(\n",
        "        response.get('output_files', []),\n",
        "        save_files_locally = True))\n",
        "\n",
        "  display(\n",
        "      IPython.display.HTML(\n",
        "        ( f\"{css_styles}\"\n",
        "f\"\"\"\n",
        "<div id='main'>\n",
        "    <div id=\"right\">\n",
        "      <h3>Generated Code by Code Interpreter</h3>\n",
        "      <pre><code>{code}</code></pre>\n",
        "    </div>\n",
        "    <div id=\"left\">\n",
        "      <h3>Code Execution Results</h3>\n",
        "      {result}\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "        )\n",
        "      )\n",
        "  )"
      ],
      "metadata": {
        "id": "Md76P2cH_qMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `run_code_interpreter`\n",
        "`run_code_interpreter` eases calling Code Interpreter by encoding files to base 64 (a Code Interpreter requirement) and submitting the files alongside the instructions. It also automates retries (5 by default) if the generated code doesn't execute or if Code Interpreter fails due to exceeding Gemini (time-based) quotas. Additionally, a global `CODE_INTERPRETER_WRITTEN_FILES` variable is populated by `run_code_interpreter` to aid with cleaning up files created by Code Intprereter.\n",
        "\n",
        "**To use this functionality**  call `run_code_interpreter(instructions, filenames, retry_num, retry_wait_time)`\n",
        "where `instructions` is the prompt for Code Interpreter, `filenames` is a list of local files in the working directory to submit to Code Interpreter, optionally `retry_num` if you want to change the default number of retries from 5, and optionally `retry_wait_time` if you want to change the default 15 second wait between retries."
      ],
      "metadata": {
        "id": "9UYWV1OYEYz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "\n",
        "global CODE_INTERPRETER_WRITTEN_FILES\n",
        "CODE_INTERPRETER_WRITTEN_FILES = []\n",
        "\n",
        "def run_code_interpreter(instructions: str,\n",
        "                         filenames: list[dict] = [],\n",
        "                         retry_num: int = 5,\n",
        "                         retry_wait_time: int = 15) -> dict['str', 'str']:\n",
        "\n",
        "  global CODE_INTERPRETER_WRITTEN_FILES\n",
        "\n",
        "  file_arr = [\n",
        "      {\n",
        "          \"name\": filename,\n",
        "          \"contents\":  base64.b64encode(open(filename, \"rb\").read()).decode()\n",
        "      }\n",
        "      for filename in filenames\n",
        "  ]\n",
        "\n",
        "  attempts = 0\n",
        "  res = {}\n",
        "\n",
        "  while attempts <= retry_num:\n",
        "    attempts += 1\n",
        "\n",
        "    res = extension_code_interpreter.execute(\n",
        "        operation_id = \"generate_and_execute\",\n",
        "        operation_params = {\n",
        "            \"query\": instructions,\n",
        "            \"files\": file_arr\n",
        "        },\n",
        "    )\n",
        "\n",
        "    CODE_INTERPRETER_WRITTEN_FILES.extend(\n",
        "        [item['name'] for item in res['output_files']])\n",
        "\n",
        "    if not res.get('execution_error', None):\n",
        "      return res\n",
        "    elif attempts <= retry_num:\n",
        "      print(f\"The generated code produced an error {res.get('execution_error')}\"\n",
        "            f\" -Automatic retry attempt # {attempts}/{retry_num}\")"
      ],
      "metadata": {
        "id": "L2xJ63r2EZGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `run_locally`\n",
        "`run_locally` executes code generated by Code Interpreter.\n",
        "\n",
        "**To use this functionality**  call `run_locally(response)` with the `response` object returned by Code Interpreter.\n",
        "\n",
        "Note: to avoid unexpected issues you should always inspect generated code before you run it locally."
      ],
      "metadata": {
        "id": "s-T0SwZbNxmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_locally(response):\n",
        "  my_code = \"\\n\".join(response['generated_code'].split('\\n')[1:-1])\n",
        "  exec(my_code)"
      ],
      "metadata": {
        "id": "m6pn9muMNx6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCjnPm_lyWz"
      },
      "source": [
        "## Step 2: Use Code Interpreter to Analyze Steam Reviews\n",
        "\n",
        "In this section, you will specify a game title and parse some steam reviews for the title from store.steampowered.com.\n",
        "Using the Code Interpreter extension, you will then perform automated analysis on the reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O9PZdlhGNLm"
      },
      "outputs": [],
      "source": [
        "#@markdown Specify the name of the game\n",
        "game = \"Palworld\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcr6drreG_jE"
      },
      "source": [
        "### Prepare the Reviews Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uusyDyPfC5L"
      },
      "source": [
        "Now, grab the steam App ID for the game, if the game is supported on the platform. For this, we will do a Google Search to retrieve the Steam Game URL, and parse the ID out of the URL.\n",
        "\n",
        "**Note:** if you are facing errors with importing googlesearch, make sure that you don't have any conflicting packages installed. This is the googlesearch module that's installed when running `pip install google`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDZ5EcodfCjn"
      },
      "outputs": [],
      "source": [
        "# Fetch steam review URL and the games App ID\n",
        "from googlesearch import search\n",
        "\n",
        "query = f\"{game} steampowered.com \"\n",
        "steam_url = list()\n",
        "\n",
        "for j in search(query, tld=\"com\", num=1, stop=1, pause=1):\n",
        "    print(\"URL: \",j)\n",
        "    steam_url.append(j)\n",
        "\n",
        "try:\n",
        "  steam_url = steam_url[0].split('app/')[1]\n",
        "  steam_appId = steam_url.split('/')[0]\n",
        "\n",
        "  print(\"App ID: \", steam_appId)\n",
        "\n",
        "except:\n",
        "  print(\"Could not parse the steam ID out of the URL. The game is likely not supported on Steam.\")\n",
        "  steam_appId = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAVahl-_NlO7"
      },
      "source": [
        "Now, grab some reviews from steam.\n",
        "The steam website loads infinitely and does not allow to search through the pages by the url. So we are limited to retrieving 10 hits for now.\n",
        "To circumvent, we will set five different filters to get the reviews:\n",
        "1. Top rated reviews of all time\n",
        "2. Trending reviews today\n",
        "3. Trending reviews this week\n",
        "4. Trending reviews this month  \n",
        "5. Most recent reviews\n",
        "\n",
        "This will give us a total of 50 reviews to work with.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frMOHXzG9vV7"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "def get_steam_reviews(filter, num_reviews=10):\n",
        "    \"\"\"\n",
        "    Fetches Steam reviews for a given filter and number of reviews.\n",
        "\n",
        "    Args:\n",
        "        filter (str): The filter type (e.g., 'toprated', 'trendweek').\n",
        "        num_reviews (int): The desired number of reviews to fetch. Defaults to 10.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each representing a review with\n",
        "            'author', 'content', 'rating', 'date', and 'hours_played' keys.\n",
        "    \"\"\"\n",
        "    url = f'https://steamcommunity.com/app/{steam_appId}/reviews/?p=1&browsefilter={filter}'\n",
        "\n",
        "    print(\"URL: \", url)\n",
        "\n",
        "    reviews = []\n",
        "\n",
        "    # Iterate over reviews until we have num_reviews\n",
        "    while len(reviews) < num_reviews:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        review_blocks = soup.find_all('div', class_='apphub_Card') #find all review cards\n",
        "\n",
        "        for block in review_blocks:\n",
        "            #print(\"\\nReview Block: \\n\", block)\n",
        "\n",
        "            # Author\n",
        "            author_block = block.find('div', class_='apphub_CardContentAuthorName') #fetch author\n",
        "            if author_block:\n",
        "                author = author_block.text.strip()\n",
        "\n",
        "            # Rating\n",
        "            rating_block = block.find('div', class_='title') #fetch title\n",
        "            if rating_block:\n",
        "                rating = rating_block.text.strip()\n",
        "\n",
        "            # Review Content\n",
        "            content_block = block.find('div', class_='apphub_CardTextContent') #fetch content\n",
        "            if content_block:\n",
        "                content = content_block.text.strip()\n",
        "\n",
        "            # Review Date\n",
        "            date_block = content_block.find('div', class_='date_posted') #fetch date\n",
        "            if date_block:\n",
        "                date = date_block.text.replace('Posted:', '').strip()\n",
        "\n",
        "            # Total Hours Played\n",
        "            hours_block = block.find('div', class_='hours') #fetch total hours played\n",
        "            if hours_block:\n",
        "                hours_played = hours_block.text.strip()\n",
        "\n",
        "\n",
        "            reviews.append({'author': author, 'content': content, 'rating': rating, 'date': date, 'hours_played' : hours_played})\n",
        "\n",
        "\n",
        "            if len(reviews) >= num_reviews:\n",
        "                break\n",
        "\n",
        "    return reviews\n",
        "\n",
        "topRated_reviews = get_steam_reviews('toprated')\n",
        "trendWeek_reviews = get_steam_reviews('trendweek')\n",
        "trendMonth_reviews = get_steam_reviews('trendmonth')\n",
        "trendDay_reviews = get_steam_reviews('trendday')\n",
        "mostRecent_reviews = get_steam_reviews('mostrecent')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUOEgt73GWVJ"
      },
      "source": [
        "Concatenate all the reviews in one single list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9g6hW5-OvDe"
      },
      "outputs": [],
      "source": [
        "all_reviews = topRated_reviews + trendWeek_reviews + trendMonth_reviews+ trendDay_reviews+ mostRecent_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPFrofM0nGub"
      },
      "source": [
        "Write the reviews into a .csv file so you can parse it with the Code Interpreter extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOy00HlTR12H"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "filename = 'reviews.csv'\n",
        "\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "    # Determine field names (header row)\n",
        "    fieldnames = all_reviews[0].keys()\n",
        "\n",
        "    # Create a DictWriter\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    # Write the header\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write the data rows\n",
        "    writer.writerows(all_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqhj_DBMGpUR"
      },
      "source": [
        "Get the reviews in a pandas dataframe, so you can take a look into its content and inspect the reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSrIOYG0FRkV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('reviews.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4guwwt37G2_F"
      },
      "source": [
        "### Let Code Interpreter do its Magic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNWQ7DttHHEe"
      },
      "source": [
        "Write a helper function to collect all of the assets created by a Vertex AI Extension. This will help later when generating the PDF Report and with cleaning up the generated files afterwards. For this purpose, this function collects the file names of any generated images from Code Interpreter Extension as well as the text outputs generated by the Vertex AI Search Extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq7gEArxoqn9"
      },
      "outputs": [],
      "source": [
        "output_list = []\n",
        "\n",
        "def is_string(value):\n",
        "    return isinstance(value, str)\n",
        "\n",
        "def grab_outs(response):\n",
        "  # Check if response is a string from Search Extension\n",
        "  if is_string(response):\n",
        "    output_list.append(response)\n",
        "\n",
        "  # Else it's a dict output from Code Interpreter Extension\n",
        "  else:\n",
        "    for dict in response['output_files']:\n",
        "      output_list.append(dict[\"name\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3edqBaVHUaq"
      },
      "source": [
        "You can call the Vertex AI Code Interpreter Extension to generate plots and graphs on your dataset. However, you can also ask the Code Interpreter extension to take a look at the dataset for you and generate a few ideas for insightful visualizations. The following cell prompts the Code Interpreter extension to save some plot ideas in the ideas.txt file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6yjvRipGlX3"
      },
      "outputs": [],
      "source": [
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "You are given a dataset of reviews. I want you to come up with some ideas for relevant visualization for this dataset.\n",
        "Create natural language **instructions** and save them into the file ideas.txt\n",
        "Please put your ideas as natural language **instructions** into the file ideas.txt\n",
        "Do not generate any plots yourself.\n",
        "\"\"\", filenames= ['reviews.csv'])\n",
        "process_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFNhqz4Bb5cV"
      },
      "source": [
        "That looks interesting! You could go ahead and parse these ideas automatically by another Code Interpreter extension call. We will see an optional cell below on how to do that. But for now, we want to reformulate things a bit, so let's go ahead and plot some of the ideas above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyvNv5APRYn_"
      },
      "outputs": [],
      "source": [
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "    You are given a dataset of reviews. Create a pie chart showing the following:\n",
        "    - how many ratings have 'recommended' vs 'not recommended'?\n",
        "    Save the plot with a descriptive name.\n",
        "\"\"\", filenames= ['reviews.csv'])\n",
        "process_response(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ5PFHQWmSNr"
      },
      "outputs": [],
      "source": [
        "# Grab the output if it looks good.\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxPsjO7mJwzd"
      },
      "source": [
        "Easy peasy. But what if we want to generate a more complex plot with the Code Interpreter extension? You can try that with the next cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFsFZN4mU1uN"
      },
      "outputs": [],
      "source": [
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "    You are given a dataset of reviews. The hours_played column contains information on the total hours played, in the format '3,650.6 hrs on record' or '219.6 hrs on record'.\n",
        "    Avoid and handle conversion errors, e.g. 'could not convert string to float: '3,650.6''.\n",
        "    Make a plot that shows the relationship between hours played and the count of the ratings 'Not Recommended'.\n",
        "    Put the hours_played into the different buckets 0-50, 50-100, 100-1000, >1000.\n",
        "    Save the plot with a descriptive name.\n",
        "\n",
        "    Make sure Plots have visible numbers or percentages when applicable, and labels.\n",
        "    Make sure to avoid and handle the error 'Expected value of kwarg 'errors' to be one of ['raise', 'ignore']. Supplied value is 'coerce' '.\n",
        "    Use >>> import warnings\n",
        "    warnings.simplefilter(action='ignore', category=FutureWarning) <<< to avoid any FutureWarnings from pandas.\n",
        "\n",
        "    \"\"\", filenames= ['reviews.csv'])\n",
        "process_response(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDn1ZHbol5Bl"
      },
      "outputs": [],
      "source": [
        "# Grab the output if it looks good.\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrcJUnyETErU"
      },
      "source": [
        "###Optional: Plotting ideas.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFgEjmyyKETT"
      },
      "source": [
        "**OPTIONAL**: You can also parse the plot ideas that Code Interpreter extension created and use it as a direct set of instructions when making another call to Code Interpreter.\n",
        "Code Interpreter may generate some weird plots at this step - this is usually because the instructions are not clearly defined.\n",
        "\n",
        "💡**Tip**: you will need to grab the instructions form the ideas.txt file and put them along in the prompt, instead of passing the file over in the filenames. Code Interpreter is not parsing any instructions from attached files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Q0ntCZvlY0sH"
      },
      "outputs": [],
      "source": [
        "with open('ideas.txt', 'r', encoding='utf-8') as file:\n",
        "    ideas = file.read()\n",
        "\n",
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "    Create and save the following plots.\n",
        "    Make sure each plot is in  its own file and do not overlay multiple plots so for every plot reset the process.\n",
        "    Save the plot with a descriptive name.\n",
        "    Make sure Plots have visible numebers or percentages, when applicable, and labels.\n",
        "    Do not use the library 'wordcloud', it's not available. Skip an idea if it uses wordcloud.\n",
        "    Make sure to avoid 'Rectangle.set() got an unexpected keyword argument 'kind''\n",
        "    Make sure to surpress any user warnings.\n",
        "    **If any of the following produces an exception make sure you catch and print it, and continue to the next item in the list**:\n",
        "    {str(ideas)}\n",
        "\"\"\", filenames= ['reviews.csv'])\n",
        "process_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFUC9V4NKR5V"
      },
      "source": [
        "## Step 3: Use Vertex AI Search Extension to do a Qualitative Analysis of the Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For using the Vertex AI Search Extension, please grant the [Vertex AI Extension Service agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) the [permission needed](https://cloud.google.com/vertex-ai/docs/general/access-control#home-project) by following the UI instructions or by running the next cell.\n",
        "\n",
        "To do so in the UI:\n",
        "1. Go to https://console.cloud.google.com/iam-admin/iam\n",
        "2. Make sure you're in the right project.\n",
        "3. Enable the checkfield `Include Google-provided role grants`. This will show you the active service accounts in your project.\n",
        "4. Locate the service agent with the name **Vertex AI Extension Service Agent**.\n",
        "5. Click on the pen icon to edit the roles for this service agent.\n",
        "6. Click on `add another role` and add **Discovery Engine Editor**.\n",
        "7. Save the changes.\n",
        "\n",
        "\n",
        "**Alternatively, run the next cell to assign the role to the Service Agent programmatically:**"
      ],
      "metadata": {
        "id": "wQYE7e8lrwR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash -s \"$PROJECT_ID\"\n",
        "\n",
        "# Get project number using gcloud\n",
        "PROJECT_NUMBER=$(gcloud projects describe $1 --format=\"value(projectNumber)\")\n",
        "\n",
        "# Service agent email\n",
        "SERVICE_AGENT_EMAIL=\"service-$PROJECT_NUMBER@gcp-sa-vertex-ex.iam.gserviceaccount.com\"\n",
        "\n",
        "# Role to add\n",
        "ROLE=\"roles/discoveryengine.editor\"\n",
        "\n",
        "# Add the role using gcloud CLI (with the correct service agent email)\n",
        "gcloud projects add-iam-policy-binding $1 \\\n",
        "    --member=\"serviceAccount:$SERVICE_AGENT_EMAIL\" \\\n",
        "    --role=$ROLE\n"
      ],
      "metadata": {
        "id": "XKpHduryrxx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TaNXRnqL1Lu"
      },
      "source": [
        "### Set Up Qualitative Review Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWO5fNxGe9JX"
      },
      "source": [
        "Grab some more detailed reviews of the game for qualitative analysis. For this, you can use google search to get urls of the top 10 results for the game's reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFMCT89eG7qY"
      },
      "outputs": [],
      "source": [
        "from googlesearch import search\n",
        "\n",
        "# Search\n",
        "query = f\"{game} Reviews\"\n",
        "urls = list()\n",
        "\n",
        "for j in search(query, tld=\"com\", num=10, stop=10, pause=2):\n",
        "    print(j)\n",
        "    urls.append(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNHMCmZJfjdJ"
      },
      "source": [
        "We want the Vertex AI Search extension to summarize the contents for us and to answer our questions. To do this, we could manually grab the above URLs and set up a data store for websites in the Google Cloud Console.\n",
        "\n",
        "But, we want to ensure cleaner results. For this reason, first fetch the text contents from the websites, then store the .txt files in your Google Cloud Storage Bucket."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTAhUI7DT8Ek"
      },
      "source": [
        "The following cell lets you grab the contents from the websites and write them into .txt files. Then, these files will be uploaded to your GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqsfwqQdGVq5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "from google.cloud import storage\n",
        "\n",
        "def url_txt_to_gcs(id, url, filename, bucket_name):\n",
        "\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract all text content\n",
        "    all_text = soup.get_text(separator='\\n', strip=True)\n",
        "\n",
        "    # Save to .txt file\n",
        "    with open(filename, \"w\", encoding='utf-8') as file:\n",
        "        file.write(id +\"\\n\"+ all_text)\n",
        "\n",
        "    # Upload\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(filename)\n",
        "\n",
        "    # Assuming the file is in the root of your Colab temp directory\n",
        "    local_temp_path = os.path.join(filename)\n",
        "    blob.upload_from_filename(local_temp_path)\n",
        "\n",
        "    print(f\"File uploaded to gs://{bucket_name}/{filename}\")\n",
        "\n",
        "\n",
        "# Upload the website content .txt files into GCS\n",
        "txt_files = []\n",
        "\n",
        "for idx, url in enumerate(urls):\n",
        "  id = \"doc-\"+str(idx)\n",
        "  filename = f\"website_text_{idx}.txt\"\n",
        "  txt_files.append(f\"website_text_{idx}.txt\")\n",
        "  url_txt_to_gcs(id, url, filename, GCS_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsZUGcCSgMFw"
      },
      "source": [
        "### Create a Search Data Store and Ingest your Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTpr3AoY10Hp"
      },
      "source": [
        "The Vertex AI Search extension needs a **Data Store** and **Vertex Search Engine** to run. [You can learn more about Data Stores and Vertex Search Engines here](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest).\n",
        "\n",
        "The following cells will help you in the setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmKy60yIivpb"
      },
      "outputs": [],
      "source": [
        "# @markdown Specify an id for your datastore. It should only use lowercase letters.\n",
        "data_store_id = \"gamereview-extensions\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwLU9sb6UWvK"
      },
      "source": [
        "Use the following bash command to **create** your Data Store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOLi7KS5gR0P"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$PROJECT_ID\" \"$data_store_id\"\n",
        "\n",
        "curl -X POST \\\n",
        "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-H \"X-Goog-User-Project: $1\" \\\n",
        "\"https://discoveryengine.googleapis.com/v1alpha/projects/$1/locations/global/collections/default_collection/dataStores?dataStoreId=$2\" \\\n",
        "-d '{\n",
        "  \"displayName\": \"GameReview-Extensions-Store\",\n",
        "  \"industryVertical\": \"GENERIC\",\n",
        "  \"solutionTypes\": [\"SOLUTION_TYPE_SEARCH\"],\n",
        "  \"contentConfig\": \"CONTENT_REQUIRED\",\n",
        "}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEMZ-vPVWO9O"
      },
      "source": [
        "🎉 Your Data Store is all set! You can inspect it under: https://console.cloud.google.com/gen-app-builder/data-stores\n",
        "\n",
        "Now you just need to **ingest** your .txt files with the website contents into it by running the cell below.\n",
        "\n",
        "**This process can take somewhere between 5-10 mins.** The cell will finish running once the ingestion is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MT6vj3nr6T8e"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from google.api_core.client_options import ClientOptions\n",
        "from google.cloud import discoveryengine\n",
        "\n",
        "def import_documents_sample(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    data_store_id: str,\n",
        "    gcs_uri: Optional[str] = None,\n",
        ") -> str:\n",
        "    \"\"\"Imports documents into a Vertex AI data store from GCS.\n",
        "\n",
        "    This function imports documents into a specified data store within Vertex AI Agent Builder\n",
        "    from a GCS bucket. It uses the incremental reconciliation\n",
        "    mode, which adds new documents and updates existing ones.\n",
        "\n",
        "    Args:\n",
        "        project_id: The ID of the Google Cloud project.\n",
        "        location: The region where the data store is located (e.g., \"us-central1\").\n",
        "        data_store_id: The ID of the data store.\n",
        "        gcs_uri: The GCS URI of the documents to import (e.g., \"gs://my-bucket/docs/*.txt\").\n",
        "\n",
        "    Returns:\n",
        "        str: The name of the long-running operation that imports the documents.\n",
        "\n",
        "    Raises:\n",
        "        google.api_core.exceptions.GoogleAPICallError: If the API call fails.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    client_options = (\n",
        "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
        "        if location != \"global\"\n",
        "        else None\n",
        "    )\n",
        "\n",
        "    # Create a client\n",
        "    client = discoveryengine.DocumentServiceClient(client_options=client_options)\n",
        "\n",
        "    # The full resource name of the search engine branch.\n",
        "    # e.g. projects/{project}/locations/{location}/dataStores/{data_store_id}/branches/{branch}\n",
        "    parent = client.branch_path(\n",
        "        project=project_id,\n",
        "        location=location,\n",
        "        data_store=data_store_id,\n",
        "        branch=\"default_branch\",\n",
        "    )\n",
        "\n",
        "    request = discoveryengine.ImportDocumentsRequest(\n",
        "        parent=parent,\n",
        "        gcs_source=discoveryengine.GcsSource(\n",
        "            input_uris=[gcs_uri], data_schema=\"content\"\n",
        "        ),\n",
        "        # Options: `FULL`, `INCREMENTAL`\n",
        "        reconciliation_mode=discoveryengine.ImportDocumentsRequest.ReconciliationMode.INCREMENTAL,\n",
        "    )\n",
        "\n",
        "\n",
        "    # Make the request\n",
        "    operation = client.import_documents(request=request)\n",
        "\n",
        "    print(f\"Waiting for operation to complete: {operation.operation.name}\")\n",
        "    response = operation.result()\n",
        "\n",
        "    # Once the operation is complete,\n",
        "    # get information from operation metadata\n",
        "    metadata = discoveryengine.ImportDocumentsMetadata(operation.metadata)\n",
        "\n",
        "    # Handle the response\n",
        "    print(response)\n",
        "    print(metadata)\n",
        "\n",
        "    return operation.operation.name\n",
        "\n",
        "\n",
        "gcs_uri = f\"gs://{GCS_BUCKET}/*.txt\" # grabs all the .txt files we generated\n",
        "import_documents_sample(PROJECT_ID, 'global', data_store_id, gcs_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwcBGeljauNR"
      },
      "source": [
        "### Connect Data Store to a Vertex AI Search Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h87Jzly6ax7d"
      },
      "source": [
        "The following cell let's you create a Vertex AI Search Engine to connect to your newly created Data Store. For the Vertex AI Search Extension to work, we need to enable Enterprise features by setting `\"searchTier\": \"SEARCH_TIER_ENTERPRISE\" `and Advanced LLM Features by setting `\"searchAddOns\": [\"SEARCH_ADD_ON_LLM\"]` in the code cell below.\n",
        "\n",
        "**These settings will be set automatically by running the cell below.**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu8919bNaybd"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$PROJECT_ID\" \"$data_store_id\"\n",
        "\n",
        "curl -X POST \\\n",
        "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-H \"X-Goog-User-Project: $1\" \\\n",
        "\"https://discoveryengine.googleapis.com/v1/projects/$1/locations/global/collections/default_collection/engines?engineId=$2\" \\\n",
        "-d '{\n",
        "  \"displayName\": \"game-review-engine\",\n",
        "  \"dataStoreIds\": [\"'$2'\"],\n",
        "  \"solutionType\": \"SOLUTION_TYPE_SEARCH\",\n",
        "  \"searchEngineConfig\": {\n",
        "     \"searchTier\": \"SEARCH_TIER_ENTERPRISE\",\n",
        "     \"searchAddOns\": [\"SEARCH_ADD_ON_LLM\"]\n",
        "   }\n",
        "}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8n2cU8eXyKD"
      },
      "source": [
        "### Set up the Vertex AI Search Extension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvcXnnFxX6f-"
      },
      "source": [
        "Your Data Store and Search Engine are all set. Now you just need to create an instance of the Vertex AI Search Extension by running the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXggbziVKPC2"
      },
      "outputs": [],
      "source": [
        "# Construct an object that points to the relevant data store\n",
        "DATASTORE = f\"projects/{PROJECT_ID}/locations/global/collections/default_collection/dataStores/{data_store_id}/servingConfigs/default_search\"\n",
        "\n",
        "# Instantiate extension\n",
        "extension_vertex_ai_search = extensions.Extension.from_hub(\n",
        "    \"vertex_ai_search\",\n",
        "    runtime_config={\n",
        "        \"vertex_ai_search_runtime_config\": {\n",
        "            \"serving_config_name\": DATASTORE,\n",
        "        }\n",
        "    })\n",
        "\n",
        "extension_vertex_ai_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WcNCzR5NgEG"
      },
      "source": [
        "The following is a helper function. We can let the Vertex AI Search Engine generate an answer for our prompt directly. However, for a more descriptive response, we can retrieve the segment matches provided by the search engine and let Gemini generate an answer over it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zCrkC_OgJjY"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.generative_models import GenerativeModel, Part\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
        "\n",
        "# Helper function\n",
        "def get_vertexSearch_response(QUERY, mode):\n",
        "  \"\"\"Queries Vertex AI Search and generates a response using either Vertex Search or Gemini.\n",
        "\n",
        "  This function takes a query and a mode as input. It first sends the query to Vertex AI Search.\n",
        "  Depending on the specified mode, it either:\n",
        "\n",
        "  - Returns the extractive answers directly from Vertex AI Search (mode='vertex').\n",
        "  - Uses the extractive segments from Vertex AI Search as context for Gemini to generate a more\n",
        "    comprehensive response (mode='gemini').\n",
        "\n",
        "  Args:\n",
        "      QUERY: The query string to send to Vertex AI Search.\n",
        "      mode: The response generation mode, either 'vertex' or 'gemini'.\n",
        "\n",
        "  Returns:\n",
        "      str: The generated response, either from Vertex AI Search or Gemini.\n",
        "\n",
        "  Raises:\n",
        "      ValueError: If the `mode` is not 'vertex' or 'gemini'.\n",
        "      vertexai.preview.generative_models.errors.GenerativeModelError: If the Gemini API call fails.\n",
        "  \"\"\"\n",
        "  vertex_ai_search_response = extension_vertex_ai_search.execute(\n",
        "    operation_id = \"search\",\n",
        "    operation_params = {\"query\": QUERY},\n",
        "  )\n",
        "\n",
        "  # Let Vertex Search Extension generate a response\n",
        "  if mode == 'vertex':\n",
        "    list_extractive_answers = []\n",
        "    for i in vertex_ai_search_response:\n",
        "      list_extractive_answers.append(i[\"extractive_answers\"][0])\n",
        "      return list_extractive_answers\n",
        "\n",
        "\n",
        "  # Let Gemini generate a response over the Vertex Search Extension segments\n",
        "  elif mode == 'gemini':\n",
        "    list_extractive_segments = []\n",
        "\n",
        "    for i in vertex_ai_search_response:\n",
        "      list_extractive_segments.append(i[\"extractive_segments\"][0])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Prompt: {QUERY};\n",
        "    Contents: {str(list_extractive_segments)}\n",
        "    \"\"\"\n",
        "\n",
        "    res = model.generate_content(\n",
        "        prompt,\n",
        "        generation_config={\n",
        "            \"max_output_tokens\": 2048,\n",
        "            \"temperature\": 0.1,\n",
        "            \"top_p\": 1\n",
        "        },\n",
        "        safety_settings={\n",
        "              generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "              generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "              generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "              generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "        },\n",
        "        stream=False,\n",
        "      )\n",
        "\n",
        "    return res.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G-jUjCjOsSk"
      },
      "source": [
        "### Use Vertex AI Search Extension to answer Questions and retrieve Summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrT-HTS3POFg"
      },
      "source": [
        "Now you can run Vertex AI Search Extension. The cell below demonstrates an output of Vertex AI Search Engine without Gemini.\n",
        "\n",
        "ㅤ\n",
        "\n",
        "❗❗❗ **NOTE:** if you are facing the following error:\n",
        "\n",
        "`FailedPrecondition: 400 Cannot use enterprise edition features (website search, multi-modal search, extractive answers/segments, etc.) in a standard edition search engine...`\n",
        "\n",
        "\n",
        "when running the cell below, simply wait a few minutes and try to run the cell again. That means the settings from the Vertex AI Search Engine creation have not yet propagated to the system. ❗❗❗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgX31Eug83YV"
      },
      "outputs": [],
      "source": [
        "QUERY = f\"What are some negative review points for {game}?\" # @param {type:\"string\"}\n",
        "\n",
        "search_res = get_vertexSearch_response(QUERY, mode='vertex')\n",
        "\n",
        "search_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-U047_vPZYe"
      },
      "source": [
        "The following cell highlights the differences between the pure Vertex AI Search Extension output above, and the hybrid response generated with Gemini below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSPriyrGjXdo"
      },
      "outputs": [],
      "source": [
        "QUERY = f\"List 10 positive review points for {game}\"\n",
        "\n",
        "response = get_vertexSearch_response(QUERY, mode='gemini')\n",
        "\n",
        "print(response)\n",
        "\n",
        "# Grab the output for report generation\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQvZPXx7PlsS"
      },
      "source": [
        "Looks good. Collect more information from the website contents by giving the extension some more prompts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TNJ2BddhiWw"
      },
      "outputs": [],
      "source": [
        "QUERY = f\"List 10 negative review points for {game}\"\n",
        "\n",
        "response = get_vertexSearch_response(QUERY, mode='gemini')\n",
        "\n",
        "response\n",
        "\n",
        "# Grab the output for report generation\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26YnYGWtPsIn"
      },
      "outputs": [],
      "source": [
        "QUERY = f\"Provide a summary description of the game {game}\"\n",
        "\n",
        "response = get_vertexSearch_response(QUERY, mode='gemini')\n",
        "\n",
        "response\n",
        "\n",
        "# Grab the output for report generation\n",
        "grab_outs(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAkfc7-i3hdg"
      },
      "source": [
        "## Step 4: Populate your Results in a PDF Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8EKZ_SRky90"
      },
      "source": [
        "Now it's time to put everything together. We have collected the generated responses (both images and texts) from Vertex AI Code Interpreter and Search Extensions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8KCzXfMuZx6"
      },
      "outputs": [],
      "source": [
        "output_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next you need to fetch the image filenames from the output_list:"
      ],
      "metadata": {
        "id": "5c8uaAW2GUSJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9sQ7kKx0qjE"
      },
      "outputs": [],
      "source": [
        "imgs_files = []\n",
        "other_files = []\n",
        "txt_outs = []\n",
        "\n",
        "for element in output_list:\n",
        "  if \".png\" in element or \".jpg\" in element or \".jpeg\" in element:\n",
        "\n",
        "    # Ignore images with code_execution in filename (these are doubles)\n",
        "    if \"code_execution\" in element:\n",
        "      other_files.append(element)\n",
        "\n",
        "    else:\n",
        "    # Grab image filenames\n",
        "      imgs_files.append(element)\n",
        "\n",
        "  else:\n",
        "    # Get text outputs\n",
        "    txt_outs.append(element)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxXQX2Lu0fm7"
      },
      "source": [
        "Upload the images to GCS to get a public URL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCFYcWiH0qhK"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "def upload_to_gcs(local_file, bucket_name, blob_name):\n",
        "    \"\"\"\n",
        "    Upload a file to GCS bucket.\n",
        "    \"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_filename(local_file)\n",
        "\n",
        "def get_public_url(bucket_name, blob_name):\n",
        "    \"\"\"\n",
        "    Get the public URL of a file in the GCS bucket.\n",
        "    \"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    return blob.public_url\n",
        "\n",
        "# Upload to GCS\n",
        "gcs_img_files = [] #collect public image urls in this list\n",
        "\n",
        "for image in imgs_files:\n",
        "  # Upload Image\n",
        "  upload_to_gcs(image, GCS_BUCKET, image)\n",
        "\n",
        "  # Get Image public URL\n",
        "  public_image_url = get_public_url(GCS_BUCKET, image)\n",
        "  gcs_img_files.append(public_image_url)\n",
        "  print(public_image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d6S-S2CRQfD"
      },
      "source": [
        "### Generate the Report with Vertex AI Code Interpreter Extension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpbQpB8wQlXv"
      },
      "source": [
        "With the collected text outputs and the public URLs of the images, you can ask Code Interpreter extension to generate a compelling PDF Report. For this, let it generate a .html file first - you can convert it to PDF in the next cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DerzVD39k2oM"
      },
      "outputs": [],
      "source": [
        "response = run_code_interpreter(instructions=f\"\"\"\n",
        "    You are a report generator. Given a list of filenames and strings, create an interesting report in html language and save it to report.html.\n",
        "    The report revolves around reviews for the game {game}.\n",
        "\n",
        "    Structure the report with proper headings. Don't use 'String' as a heading.\n",
        "    Write the whole report in natural language. You are allowed to use bullet points.\n",
        "    Start the report with a summary of the game {game}\n",
        "    Embed the images directly in the html and include image descriptions.\n",
        "\n",
        "    The contents you can use are these, including images (the filenames indicate the image content):\n",
        "    {gcs_img_files}\n",
        "\n",
        "    And string contents:\n",
        "    {txt_outs}\n",
        "    \"\"\")\n",
        "process_response(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu7Oc0QX2dt-"
      },
      "source": [
        "Convert the html to a .pdf file:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xhtml2pdf.pisa as pisa\n",
        "\n",
        "with open(\"report.html\") as infile, open(\"report.pdf\", \"w+b\") as outfile:\n",
        "    pisa.CreatePDF(infile, outfile)"
      ],
      "metadata": {
        "id": "-U2h2Pt-G1oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAERYURKx6Me"
      },
      "source": [
        "Your report.pdf is now generated and saved within your (Colab) environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8gZtlqZnvH4"
      },
      "source": [
        "## [OPTIONAL] Step 5: Google Workspace APIs (Outside Colab)\n",
        "\n",
        "This section shows how you can store your generated PDF report in your Google Drive, and how you can send the report as an attachment via Gmail.\n",
        "\n",
        "🚨 **You will need to run this section outside of Colab in a local environment, as we will set up the API Credentials for a Desktop App.**🚨\n",
        "\n",
        "For this, you need to configure the Google Workspace API and credentials first.\n",
        "\n",
        "You can check out the [Python Quick Start Guide](https://developers.google.com/gmail/api/quickstart/python) for more details.\n",
        "\n",
        "ㅤ\n",
        "\n",
        "👣 **Steps for setting up the scopes:**\n",
        "1. [Go to the OAuth consent screen in your project](https://console.cloud.google.com/apis/credentials/consent)\n",
        "1. For User type select external, then click Create.\n",
        "1. Complete the app registration form by adding an app name, and adding your email to the user support email & developer contact information, then click Save and Continue.\n",
        "1. Click on `Add or Remove Scopes`\n",
        "1. In the filter search bar of the selected scopes window, search for drive and enable the Scope https://www.googleapis.com/auth/drive\n",
        "1. Now search for Gmail and enable the Scope https://www.googleapis.com/auth/gmail.send\n",
        "1. Click on Save and Continue.\n",
        "1. In the Test Users window, add your own Google email address as a User by clicking `Add Users`, then click on Save and Continue.\n",
        "1. Review your app registration summary. To make changes, click Edit. If the app registration looks OK, click Back to Dashboard.\n",
        "\n",
        "ㅤ\n",
        "\n",
        "\n",
        "👣  **Steps for retrieving authorized credentials:**\n",
        "1. Go to [Credentials](https://console.cloud.google.com/apis/credentials) in the GCP console.\n",
        "1. Click Create Credentials > OAuth client ID.\n",
        "1. Click Application type > Desktop app.\n",
        "1. In the Name field, type a name for the credential. This name is only shown in the Google Cloud console.\n",
        "1. Click Create. The OAuth client created screen appears, showing your new Client ID and Client secret.\n",
        "1. Click OK. The newly created credential appears under OAuth 2.0 Client IDs.\n",
        "1. Save the downloaded JSON file as credentials.json, and move the file to your working directory.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "After that, you can run the following cell to get your creds variable by parsing the credentials.json file:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2 import credentials\n",
        "\n",
        "SCOPES = ['https://mail.google.com/', 'https://www.googleapis.com/auth/gmail.send', 'https://www.googleapis.com/auth/drive']\n",
        "\n",
        "creds = None\n",
        "# Token file typically stores credentials for reuse\n",
        "token_file = 'token.json'\n",
        "\n",
        "# Check if authorized credentials exist\n",
        "if os.path.exists(token_file):\n",
        "    creds = credentials.Credentials.from_authorized_user_file(token_file, SCOPES)\n",
        "# If not, or credentials are invalid, trigger the authorization flow\n",
        "if not creds or not creds.valid:\n",
        "    if creds and creds.expired and creds.refresh_token:\n",
        "        creds.refresh(Request())\n",
        "    else:\n",
        "        flow = InstalledAppFlow.from_client_secrets_file(\n",
        "        \"credentials.json\", SCOPES\n",
        "        )\n",
        "        creds = flow.run_local_server(port=0)\n",
        "    # Save the credentials for the next run\n",
        "    with open(\"token.json\", \"w\") as token:\n",
        "        token.write(creds.to_json())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OD5B_RxW1xqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading Report to Google Drive\n",
        "This section let's you upload the generated PDF report to your Google Drive. It will first create a new folder for you (specify the folder name in the next cell) and upload the PDF file to that folder."
      ],
      "metadata": {
        "id": "FN-tQMuU1k1y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWsSrRt1RteH"
      },
      "outputs": [],
      "source": [
        "# @markdown Provide the folder name on Google Drive where the PDF should be saved into:\n",
        "\n",
        "folder_name = 'extensions-demo' # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function lets you create a new folder in Google Drive:"
      ],
      "metadata": {
        "id": "vNNxhVG_IO73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdlpIvw6vb5d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "def create_folder(folder_name):\n",
        "    \"\"\"Creates a folder in Google Drive.\n",
        "    This function uses the Google Drive API to create a new folder with the specified name.\n",
        "\n",
        "    Args:\n",
        "        folder_name: The name of the folder to create.\n",
        "\n",
        "    Returns:\n",
        "        str: The ID of the newly created folder.\n",
        "    \"\"\"\n",
        "    drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "    file_metadata = {\n",
        "        'name': folder_name,\n",
        "        'mimeType': 'application/vnd.google-apps.folder'\n",
        "    }\n",
        "    folder = drive_service.files().create(body=file_metadata, fields='id').execute()\n",
        "    return folder.get('id')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzJv8YrlAqj5"
      },
      "outputs": [],
      "source": [
        "# Create your folder\n",
        "folder_id = create_folder(folder_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT8PpUlISFQw"
      },
      "source": [
        "Lastly, upload your report.pdf to your new Google Drive Folder. The next function will help you upload a specified file to your newly created folder:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file(file_path, folder_id):\n",
        "    \"\"\"Uploads a file to a specific folder in Google Drive.\n",
        "\n",
        "    This function uses the Google Drive API to upload a file from the local filesystem\n",
        "    to a specified folder in Google Drive. It automatically determines the appropriate\n",
        "    MIME type based on the file extension.\n",
        "\n",
        "    Args:\n",
        "        file_path: The path to the file to upload.\n",
        "        folder_id: The ID of the folder to upload the file to.\n",
        "\n",
        "    Returns:\n",
        "        str: The ID of the uploaded file.\n",
        "    \"\"\"\n",
        "    # Build the Gmail API service object\n",
        "    drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "    file_metadata = {\n",
        "        'name': os.path.basename(file_path),\n",
        "        'parents': [folder_id]\n",
        "    }\n",
        "\n",
        "    # Determine MIME type based on file extension\n",
        "    extension = os.path.splitext(file_path)[1].lower()\n",
        "    if extension in ['.jpg', '.jpeg', '.png']:\n",
        "        mime_type = 'image/jpeg'  # Adjust for other image types if needed\n",
        "    elif extension == '.pdf':\n",
        "        mime_type = 'application/pdf'\n",
        "    else:\n",
        "        mime_type = 'application/octet-stream'  # Generic fallback\n",
        "\n",
        "    media = MediaFileUpload(file_path, mimetype=mime_type, resumable=True)\n",
        "    file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "    print(f'File uploaded to Drive: {file.get(\"id\")}')\n",
        "\n",
        "    return file.get(\"id\")"
      ],
      "metadata": {
        "id": "SceOEWCYIp41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uVEcbkdAq4q"
      },
      "outputs": [],
      "source": [
        "# Upload file to Google Drive folder\n",
        "file_id = upload_file('report.pdf', folder_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sending the Report via Gmail\n",
        "The following sections show how to attach the generated PDF report to an email and send it to a recipient with the Gmail API."
      ],
      "metadata": {
        "id": "wK_Fjve2vWro"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDxWXDdIyt9m"
      },
      "source": [
        "Grab the contents of the pdf report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZcwa89bkl5o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_pdf_file(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        pdf_data = f.read()\n",
        "    return pdf_data\n",
        "\n",
        "pdf_filename = \"report.pdf\"  # Path to your PDF in Colab\n",
        "pdf_data = read_pdf_file(pdf_filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rXqEyxfyxs_"
      },
      "source": [
        "Funciton to parse the pdf contents into a raw message for the e-mail attachment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1c4Az0Lkl2_"
      },
      "outputs": [],
      "source": [
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "import base64\n",
        "\n",
        "def create_message_with_attachment(sender, to, subject, body, filename, attachment):\n",
        "    message = MIMEMultipart()\n",
        "    message['to'] = to\n",
        "    message['from'] = sender\n",
        "    message['subject'] = subject\n",
        "\n",
        "    msg_body = MIMEText(body, 'plain')\n",
        "    message.attach(msg_body)\n",
        "\n",
        "    part = MIMEBase('application', 'octet-stream')  # For PDFs\n",
        "    part.set_payload(attachment)\n",
        "    encoders.encode_base64(part)\n",
        "    part.add_header('Content-Disposition', f'attachment; filename={filename}')\n",
        "    message.attach(part)\n",
        "\n",
        "    raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
        "    return {'raw': raw_message}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GuNuRmXy6ud"
      },
      "source": [
        "#### Setting up e-mail configuration\n",
        "Provide the recipient and run the next cell to get a API token for accessing Gmail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWgbAgUYopXq"
      },
      "outputs": [],
      "source": [
        "# Provide the details for constructing your e-mail\n",
        "\n",
        "recipient = 'recipient@domain.com' #@param {type: 'string'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lp54MYkzGgM"
      },
      "source": [
        "#### Send the e-mail\n",
        "📧 Now you can send the e-mail with the attached pdf report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ic38FaEis1k-"
      },
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Build the Gmail API service object\n",
        "service = build('gmail', 'v1', credentials=creds)\n",
        "\n",
        "# Provide the details for constructing your e-mail\n",
        "subject = f\"{game} Review Analysis Report\"\n",
        "body = f\"Attached is the Report on the Review Analysis for {game}\"\n",
        "\n",
        "# Construct e-mail\n",
        "message = create_message_with_attachment('me', recipient,\n",
        "                                          subject, body,\n",
        "                                          pdf_filename, pdf_data)\n",
        "\n",
        "# Send e-mail\n",
        "service.users().messages().send(userId='me', body=message).execute()\n",
        "print(\"Email sent!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co10z50ugMF3"
      },
      "source": [
        "# 🧹 Cleaning up\n",
        "\n",
        "Clean up resources created in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo2UYWl_dC55"
      },
      "source": [
        "Remove the extensions instances created in this notebook by running the cell below:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtdR2b7DdC55"
      },
      "outputs": [],
      "source": [
        "extension_code_interpreter.delete()\n",
        "extension_vertex_ai_search.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1pyDrUuSOg8"
      },
      "source": [
        "You can run the next cell to get a list of all other remaining Vertex AI Extension Instances in your environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTEgYGhFQfTW"
      },
      "outputs": [],
      "source": [
        "extensions.Extension.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihJEWJvNSfc9"
      },
      "source": [
        "Alternatively, you can uncomment the following code block to delete all active extensions in your project, by using the IDs above to clean up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsPKKv-USmi-"
      },
      "outputs": [],
      "source": [
        "#clean_ids = []\n",
        "\n",
        "#for element in extensions.Extension.list():\n",
        "    #clean_ids.append(str(element).split(\"extensions/\")[1])\n",
        "\n",
        "#for id in clean_ids:\n",
        "   #extension = extensions.Extension(id)\n",
        "   #extension.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncomment below to delete your public GCS Bucket by first deleting all files in it, then deleting the bucket itself:\n",
        "\n",
        "❗❗❗ Only run the below cells if you created a new bucket just for this notebook ❗❗❗"
      ],
      "metadata": {
        "id": "1Yvrftwc91S0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "def empty_bucket(bucket_name):\n",
        "    \"\"\"Deletes all objects in the specified GCS bucket.\"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "    blobs = bucket.list_blobs()  # List all blobs (objects)\n",
        "    for blob in blobs:\n",
        "        blob.delete()  # Delete each blob\n",
        "\n",
        "    print(f\"Bucket {bucket_name} emptied.\")"
      ],
      "metadata": {
        "id": "t1hxIR5ySCA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Empty the bucket by deleting all files in it\n",
        "empty_bucket(GCS_BUCKET)\n",
        "\n",
        "## Create a client object\n",
        "client = storage.Client(project=PROJECT_ID)\n",
        "\n",
        "## Get the bucket object\n",
        "bucket = client.get_bucket(GCS_BUCKET)\n",
        "\n",
        "## Delete the bucket\n",
        "bucket.delete()\n",
        "\n",
        "print(f\"Bucket {GCS_BUCKET} deleted successfully.\")"
      ],
      "metadata": {
        "id": "WIbOqLxE9iqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, delete all the assets generated by the Vertex AI extensions. First, let's get the filenames:"
      ],
      "metadata": {
        "id": "kp1vrA6ITpyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = imgs_files + other_files\n",
        "\n",
        "for i in range (10):\n",
        "  files.append(f'website_text_{i}.txt')\n",
        "\n",
        "files.append('report.html')\n",
        "files.append('report.pdf')\n",
        "files.append('reviews.csv')\n",
        "files.append('ideas.txt')\n",
        "files"
      ],
      "metadata": {
        "id": "_wdoGGsPS7GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, delete the files:"
      ],
      "metadata": {
        "id": "hsY43wOCTv7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for file in files:\n",
        "  try:\n",
        "    os.remove(file)\n",
        "  except FileNotFoundError as e:\n",
        "    print(e)\n",
        "    print('Skipping.')"
      ],
      "metadata": {
        "id": "Cpa6wnBCScsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete your newly created Google Drive folder and the file in it:"
      ],
      "metadata": {
        "id": "ie99m0cXUpHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Delete the file with file_id\n",
        "drive_service = build('drive', 'v3', credentials=creds)  # Assuming 'creds' are set up\n",
        "drive_service.files().delete(fileId=file_id).execute()\n",
        "print(f\"File with ID {file_id} deleted.\")\n",
        "\n",
        "# Delete the folder with folder_id\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "drive_service.files().delete(fileId=folder_id).execute()\n",
        "print(f\"Folder with ID {folder_id} deleted.\")"
      ],
      "metadata": {
        "id": "mITGMyKdUjBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete your Google Cloud CLI ADC Configuration, if you no longer need it, by running:\n",
        "\n",
        "`$ gcloud config configurations delete CONFIG_NAME`\n"
      ],
      "metadata": {
        "id": "3w8tg9O6rBmx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuJs4q0oThE3"
      },
      "source": [
        "❗❗❗ Don't forget to delete any other created assets if you don't need them, e.g.\n",
        "\n",
        "*   Your Vertex Search Engine: https://console.cloud.google.com/gen-app-builder/apps\n",
        "*   Your Data Store: https://console.cloud.google.com/gen-app-builder/data-stores\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NUe3Zgg-DoVF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}