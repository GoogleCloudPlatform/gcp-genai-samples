{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "VCyg9mhJ6yIZ",
   "metadata": {
    "id": "VCyg9mhJ6yIZ"
   },
   "source": [
    "# Tuning text foundation models with Adapter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ArPgx74OHCTC",
   "metadata": {
    "id": "ArPgx74OHCTC"
   },
   "source": [
    "## Adapter Tuning in Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IcsZCiGJHxpK",
   "metadata": {
    "id": "IcsZCiGJHxpK"
   },
   "source": [
    "<img src=\"./images/architecture.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ePC0nZm-7CgU",
   "metadata": {
    "id": "ePC0nZm-7CgU"
   },
   "source": [
    "## Install pre-requisites\n",
    "\n",
    "If running in Colab install the pre-requisites into the runtime. Otherwise it is assumed that the notebook is running in Vertex Workbench. In that case it is recommended to install the pre-requistes from a terminal using the `--user` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e5c3c-9bf3-4112-bb1a-fe1c07de8a16",
   "metadata": {
    "id": "351e5c3c-9bf3-4112-bb1a-fe1c07de8a16"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    ! pip install -U google-cloud-aiplatform \"shapely<2.0.0\"\n",
    "    ! pip install -U datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da75c5-6a27-4900-8ccc-52196f684087",
   "metadata": {
    "id": "74da75c5-6a27-4900-8ccc-52196f684087"
   },
   "source": [
    "## Authenticate\n",
    "\n",
    "If running in Colab authenticate with `google.colab.google.auth` otherwise assume that running on Vertex Workbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020223cd-b47f-43a2-b3e7-1550689d3bc0",
   "metadata": {
    "id": "020223cd-b47f-43a2-b3e7-1550689d3bc0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth as google_auth\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6acd485-20e1-4b78-9c95-a0c1038c89d4",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f435cd50-1cc1-4a61-91ae-2065b0f9c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501fe924-5b58-447a-89af-ca3bd5f63c53",
   "metadata": {
    "id": "501fe924-5b58-447a-89af-ca3bd5f63c53"
   },
   "source": [
    "## Configure environment setttings\n",
    "\n",
    "* `PROJECT_ID` - your GCP project ID\n",
    "* `ENDPOINT_LOCATION` - a region where the the adapter endpoint will be deployed \n",
    "* `TUNING_JOB_LOCATION` - a region to run a tuning pipeline. Must be `europe-west4`\n",
    "* `PIPELINE_ROOT_GCS_LOCATION` - a GCS location for storing tuning pipeline artifacts. Must be in the same region where the tuning job runs\n",
    "* `DATA_STAGING_GCS_LOCATION` - a GCS location for training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be1e9a1-8daa-4f0e-af8a-b0a8304c2311",
   "metadata": {
    "id": "7be1e9a1-8daa-4f0e-af8a-b0a8304c2311"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"jk-mlops-dev\"  # @param {type:\"string\"}\n",
    "ENDPOINT_LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "TUNING_JOB_LOCATION = \"europe-west4\" # @param {type:\"string\"}\n",
    "PIPELINE_ROOT_GCS_LOCATION = 'gs://jk-staging-europe-west4/vertex-genai-tuning-examples/pipelines'\n",
    "DATA_STAGING_GCS_LOCATION = 'gs://jk-vertex-us-central1/vertex-genai-tuning-examples/datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f2e30-b42a-4398-a151-a137877243e8",
   "metadata": {},
   "source": [
    "### Initialize Vertex SKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ca645e-a296-4802-892f-0af835d2fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=ENDPOINT_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc15fca-7740-4243-9c13-b964be27cce7",
   "metadata": {},
   "source": [
    "### Create a Vertex AI TensorBoard instance\n",
    "\n",
    "The Adapter Tuning pipeline can log the training metrics for tracking and retrospective analysis. \n",
    "\n",
    "Create an instance of Vertex AI Tensorboard that will be used by tuning pipeline runs. \n",
    "\n",
    "If you want to reuse an existing instance, skip the following cell and set the `tensorboard_id` variable to your instance ID. Note that the instance must be in the same region where the tuning jobs will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef06274-56ca-4ce1-8e1d-9c44379990f7",
   "metadata": {
    "id": "bef7085f-8c28-4c85-bc2c-a84676b68de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter tuning - \n",
      "projects/895222332033/locations/europe-west4/tensorboards/548190109330046976\n"
     ]
    }
   ],
   "source": [
    "display_name = 'Adapter tuning - '\n",
    "\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "        display_name=display_name,\n",
    "        project=PROJECT_ID,\n",
    "        location=TUNING_JOB_LOCATION,\n",
    "    )\n",
    "\n",
    "print(tensorboard.display_name)\n",
    "print(tensorboard.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13f34bf1-977b-4f61-b39e-dbd89e09f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard_id = tensorboard.resource_name.split('/')[-1]\n",
    "#tensorboard_id = '5392374458520436736'\n",
    "tensorboard_id = '548190109330046976'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21122190-b7e8-4ddd-a512-a49793470c02",
   "metadata": {
    "id": "21122190-b7e8-4ddd-a512-a49793470c02"
   },
   "source": [
    "## Prepare training dataset\n",
    "\n",
    "In this lab, you are going to tune the **text-bison** foundation model for a single label text classification task. You are going to use the `dair-ai/emotion` dataset from HuggingFace. .\n",
    "\n",
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "555f7be7-5833-495f-97e6-1105bb4b4274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n",
      "{'text': ['im feeling rather rotten so im not very ambitious right now', 'im updating my blog because i feel shitty'], 'label': [0, 0]}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('dair-ai/emotion')\n",
    "print(dataset)\n",
    "print(dataset['test'][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06545e0f-d34a-4abc-826b-d865420280e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7200\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 256\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 256\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = {k:v for (k,v) in zip(['train', 'validation', 'test'],\n",
    "                                 load_dataset('dair-ai/emotion', split=['train[0:7200]', 'validation[0:256]', 'test[0:256]']))}\n",
    "dataset = DatasetDict(splits)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394abc2d-3a1d-4fed-80b2-bd7cf4deeabf",
   "metadata": {
    "id": "394abc2d-3a1d-4fed-80b2-bd7cf4deeabf"
   },
   "source": [
    "### Convert to the format required by the tuning pipeline\n",
    "\n",
    "Your model tuning dataset must be in JSON Lines (JSONL) format where each line contains a single tuning example. Each example is composed of an `input_text` field that contains the prompt to the model and an `output_text` field that contains an example response that the tuned model is expected to produce. The maximum token length for input_text is 8,192 and the maximum token length for output_text is 1,024. If either fields exceed the maximum token length, the excess tokens are truncated.\n",
    "\n",
    "The examples included in your dataset should match your expected production traffic. If your dataset contains specific formatting, keywords, instructions, or information, the production data should be formatted in the same way and contain the same instructions.\n",
    "\n",
    "For example, if the examples in your dataset include a `\"question:\"` and a `\"context:\"`, production traffic should also be formatted to include a `\"question:\"` and a `\"context:\"` in the same order as it appears in the dataset examples. If you exclude the context, the model will not recognize the pattern, even if the exact question was in an example in the dataset.\n",
    "\n",
    "For tasks such as classification, it is possible to create a dataset of examples that don't contain instructions. However, excluding instructions from the examples in the dataset leads to worse performance after tuning than including instructions, especially for smaller datasets.\n",
    "\n",
    "For our dataset, we are going to add the following instructions\n",
    "\n",
    "```\n",
    "Classify the following as one of the following categories:\n",
    "- sadness,\n",
    "- joy,\n",
    "Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13dd9227-c0ea-418e-96c7-997e31c3275c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = {\n",
    "    0: 'sadness',\n",
    "    1: 'joy',\n",
    "    2: 'love',\n",
    "    3: 'anger',\n",
    "    4: 'fear',\n",
    "    5: 'surprise'\n",
    "}\n",
    "\n",
    "class_labels.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11f9f3b5-88ec-4c7b-9df6-ede3fe709ee6",
   "metadata": {
    "id": "11f9f3b5-88ec-4c7b-9df6-ede3fe709ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_text', 'output_text'],\n",
      "        num_rows: 7200\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_text', 'output_text'],\n",
      "        num_rows: 256\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_text', 'output_text'],\n",
      "        num_rows: 256\n",
      "    })\n",
      "})\n",
      "{'input_text': ['Classify the following text into one of the following classes: \\n[sadness, joy, love, anger, fear, surprise]\\nText:\\ni didnt feel humiliated'], 'output_text': ['sadness']}\n"
     ]
    }
   ],
   "source": [
    "instructions = f'''Classify the following text into one of the following classes: \n",
    "[{', '.join(class_labels.values())}]\n",
    "Text:\n",
    "'''\n",
    "\n",
    "def add_instructions(example, instructions):\n",
    "    example[\"input_text\"] = f'{instructions}{example[\"text\"]}'\n",
    "    example[\"output_text\"] = class_labels[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "tuning_dataset = dataset.map(lambda x: add_instructions(x, instructions)).remove_columns(['text', 'label'])\n",
    "\n",
    "print(tuning_dataset)\n",
    "print(tuning_dataset['train'][:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39815f52-4b82-4a7d-a27c-0ef2a80d44d1",
   "metadata": {},
   "source": [
    "### Export the dataset splits to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf60eca2-29e1-42b9-9b31-f25b5aeb254d",
   "metadata": {
    "id": "bf60eca2-29e1-42b9-9b31-f25b5aeb254d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c956283b77bc49b2a0177c5813c3eb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://emotion-train.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  1.8 MiB/  1.8 MiB]                                                \n",
      "Operation completed over 1 objects/1.8 MiB.                                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f629ae0ad0d64ec29d0187507fbf1e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://emotion-validation.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 62.8 KiB/ 62.8 KiB]                                                \n",
      "Operation completed over 1 objects/62.8 KiB.                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cee417408e4fa286320a2b42d2d8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://emotion-test.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 62.6 KiB/ 62.6 KiB]                                                \n",
      "Operation completed over 1 objects/62.6 KiB.                                     \n",
      "gs://jk-vertex-us-central1/vertex-genai-tuning-examples/datasets/batch_inputs.json\n",
      "gs://jk-vertex-us-central1/vertex-genai-tuning-examples/datasets/emotion-evaluation.json\n",
      "gs://jk-vertex-us-central1/vertex-genai-tuning-examples/datasets/emotion-test.jsonl\n",
      "gs://jk-vertex-us-central1/vertex-genai-tuning-examples/datasets/emotion-train.jsonl\n",
      "gs://jk-vertex-us-central1/vertex-genai-tuning-examples/datasets/emotion-validation.jsonl\n",
      "gs://jk-vertex-us-central1/vertex-genai-tuning-examples/datasets/batch_prediction_outputs/\n"
     ]
    }
   ],
   "source": [
    "gcs_uris = {}\n",
    "filename_prefix = 'emotion'\n",
    "\n",
    "for split_name, split_data in tuning_dataset.items():\n",
    "    jsonl_filename = f'{filename_prefix}-{split_name}.jsonl'\n",
    "    gcs_uri = f'{DATA_STAGING_GCS_LOCATION}/{jsonl_filename}'\n",
    "    gcs_uris[split_name] = gcs_uri\n",
    "    split_data.to_json(jsonl_filename)\n",
    "    !gsutil cp {jsonl_filename} {gcs_uri}\n",
    "\n",
    "!gsutil ls {DATA_STAGING_GCS_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71eed0d-6197-4830-a51d-29c4a234d288",
   "metadata": {
    "id": "e71eed0d-6197-4830-a51d-29c4a234d288"
   },
   "source": [
    "## Run a tuning pipeline\n",
    "\n",
    "Currently, Vertex SDK does not have a full support for running Adapter Tuning pipelines. In the interim you can use Vertex Pipelines API directly.\n",
    "\n",
    "### Configure a pipeline job\n",
    "\n",
    "The key parameters used to configure a run of the tuning pipeline are as follows:\n",
    "* `model_display_name` - a display name of the deployed adapter\n",
    "* `location` - a region where the adapter endpoint will be deployed\n",
    "* `dataset_uri` - a GCS location of the training split\n",
    "* `evaluation_data_uri` - a GCS location of the validation split\n",
    "* `train_steps` - a number of steps to train for\n",
    "* `evaluation_interval` - training metrics are generated every `evaluation_interval` steps\n",
    "* `tensorboard_resource_id` - an ID of a Tensorboard instance to use for tracking\n",
    "* `large_model_reference` - the name of the base foundation model to tune\n",
    "\n",
    "There are other parameters that can be configured, including parameters controlling a learning rate. In this lab we use the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cee82826-4649-48a8-8a35-f39076206ccb",
   "metadata": {
    "id": "cee82826-4649-48a8-8a35-f39076206ccb"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import PipelineJob\n",
    "\n",
    "train_steps = 50\n",
    "model_display_name = f\"emotion-classification-demo-{train_steps}-steps\"\n",
    "\n",
    "pipeline_arguments = {\n",
    "    \"model_display_name\": model_display_name,\n",
    "    \"location\": ENDPOINT_LOCATION,\n",
    "    \"large_model_reference\": \"text-bison@001\",\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"train_steps\": train_steps,\n",
    "    \"dataset_uri\": gcs_uris['train'],\n",
    "    \"evaluation_interval\": 20,\n",
    "    \"evaluation_data_uri\": gcs_uris['validation'],\n",
    "    \"tensorboard_resource_id\": tensorboard_id,\n",
    "}\n",
    "\n",
    "pipeline_root = f'{PIPELINE_ROOT_GCS_LOCATION}/{model_display_name}'\n",
    "template_path = 'https://us-kfp.pkg.dev/ml-pipeline/large-language-model-pipelines/tune-large-model/v2.0.0'\n",
    "\n",
    "job = PipelineJob(\n",
    "    template_path=template_path,\n",
    "    display_name=None,\n",
    "    parameter_values=pipeline_arguments,\n",
    "    location=TUNING_JOB_LOCATION,\n",
    "    pipeline_root=pipeline_root,\n",
    "    enable_caching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2baf200-da88-4e9b-98c5-0c58f7b87242",
   "metadata": {
    "id": "d2baf200-da88-4e9b-98c5-0c58f7b87242"
   },
   "source": [
    "### Submit a pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c856cfbb-4192-480f-a3be-c8ec6a84158b",
   "metadata": {
    "id": "c856cfbb-4192-480f-a3be-c8ec6a84158b"
   },
   "outputs": [],
   "source": [
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926c6a3-84dc-4346-810e-06c61bd89068",
   "metadata": {},
   "source": [
    "### Monitor the job\n",
    "\n",
    "You can monitor the job execution using Vertex AI UI or inspecting the job object. The job may take a couple of hours to complete. Wait for the job to finish before moving to another step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9955e8db-fdd5-4645-a39b-bc3d047f38ef",
   "metadata": {},
   "source": [
    "## Using and evaluating the tuned model\n",
    "\n",
    "### Configure environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16489195-f752-4e9b-9633-a23558be207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from kfp import compiler\n",
    "from vertexai.preview import language_models\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e76569-3057-4e5f-8dac-ee0ea6c1e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"jk-mlops-dev\"  # @param {type:\"string\"}\n",
    "ENDPOINT_LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "TUNING_JOB_LOCATION = \"europe-west4\" # @param {type:\"string\"}\n",
    "PIPELINE_ROOT_GCS_LOCATION = 'gs://jk-staging-europe-west4/vertex-genai-tuning-examples/pipelines'\n",
    "DATA_STAGING_GCS_LOCATION = 'gs://jk-vertex-us-central1/vertex-genai-tuning-examples/datasets'\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=ENDPOINT_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162511a-3fa7-4ecd-8dfa-162a210e5b13",
   "metadata": {},
   "source": [
    "### Online prediction on the tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e0cf4-ebba-4eae-b9b1-9d76a4e17c40",
   "metadata": {},
   "source": [
    "#### Prepare a test prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9978e17e-9878-4e81-a1ed-e7ca997c4e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_filename = 'emotion-test.jsonl'\n",
    "test_split = load_dataset('json',\n",
    "                          data_files={'test': test_split_filename})\n",
    "print(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84949a7a-f1db-480a-a06b-b7c5df2246fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = test_split['test']['input_text'][1]\n",
    "ground_truth = test_split['test']['output_text'][1]\n",
    "print(prompt)\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11edda7-5856-49f5-be54-86f8512e8450",
   "metadata": {},
   "source": [
    "#### Get a tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60057b5c-b45a-4d3b-b1fa-3be3d232b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerationModel.from_pretrained('text-bison@001')\n",
    "tuned_model_names = model.list_tuned_model_names()\n",
    "print(tuned_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881edcf9-cfd7-4064-b1c0-413070f15f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_name = 'projects/895222332033/locations/us-central1/models/1462409838569979904'\n",
    "\n",
    "tuned_model = TextGenerationModel.get_tuned_model(tuned_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c0db6-c0a9-4d7a-bf6d-cffc16c3a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tuned_model.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744aa142-06c9-46bf-9581-072ff89a9e08",
   "metadata": {},
   "source": [
    "### Batch predictions\n",
    "#### Prepare the batch inference dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86a4e4-7a48-4b39-82b7-022275baf755",
   "metadata": {},
   "source": [
    "The input for batch requests can provided as a BigQuery table or a JSONL file. The JSONL file must use the following format:\n",
    "\n",
    "```\n",
    "{\"prompt\": \"prompt 1 text\"}\n",
    "{\"prompt\": \"prompt 2 text\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d76e1-3c29-4f94-96a1-10a2fe5754ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs = test_split['test'].select(range(0,20))\n",
    "batch_inputs = batch_inputs.rename_column('input_text', 'prompt').remove_columns(['output_text'])\n",
    "print(batch_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7453d78-733d-48fb-b528-18040f884f54",
   "metadata": {},
   "source": [
    "Copy the input file to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438363b3-216b-49d9-9e31-9fee3fae49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs_filename = 'batch_inputs.json'\n",
    "batch_inputs_gcs_uri = f'{DATA_STAGING_GCS_LOCATION}/{batch_inputs_filename}'\n",
    "\n",
    "batch_inputs.to_json(batch_inputs_filename)\n",
    "!gsutil cp {batch_inputs_filename} {batch_inputs_gcs_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1343f5d8-35fd-4e78-987a-a8b2e8c5b8ed",
   "metadata": {},
   "source": [
    "#### Run the batch prediction job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04ec6c-faf0-4601-aba5-efea83dc4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_uri_prefix = f'{DATA_STAGING_GCS_LOCATION}/batch_prediction_outputs'\n",
    "\n",
    "model_parameters={\n",
    "    \"maxOutputTokens\": \"64\",\n",
    "    \"temperature\": \"0.0\",\n",
    "}\n",
    "\n",
    "job = aiplatform.BatchPredictionJob.create(\n",
    "            model_name=tuned_model_name,\n",
    "            job_display_name=None,\n",
    "            gcs_source=batch_inputs_gcs_uri,\n",
    "            gcs_destination_prefix=destination_uri_prefix,\n",
    "            model_parameters=model_parameters,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5f236-be3c-4120-82fb-bfd183159e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b57b4-814a-48a1-b44a-8e995e55f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job.output_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d7fe2-e468-409a-8a80-22953cfa0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_prefix = 'prediction-output'\n",
    "for count, blob in enumerate(job.iter_outputs()):\n",
    "    with open(f'{filename_prefix}-{count}.jsonl', 'wb') as f:\n",
    "        blob.download_to_file(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fb2e0-6b88-4700-b062-499ca67f1669",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f106df-3896-4468-a56f-74f186145fc1",
   "metadata": {},
   "source": [
    "### Compile the evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecded402-cf82-4a10-b518-037b3e57fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.preview.model_evaluation import evaluation_llm_classification_pipeline\n",
    "\n",
    "classification_pipeline_path = 'https://us-kfp.pkg.dev/vertex-evaluation/pipeline-templates/evaluation-llm-classification-pipeline/1.0.1'\n",
    "classification_pipeline_path = 'classification_pipeline.json'\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=evaluation_llm_classification_pipeline,\n",
    "    package_path=classification_pipeline_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a5d08-d30b-45f6-b83c-ecd826c9bbca",
   "metadata": {},
   "source": [
    "### Prepare evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdef6f3-95c5-4455-a213-a7e1748bb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset = test_split.rename_column('input_text', 'prompt').rename_column('output_text', 'ground_truth')\n",
    "print(evaluation_dataset)\n",
    "print(evaluation_dataset['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab64e76-1589-4465-86e4-90d0cd92daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset_filename = 'emotion-evaluation.json'\n",
    "evaluation_dataset_gcs_uri = f'{DATA_STAGING_GCS_LOCATION}/{evaluation_dataset_filename}'\n",
    "evaluation_dataset['test'].to_json(evaluation_dataset_filename)\n",
    "!gsutil cp {evaluation_dataset_filename} {evaluation_dataset_gcs_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469fae4-d8aa-41e2-b4d7-f5907d6c8e9f",
   "metadata": {},
   "source": [
    "### Establish a baseline by evaluating a base model\n",
    "\n",
    "When evaluating the base model, the Model Registry is not used to track evaluation metrics. However, you track the metrics in Vertex Experiments by starting the evaluation pipeline using the PipelineJob API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea90458-364a-4880-974c-9718c6403fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(set(evaluation_dataset['test']['ground_truth']))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f160fa-6ea8-4f2c-a459-7899c67ae3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = TextGenerationModel.from_pretrained('text-bison@001')\n",
    "model_name = base_model._model_resource_name\n",
    "\n",
    "parameters = {\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"location\": ENDPOINT_LOCATION,\n",
    "    \"batch_predict_gcs_destination_output_uri\": f'{PIPELINE_ROOT_GCS_LOCATION}/output',\n",
    "    \"evaluation_class_labels\": class_names,\n",
    "    \"batch_predict_gcs_source_uris\": [evaluation_dataset_gcs_uri],\n",
    "    \"target_field_name\": 'ground_truth',\n",
    "    \"model_name\": model_name,\n",
    "}\n",
    "\n",
    "job_id = \"base-model-evaluation-{}\".format(uuid.uuid4())\n",
    "\n",
    "experiment_name = 'tweet-emotion-classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeaedce-a992-4e69-a259-ce0dd1f13ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=job_id,\n",
    "    template_path=classification_pipeline_path,\n",
    "    job_id=job_id,\n",
    "    pipeline_root=PIPELINE_ROOT_GCS_LOCATION,\n",
    "    parameter_values=parameters,\n",
    "    enable_caching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aabc5b3-9a95-4607-b1ea-4e77adf9a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.submit(experiment=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf2a24-9b27-4070-a224-04ec168e46f0",
   "metadata": {},
   "source": [
    "### Evaluate the tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3005b79-4efd-45a8-9d18-6581f2126ec4",
   "metadata": {},
   "source": [
    "#### View a list of tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be388d0-b393-4b3a-bd40-9e71e50db9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerationModel.from_pretrained('text-bison@001')\n",
    "tuned_model_names = model.list_tuned_model_names()\n",
    "print(tuned_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363c016-c89d-400f-8a53-9632bc50120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_name = 'projects/895222332033/locations/us-central1/models/6896565738945904640'\n",
    "job_id = f\"tuned-model-100-steps-{uuid.uuid4()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e02839-91df-4b5c-ade1-5072aaa88b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"location\": ENDPOINT_LOCATION,\n",
    "    \"batch_predict_gcs_destination_output_uri\": f'{PIPELINE_ROOT_GCS_LOCATION}/output',\n",
    "    \"evaluation_class_labels\": class_names,\n",
    "    \"batch_predict_gcs_source_uris\": [evaluation_dataset_gcs_uri],\n",
    "    \"target_field_name\": 'ground_truth',\n",
    "    \"model_name\": tuned_model_name,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e58d2-4e8c-44b2-808b-016da8b87105",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=job_id,\n",
    "    template_path=classification_pipeline_path,\n",
    "    job_id=job_id,\n",
    "    pipeline_root=PIPELINE_ROOT_GCS_LOCATION,\n",
    "    parameter_values=parameters,\n",
    "    enable_caching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e8c63-b0ca-468b-97b2-77b6b5fdd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.submit(experiment=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e4ebd-4645-4a10-8c45-f410209ff1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1oauNzDuhzETuaHTgC_b3WN64UWYUBzU_",
     "timestamp": 1691439095914
    }
   ]
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
